{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68ffaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�T�u�f�B���N�g���܂��̓t�@�C�� output �͊��ɑ��݂��܂��B\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "!mkdir output\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3282798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    AMP = False\n",
    "    BATCH_SIZE_TRAIN = 3 #32\n",
    "    BATCH_SIZE_VALID = 3 #32\n",
    "    DEBUG = False\n",
    "    EPOCHS = 3  #30\n",
    "    FOLDS = 5\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    LEARNING_RATE = 1e-3\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    TRAIN_FULL_DATA = False\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "\n",
    "class paths:\n",
    "    OUTPUT_DIR = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\output\"\n",
    "    TEST_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test.csv\"\n",
    "    TEST_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test_demographics.csv\"\n",
    "    TRAIN_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train_demographics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e2e84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s: float):\n",
    "    \"Convert to minutes.\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since: float, percent: float):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_logger(filename=paths.OUTPUT_DIR):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def format_for_scoring(df_preds: pd.DataFrame) ->tuple[pd.DataFrame, pd.DataFrame]: \n",
    "    solution = df_preds[[\"sequence_id\", \"y_true\"]].copy()\n",
    "    solution.columns = [\"id\", \"gesture\"]\n",
    "    solution[\"gesture\"] = solution[\"gesture\"].map(num_to_label)\n",
    "\n",
    "    submission = df_preds[[\"sequence_id\", \"y_pred\"]].copy()\n",
    "    submission.columns = [\"id\", \"gesture\"]\n",
    "    submission[\"gesture\"] = submission[\"gesture\"].map(num_to_label)\n",
    "    \n",
    "    return solution, submission\n",
    "    \n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"—\"*100)\n",
    "\n",
    "\n",
    "label_to_num = {\n",
    "    'Above ear - pull hair': 0,  # < ------- TARGETS START\n",
    "    'Cheek - pinch skin': 1,\n",
    "    'Eyebrow - pull hair': 2,\n",
    "    'Eyelash - pull hair': 3,\n",
    "    'Forehead - pull hairline': 4,\n",
    "    'Forehead - scratch': 5,\n",
    "    'Neck - pinch skin': 6,\n",
    "    'Neck - scratch': 7,  # < ------- TARGETS END\n",
    "    'Drink from bottle/cup': 8,  # < ------- NON-TARGETS START\n",
    "    'Feel around in tray and pull out an object': 8,\n",
    "    'Glasses on/off': 8,\n",
    "    'Pinch knee/leg skin': 8,\n",
    "    'Pull air toward your face': 8,\n",
    "    'Scratch knee/leg skin': 8,\n",
    "    'Text on phone': 8,\n",
    "    'Wave hello': 8,\n",
    "    'Write name in air': 8,\n",
    "    'Write name on leg': 8  # < ------- NON-TARGETS END\n",
    "}\n",
    "type_to_num = {\"Target\": 1, \"Non-Target\":0}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "num_to_type = {v: k for k, v in type_to_num.items()}\n",
    "LOGGER = get_logger()\n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56a38fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (500, 341)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Tesat dataframe shape: (107, 336)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Train demographics dataframe shape: (81, 8)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Test demographics dataframe shape: (2, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>orientation</th>\n",
       "      <th>behavior</th>\n",
       "      <th>phase</th>\n",
       "      <th>gesture</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>thm_2</th>\n",
       "      <th>thm_3</th>\n",
       "      <th>thm_4</th>\n",
       "      <th>thm_5</th>\n",
       "      <th>tof_1_v0</th>\n",
       "      <th>tof_1_v1</th>\n",
       "      <th>tof_1_v2</th>\n",
       "      <th>tof_1_v3</th>\n",
       "      <th>tof_1_v4</th>\n",
       "      <th>tof_1_v5</th>\n",
       "      <th>tof_1_v6</th>\n",
       "      <th>tof_1_v7</th>\n",
       "      <th>tof_1_v8</th>\n",
       "      <th>tof_1_v9</th>\n",
       "      <th>tof_1_v10</th>\n",
       "      <th>tof_1_v11</th>\n",
       "      <th>tof_1_v12</th>\n",
       "      <th>tof_1_v13</th>\n",
       "      <th>tof_1_v14</th>\n",
       "      <th>tof_1_v15</th>\n",
       "      <th>tof_1_v16</th>\n",
       "      <th>tof_1_v17</th>\n",
       "      <th>tof_1_v18</th>\n",
       "      <th>tof_1_v19</th>\n",
       "      <th>tof_1_v20</th>\n",
       "      <th>tof_1_v21</th>\n",
       "      <th>tof_1_v22</th>\n",
       "      <th>tof_1_v23</th>\n",
       "      <th>tof_1_v24</th>\n",
       "      <th>tof_1_v25</th>\n",
       "      <th>tof_1_v26</th>\n",
       "      <th>tof_1_v27</th>\n",
       "      <th>tof_1_v28</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v14</th>\n",
       "      <th>tof_5_v15</th>\n",
       "      <th>tof_5_v16</th>\n",
       "      <th>tof_5_v17</th>\n",
       "      <th>tof_5_v18</th>\n",
       "      <th>tof_5_v19</th>\n",
       "      <th>tof_5_v20</th>\n",
       "      <th>tof_5_v21</th>\n",
       "      <th>tof_5_v22</th>\n",
       "      <th>tof_5_v23</th>\n",
       "      <th>tof_5_v24</th>\n",
       "      <th>tof_5_v25</th>\n",
       "      <th>tof_5_v26</th>\n",
       "      <th>tof_5_v27</th>\n",
       "      <th>tof_5_v28</th>\n",
       "      <th>tof_5_v29</th>\n",
       "      <th>tof_5_v30</th>\n",
       "      <th>tof_5_v31</th>\n",
       "      <th>tof_5_v32</th>\n",
       "      <th>tof_5_v33</th>\n",
       "      <th>tof_5_v34</th>\n",
       "      <th>tof_5_v35</th>\n",
       "      <th>tof_5_v36</th>\n",
       "      <th>tof_5_v37</th>\n",
       "      <th>tof_5_v38</th>\n",
       "      <th>tof_5_v39</th>\n",
       "      <th>tof_5_v40</th>\n",
       "      <th>tof_5_v41</th>\n",
       "      <th>tof_5_v42</th>\n",
       "      <th>tof_5_v43</th>\n",
       "      <th>tof_5_v44</th>\n",
       "      <th>tof_5_v45</th>\n",
       "      <th>tof_5_v46</th>\n",
       "      <th>tof_5_v47</th>\n",
       "      <th>tof_5_v48</th>\n",
       "      <th>tof_5_v49</th>\n",
       "      <th>tof_5_v50</th>\n",
       "      <th>tof_5_v51</th>\n",
       "      <th>tof_5_v52</th>\n",
       "      <th>tof_5_v53</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007_000000</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.683594</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.447327</td>\n",
       "      <td>-0.809753</td>\n",
       "      <td>28.943842</td>\n",
       "      <td>31.822186</td>\n",
       "      <td>29.553024</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>28.310535</td>\n",
       "      <td>131.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000007_000001</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>-0.340271</td>\n",
       "      <td>-0.428650</td>\n",
       "      <td>-0.824524</td>\n",
       "      <td>29.340816</td>\n",
       "      <td>31.874645</td>\n",
       "      <td>29.791740</td>\n",
       "      <td>28.663383</td>\n",
       "      <td>28.406172</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000007_000002</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.722656</td>\n",
       "      <td>5.410156</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.219055</td>\n",
       "      <td>-0.274231</td>\n",
       "      <td>-0.356934</td>\n",
       "      <td>-0.865662</td>\n",
       "      <td>30.339359</td>\n",
       "      <td>30.935045</td>\n",
       "      <td>30.090014</td>\n",
       "      <td>28.796087</td>\n",
       "      <td>28.529778</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000007_000003</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.601562</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>6.457031</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.238159</td>\n",
       "      <td>-0.885986</td>\n",
       "      <td>30.543730</td>\n",
       "      <td>27.044001</td>\n",
       "      <td>29.310717</td>\n",
       "      <td>29.018711</td>\n",
       "      <td>27.402010</td>\n",
       "      <td>143.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000007_000004</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.566406</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>9.632812</td>\n",
       "      <td>0.333557</td>\n",
       "      <td>-0.218628</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>-0.914856</td>\n",
       "      <td>29.317265</td>\n",
       "      <td>25.270855</td>\n",
       "      <td>26.808746</td>\n",
       "      <td>29.408604</td>\n",
       "      <td>27.357603</td>\n",
       "      <td>178.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row_id sequence_type sequence_id  sequence_counter      subject  \\\n",
       "0  SEQ_000007_000000        Target  SEQ_000007                 0  SUBJ_059520   \n",
       "1  SEQ_000007_000001        Target  SEQ_000007                 1  SUBJ_059520   \n",
       "2  SEQ_000007_000002        Target  SEQ_000007                 2  SUBJ_059520   \n",
       "3  SEQ_000007_000003        Target  SEQ_000007                 3  SUBJ_059520   \n",
       "4  SEQ_000007_000004        Target  SEQ_000007                 4  SUBJ_059520   \n",
       "\n",
       "                       orientation                                   behavior  \\\n",
       "0  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "1  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "2  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "3  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "4  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "\n",
       "        phase             gesture     acc_x     acc_y     acc_z     rot_w  \\\n",
       "0  Transition  Cheek - pinch skin  6.683594  6.214844  3.355469  0.134399   \n",
       "1  Transition  Cheek - pinch skin  6.949219  6.214844  3.125000  0.143494   \n",
       "2  Transition  Cheek - pinch skin  5.722656  5.410156  5.421875  0.219055   \n",
       "3  Transition  Cheek - pinch skin  6.601562  3.531250  6.457031  0.297546   \n",
       "4  Transition  Cheek - pinch skin  5.566406  0.277344  9.632812  0.333557   \n",
       "\n",
       "      rot_x     rot_y     rot_z      thm_1      thm_2      thm_3      thm_4  \\\n",
       "0 -0.355164 -0.447327 -0.809753  28.943842  31.822186  29.553024  28.592863   \n",
       "1 -0.340271 -0.428650 -0.824524  29.340816  31.874645  29.791740  28.663383   \n",
       "2 -0.274231 -0.356934 -0.865662  30.339359  30.935045  30.090014  28.796087   \n",
       "3 -0.264160 -0.238159 -0.885986  30.543730  27.044001  29.310717  29.018711   \n",
       "4 -0.218628 -0.063538 -0.914856  29.317265  25.270855  26.808746  29.408604   \n",
       "\n",
       "       thm_5  tof_1_v0  tof_1_v1  tof_1_v2  tof_1_v3  tof_1_v4  tof_1_v5  \\\n",
       "0  28.310535     131.0     134.0     132.0     135.0      98.0      74.0   \n",
       "1  28.406172     130.0     138.0     131.0     135.0     101.0      76.0   \n",
       "2  28.529778     137.0     136.0     147.0     109.0      90.0      81.0   \n",
       "3  27.402010     143.0     147.0     170.0     127.0     109.0      98.0   \n",
       "4  27.357603     178.0     191.0     183.0     157.0     146.0     139.0   \n",
       "\n",
       "   tof_1_v6  tof_1_v7  tof_1_v8  tof_1_v9  tof_1_v10  tof_1_v11  tof_1_v12  \\\n",
       "0      64.0      60.0      -1.0      -1.0      152.0      153.0      141.0   \n",
       "1      66.0      61.0      -1.0      -1.0      156.0      155.0      141.0   \n",
       "2      74.0      74.0      -1.0     164.0      165.0      146.0      106.0   \n",
       "3      95.0      95.0      -1.0     177.0      189.0      177.0      136.0   \n",
       "4     143.0     148.0      -1.0      -1.0      236.0      238.0      208.0   \n",
       "\n",
       "   tof_1_v13  tof_1_v14  tof_1_v15  tof_1_v16  tof_1_v17  tof_1_v18  \\\n",
       "0       89.0       68.0       63.0       -1.0       -1.0       -1.0   \n",
       "1       93.0       74.0       64.0       -1.0       -1.0       -1.0   \n",
       "2       94.0       77.0       77.0       -1.0       -1.0       -1.0   \n",
       "3      121.0      107.0      104.0       -1.0       -1.0       -1.0   \n",
       "4      200.0      185.0      190.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v19  tof_1_v20  tof_1_v21  tof_1_v22  tof_1_v23  tof_1_v24  \\\n",
       "0       -1.0      169.0      118.0       86.0       73.0       -1.0   \n",
       "1       -1.0      165.0      116.0       86.0       75.0      130.0   \n",
       "2      180.0      140.0      118.0      103.0       92.0       -1.0   \n",
       "3      202.0      171.0      160.0      141.0      135.0       -1.0   \n",
       "4      210.0      246.0      225.0      228.0      202.0      149.0   \n",
       "\n",
       "   tof_1_v25  tof_1_v26  tof_1_v27  tof_1_v28  ...  tof_5_v14  tof_5_v15  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0  ...      140.0      119.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0  ...      142.0      122.0   \n",
       "2       -1.0       -1.0       -1.0       -1.0  ...      145.0      139.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0  ...      133.0       -1.0   \n",
       "4      206.0      219.0      219.0      225.0  ...       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v16  tof_5_v17  tof_5_v18  tof_5_v19  tof_5_v20  tof_5_v21  \\\n",
       "0      135.0      156.0      166.0       -1.0       -1.0      155.0   \n",
       "1      138.0      157.0       -1.0       -1.0       -1.0      155.0   \n",
       "2      138.0      164.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      162.0      181.0       -1.0       -1.0       -1.0      152.0   \n",
       "4      197.0       -1.0       -1.0      219.0      192.0       -1.0   \n",
       "\n",
       "   tof_5_v22  tof_5_v23  tof_5_v24  tof_5_v25  tof_5_v26  tof_5_v27  \\\n",
       "0      137.0      112.0      148.0      163.0      164.0      153.0   \n",
       "1      133.0      117.0      145.0      170.0      163.0      157.0   \n",
       "2      145.0      120.0      151.0      165.0       -1.0       -1.0   \n",
       "3      134.0       -1.0      148.0      187.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0      204.0       -1.0       -1.0      212.0   \n",
       "\n",
       "   tof_5_v28  tof_5_v29  tof_5_v30  tof_5_v31  tof_5_v32  tof_5_v33  \\\n",
       "0      133.0      131.0      121.0      118.0      134.0      134.0   \n",
       "1      139.0      127.0      126.0      121.0      136.0      142.0   \n",
       "2       -1.0      151.0      138.0      127.0      151.0      187.0   \n",
       "3      149.0      142.0      135.0       -1.0      159.0      181.0   \n",
       "4      181.0       -1.0       -1.0       -1.0      184.0       -1.0   \n",
       "\n",
       "   tof_5_v34  tof_5_v35  tof_5_v36  tof_5_v37  tof_5_v38  tof_5_v39  \\\n",
       "0      128.0      121.0      119.0      121.0      129.0       -1.0   \n",
       "1      133.0      127.0      123.0      127.0      134.0       -1.0   \n",
       "2       -1.0      156.0      136.0      135.0      134.0       -1.0   \n",
       "3      150.0      135.0      129.0      139.0       -1.0       -1.0   \n",
       "4      179.0      162.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v40  tof_5_v41  tof_5_v42  tof_5_v43  tof_5_v44  tof_5_v45  \\\n",
       "0      113.0      124.0      122.0      131.0       -1.0       -1.0   \n",
       "1      116.0      122.0      123.0      126.0       -1.0       -1.0   \n",
       "2      133.0      142.0      131.0      130.0      132.0      136.0   \n",
       "3      141.0      136.0      120.0      122.0      132.0       -1.0   \n",
       "4      169.0      171.0      145.0      140.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v46  tof_5_v47  tof_5_v48  tof_5_v49  tof_5_v50  tof_5_v51  \\\n",
       "0       -1.0       -1.0      120.0      127.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0      122.0      129.0       -1.0       -1.0   \n",
       "2       -1.0       -1.0      112.0      121.0      123.0      125.0   \n",
       "3       -1.0       -1.0      107.0      112.0      115.0      140.0   \n",
       "4       -1.0       -1.0      132.0      125.0      131.0       -1.0   \n",
       "\n",
       "   tof_5_v52  tof_5_v53  tof_5_v54  tof_5_v55  tof_5_v56  tof_5_v57  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2       -1.0       -1.0       -1.0       -1.0      112.0      119.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0      101.0      111.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0      101.0      109.0   \n",
       "\n",
       "   tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  tof_5_v62  tof_5_v63  \n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0  \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0  \n",
       "2       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0  \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0  \n",
       "4      125.0       -1.0       -1.0       -1.0       -1.0       -1.0  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBJ_000206</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>172.0</td>\n",
       "      <td>50</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBJ_001430</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>51</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBJ_002923</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>54</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBJ_003328</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>52</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJ_004117</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>184.0</td>\n",
       "      <td>54</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject  adult_child  age  sex  handedness  height_cm  \\\n",
       "0  SUBJ_000206            1   41    1           1      172.0   \n",
       "1  SUBJ_001430            0   11    0           1      167.0   \n",
       "2  SUBJ_002923            1   28    1           0      164.0   \n",
       "3  SUBJ_003328            1   33    1           1      171.0   \n",
       "4  SUBJ_004117            0   15    0           1      184.0   \n",
       "\n",
       "   shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "0                    50               25.0  \n",
       "1                    51               27.0  \n",
       "2                    54               26.0  \n",
       "3                    52               25.0  \n",
       "4                    54               28.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(paths.TRAIN_CSV)[:500]\n",
    "df_test = pd.read_csv(paths.TEST_CSV)\n",
    "df_train_demographics = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)[:500]\n",
    "df_test_demographics = pd.read_csv(paths.TEST_DEMOGRAPHICS)\n",
    "\n",
    "print(f\"Train dataframe shape: {df_train.shape}\"), sep()\n",
    "print(f\"Tesat dataframe shape: {df_test.shape}\"), sep()\n",
    "print(f\"Train demographics dataframe shape: {df_train_demographics.shape}\"), sep()\n",
    "print(f\"Test demographics dataframe shape: {df_test_demographics.shape}\")\n",
    "\n",
    "display(df_train.head())\n",
    "display(df_train_demographics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a9876",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67abf1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target\"] = df_train[\"gesture\"].map(label_to_num)\n",
    "df_train.drop(columns=[\"behavior\", \"orientation\"], inplace=True)  # TODO: use LabelEncoder\n",
    "df_train[\"sequence_type\"] = df_train[\"sequence_type\"].map(type_to_num)\n",
    "df_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60a2a300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>phase</th>\n",
       "      <th>gesture</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>thm_2</th>\n",
       "      <th>thm_3</th>\n",
       "      <th>thm_4</th>\n",
       "      <th>thm_5</th>\n",
       "      <th>tof_1_v0</th>\n",
       "      <th>tof_1_v1</th>\n",
       "      <th>tof_1_v2</th>\n",
       "      <th>tof_1_v3</th>\n",
       "      <th>tof_1_v4</th>\n",
       "      <th>tof_1_v5</th>\n",
       "      <th>tof_1_v6</th>\n",
       "      <th>tof_1_v7</th>\n",
       "      <th>tof_1_v8</th>\n",
       "      <th>tof_1_v9</th>\n",
       "      <th>tof_1_v10</th>\n",
       "      <th>tof_1_v11</th>\n",
       "      <th>tof_1_v12</th>\n",
       "      <th>tof_1_v13</th>\n",
       "      <th>tof_1_v14</th>\n",
       "      <th>tof_1_v15</th>\n",
       "      <th>tof_1_v16</th>\n",
       "      <th>tof_1_v17</th>\n",
       "      <th>tof_1_v18</th>\n",
       "      <th>tof_1_v19</th>\n",
       "      <th>tof_1_v20</th>\n",
       "      <th>tof_1_v21</th>\n",
       "      <th>tof_1_v22</th>\n",
       "      <th>tof_1_v23</th>\n",
       "      <th>tof_1_v24</th>\n",
       "      <th>tof_1_v25</th>\n",
       "      <th>tof_1_v26</th>\n",
       "      <th>tof_1_v27</th>\n",
       "      <th>tof_1_v28</th>\n",
       "      <th>tof_1_v29</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v15</th>\n",
       "      <th>tof_5_v16</th>\n",
       "      <th>tof_5_v17</th>\n",
       "      <th>tof_5_v18</th>\n",
       "      <th>tof_5_v19</th>\n",
       "      <th>tof_5_v20</th>\n",
       "      <th>tof_5_v21</th>\n",
       "      <th>tof_5_v22</th>\n",
       "      <th>tof_5_v23</th>\n",
       "      <th>tof_5_v24</th>\n",
       "      <th>tof_5_v25</th>\n",
       "      <th>tof_5_v26</th>\n",
       "      <th>tof_5_v27</th>\n",
       "      <th>tof_5_v28</th>\n",
       "      <th>tof_5_v29</th>\n",
       "      <th>tof_5_v30</th>\n",
       "      <th>tof_5_v31</th>\n",
       "      <th>tof_5_v32</th>\n",
       "      <th>tof_5_v33</th>\n",
       "      <th>tof_5_v34</th>\n",
       "      <th>tof_5_v35</th>\n",
       "      <th>tof_5_v36</th>\n",
       "      <th>tof_5_v37</th>\n",
       "      <th>tof_5_v38</th>\n",
       "      <th>tof_5_v39</th>\n",
       "      <th>tof_5_v40</th>\n",
       "      <th>tof_5_v41</th>\n",
       "      <th>tof_5_v42</th>\n",
       "      <th>tof_5_v43</th>\n",
       "      <th>tof_5_v44</th>\n",
       "      <th>tof_5_v45</th>\n",
       "      <th>tof_5_v46</th>\n",
       "      <th>tof_5_v47</th>\n",
       "      <th>tof_5_v48</th>\n",
       "      <th>tof_5_v49</th>\n",
       "      <th>tof_5_v50</th>\n",
       "      <th>tof_5_v51</th>\n",
       "      <th>tof_5_v52</th>\n",
       "      <th>tof_5_v53</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SEQ_000007_000000</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.683594</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.447327</td>\n",
       "      <td>-0.809753</td>\n",
       "      <td>28.943842</td>\n",
       "      <td>31.822186</td>\n",
       "      <td>29.553024</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>28.310535</td>\n",
       "      <td>131.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>-0.340271</td>\n",
       "      <td>-0.428650</td>\n",
       "      <td>-0.824524</td>\n",
       "      <td>29.340816</td>\n",
       "      <td>31.874645</td>\n",
       "      <td>29.791740</td>\n",
       "      <td>28.663383</td>\n",
       "      <td>28.406172</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             row_id  sequence_type sequence_id  sequence_counter  \\\n",
       "0      0  SEQ_000007_000000              1  SEQ_000007                 0   \n",
       "1      1  SEQ_000007_000001              1  SEQ_000007                 1   \n",
       "\n",
       "       subject       phase             gesture     acc_x     acc_y     acc_z  \\\n",
       "0  SUBJ_059520  Transition  Cheek - pinch skin  6.683594  6.214844  3.355469   \n",
       "1  SUBJ_059520  Transition  Cheek - pinch skin  6.949219  6.214844  3.125000   \n",
       "\n",
       "      rot_w     rot_x     rot_y     rot_z      thm_1      thm_2      thm_3  \\\n",
       "0  0.134399 -0.355164 -0.447327 -0.809753  28.943842  31.822186  29.553024   \n",
       "1  0.143494 -0.340271 -0.428650 -0.824524  29.340816  31.874645  29.791740   \n",
       "\n",
       "       thm_4      thm_5  tof_1_v0  tof_1_v1  tof_1_v2  tof_1_v3  tof_1_v4  \\\n",
       "0  28.592863  28.310535     131.0     134.0     132.0     135.0      98.0   \n",
       "1  28.663383  28.406172     130.0     138.0     131.0     135.0     101.0   \n",
       "\n",
       "   tof_1_v5  tof_1_v6  tof_1_v7  tof_1_v8  tof_1_v9  tof_1_v10  tof_1_v11  \\\n",
       "0      74.0      64.0      60.0      -1.0      -1.0      152.0      153.0   \n",
       "1      76.0      66.0      61.0      -1.0      -1.0      156.0      155.0   \n",
       "\n",
       "   tof_1_v12  tof_1_v13  tof_1_v14  tof_1_v15  tof_1_v16  tof_1_v17  \\\n",
       "0      141.0       89.0       68.0       63.0       -1.0       -1.0   \n",
       "1      141.0       93.0       74.0       64.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v18  tof_1_v19  tof_1_v20  tof_1_v21  tof_1_v22  tof_1_v23  \\\n",
       "0       -1.0       -1.0      169.0      118.0       86.0       73.0   \n",
       "1       -1.0       -1.0      165.0      116.0       86.0       75.0   \n",
       "\n",
       "   tof_1_v24  tof_1_v25  tof_1_v26  tof_1_v27  tof_1_v28  tof_1_v29  ...  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0      147.0  ...   \n",
       "1      130.0       -1.0       -1.0       -1.0       -1.0      142.0  ...   \n",
       "\n",
       "   tof_5_v15  tof_5_v16  tof_5_v17  tof_5_v18  tof_5_v19  tof_5_v20  \\\n",
       "0      119.0      135.0      156.0      166.0       -1.0       -1.0   \n",
       "1      122.0      138.0      157.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v21  tof_5_v22  tof_5_v23  tof_5_v24  tof_5_v25  tof_5_v26  \\\n",
       "0      155.0      137.0      112.0      148.0      163.0      164.0   \n",
       "1      155.0      133.0      117.0      145.0      170.0      163.0   \n",
       "\n",
       "   tof_5_v27  tof_5_v28  tof_5_v29  tof_5_v30  tof_5_v31  tof_5_v32  \\\n",
       "0      153.0      133.0      131.0      121.0      118.0      134.0   \n",
       "1      157.0      139.0      127.0      126.0      121.0      136.0   \n",
       "\n",
       "   tof_5_v33  tof_5_v34  tof_5_v35  tof_5_v36  tof_5_v37  tof_5_v38  \\\n",
       "0      134.0      128.0      121.0      119.0      121.0      129.0   \n",
       "1      142.0      133.0      127.0      123.0      127.0      134.0   \n",
       "\n",
       "   tof_5_v39  tof_5_v40  tof_5_v41  tof_5_v42  tof_5_v43  tof_5_v44  \\\n",
       "0       -1.0      113.0      124.0      122.0      131.0       -1.0   \n",
       "1       -1.0      116.0      122.0      123.0      126.0       -1.0   \n",
       "\n",
       "   tof_5_v45  tof_5_v46  tof_5_v47  tof_5_v48  tof_5_v49  tof_5_v50  \\\n",
       "0       -1.0       -1.0       -1.0      120.0      127.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0      122.0      129.0       -1.0   \n",
       "\n",
       "   tof_5_v51  tof_5_v52  tof_5_v53  tof_5_v54  tof_5_v55  tof_5_v56  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  tof_5_v62  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v63  target  \n",
       "0       -1.0       1  \n",
       "1       -1.0       1  \n",
       "\n",
       "[2 rows x 341 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfd062",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "071e662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0d428e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    159\n",
       "1.0     61\n",
       "2.0    105\n",
       "3.0     68\n",
       "4.0    107\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>phase</th>\n",
       "      <th>gesture</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>thm_2</th>\n",
       "      <th>thm_3</th>\n",
       "      <th>thm_4</th>\n",
       "      <th>thm_5</th>\n",
       "      <th>tof_1_v0</th>\n",
       "      <th>tof_1_v1</th>\n",
       "      <th>tof_1_v2</th>\n",
       "      <th>tof_1_v3</th>\n",
       "      <th>tof_1_v4</th>\n",
       "      <th>tof_1_v5</th>\n",
       "      <th>tof_1_v6</th>\n",
       "      <th>tof_1_v7</th>\n",
       "      <th>tof_1_v8</th>\n",
       "      <th>tof_1_v9</th>\n",
       "      <th>tof_1_v10</th>\n",
       "      <th>tof_1_v11</th>\n",
       "      <th>tof_1_v12</th>\n",
       "      <th>tof_1_v13</th>\n",
       "      <th>tof_1_v14</th>\n",
       "      <th>tof_1_v15</th>\n",
       "      <th>tof_1_v16</th>\n",
       "      <th>tof_1_v17</th>\n",
       "      <th>tof_1_v18</th>\n",
       "      <th>tof_1_v19</th>\n",
       "      <th>tof_1_v20</th>\n",
       "      <th>tof_1_v21</th>\n",
       "      <th>tof_1_v22</th>\n",
       "      <th>tof_1_v23</th>\n",
       "      <th>tof_1_v24</th>\n",
       "      <th>tof_1_v25</th>\n",
       "      <th>tof_1_v26</th>\n",
       "      <th>tof_1_v27</th>\n",
       "      <th>tof_1_v28</th>\n",
       "      <th>tof_1_v29</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v16</th>\n",
       "      <th>tof_5_v17</th>\n",
       "      <th>tof_5_v18</th>\n",
       "      <th>tof_5_v19</th>\n",
       "      <th>tof_5_v20</th>\n",
       "      <th>tof_5_v21</th>\n",
       "      <th>tof_5_v22</th>\n",
       "      <th>tof_5_v23</th>\n",
       "      <th>tof_5_v24</th>\n",
       "      <th>tof_5_v25</th>\n",
       "      <th>tof_5_v26</th>\n",
       "      <th>tof_5_v27</th>\n",
       "      <th>tof_5_v28</th>\n",
       "      <th>tof_5_v29</th>\n",
       "      <th>tof_5_v30</th>\n",
       "      <th>tof_5_v31</th>\n",
       "      <th>tof_5_v32</th>\n",
       "      <th>tof_5_v33</th>\n",
       "      <th>tof_5_v34</th>\n",
       "      <th>tof_5_v35</th>\n",
       "      <th>tof_5_v36</th>\n",
       "      <th>tof_5_v37</th>\n",
       "      <th>tof_5_v38</th>\n",
       "      <th>tof_5_v39</th>\n",
       "      <th>tof_5_v40</th>\n",
       "      <th>tof_5_v41</th>\n",
       "      <th>tof_5_v42</th>\n",
       "      <th>tof_5_v43</th>\n",
       "      <th>tof_5_v44</th>\n",
       "      <th>tof_5_v45</th>\n",
       "      <th>tof_5_v46</th>\n",
       "      <th>tof_5_v47</th>\n",
       "      <th>tof_5_v48</th>\n",
       "      <th>tof_5_v49</th>\n",
       "      <th>tof_5_v50</th>\n",
       "      <th>tof_5_v51</th>\n",
       "      <th>tof_5_v52</th>\n",
       "      <th>tof_5_v53</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SEQ_000007_000000</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.683594</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.447327</td>\n",
       "      <td>-0.809753</td>\n",
       "      <td>28.943842</td>\n",
       "      <td>31.822186</td>\n",
       "      <td>29.553024</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>28.310535</td>\n",
       "      <td>131.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>-0.340271</td>\n",
       "      <td>-0.428650</td>\n",
       "      <td>-0.824524</td>\n",
       "      <td>29.340816</td>\n",
       "      <td>31.874645</td>\n",
       "      <td>29.791740</td>\n",
       "      <td>28.663383</td>\n",
       "      <td>28.406172</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SEQ_000007_000002</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.722656</td>\n",
       "      <td>5.410156</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.219055</td>\n",
       "      <td>-0.274231</td>\n",
       "      <td>-0.356934</td>\n",
       "      <td>-0.865662</td>\n",
       "      <td>30.339359</td>\n",
       "      <td>30.935045</td>\n",
       "      <td>30.090014</td>\n",
       "      <td>28.796087</td>\n",
       "      <td>28.529778</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SEQ_000007_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.601562</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>6.457031</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.238159</td>\n",
       "      <td>-0.885986</td>\n",
       "      <td>30.543730</td>\n",
       "      <td>27.044001</td>\n",
       "      <td>29.310717</td>\n",
       "      <td>29.018711</td>\n",
       "      <td>27.402010</td>\n",
       "      <td>143.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SEQ_000007_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.566406</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>9.632812</td>\n",
       "      <td>0.333557</td>\n",
       "      <td>-0.218628</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>-0.914856</td>\n",
       "      <td>29.317265</td>\n",
       "      <td>25.270855</td>\n",
       "      <td>26.808746</td>\n",
       "      <td>29.408604</td>\n",
       "      <td>27.357603</td>\n",
       "      <td>178.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             row_id  sequence_type sequence_id  sequence_counter  \\\n",
       "0      0  SEQ_000007_000000              1  SEQ_000007                 0   \n",
       "1      1  SEQ_000007_000001              1  SEQ_000007                 1   \n",
       "2      2  SEQ_000007_000002              1  SEQ_000007                 2   \n",
       "3      3  SEQ_000007_000003              1  SEQ_000007                 3   \n",
       "4      4  SEQ_000007_000004              1  SEQ_000007                 4   \n",
       "\n",
       "       subject       phase             gesture     acc_x     acc_y     acc_z  \\\n",
       "0  SUBJ_059520  Transition  Cheek - pinch skin  6.683594  6.214844  3.355469   \n",
       "1  SUBJ_059520  Transition  Cheek - pinch skin  6.949219  6.214844  3.125000   \n",
       "2  SUBJ_059520  Transition  Cheek - pinch skin  5.722656  5.410156  5.421875   \n",
       "3  SUBJ_059520  Transition  Cheek - pinch skin  6.601562  3.531250  6.457031   \n",
       "4  SUBJ_059520  Transition  Cheek - pinch skin  5.566406  0.277344  9.632812   \n",
       "\n",
       "      rot_w     rot_x     rot_y     rot_z      thm_1      thm_2      thm_3  \\\n",
       "0  0.134399 -0.355164 -0.447327 -0.809753  28.943842  31.822186  29.553024   \n",
       "1  0.143494 -0.340271 -0.428650 -0.824524  29.340816  31.874645  29.791740   \n",
       "2  0.219055 -0.274231 -0.356934 -0.865662  30.339359  30.935045  30.090014   \n",
       "3  0.297546 -0.264160 -0.238159 -0.885986  30.543730  27.044001  29.310717   \n",
       "4  0.333557 -0.218628 -0.063538 -0.914856  29.317265  25.270855  26.808746   \n",
       "\n",
       "       thm_4      thm_5  tof_1_v0  tof_1_v1  tof_1_v2  tof_1_v3  tof_1_v4  \\\n",
       "0  28.592863  28.310535     131.0     134.0     132.0     135.0      98.0   \n",
       "1  28.663383  28.406172     130.0     138.0     131.0     135.0     101.0   \n",
       "2  28.796087  28.529778     137.0     136.0     147.0     109.0      90.0   \n",
       "3  29.018711  27.402010     143.0     147.0     170.0     127.0     109.0   \n",
       "4  29.408604  27.357603     178.0     191.0     183.0     157.0     146.0   \n",
       "\n",
       "   tof_1_v5  tof_1_v6  tof_1_v7  tof_1_v8  tof_1_v9  tof_1_v10  tof_1_v11  \\\n",
       "0      74.0      64.0      60.0      -1.0      -1.0      152.0      153.0   \n",
       "1      76.0      66.0      61.0      -1.0      -1.0      156.0      155.0   \n",
       "2      81.0      74.0      74.0      -1.0     164.0      165.0      146.0   \n",
       "3      98.0      95.0      95.0      -1.0     177.0      189.0      177.0   \n",
       "4     139.0     143.0     148.0      -1.0      -1.0      236.0      238.0   \n",
       "\n",
       "   tof_1_v12  tof_1_v13  tof_1_v14  tof_1_v15  tof_1_v16  tof_1_v17  \\\n",
       "0      141.0       89.0       68.0       63.0       -1.0       -1.0   \n",
       "1      141.0       93.0       74.0       64.0       -1.0       -1.0   \n",
       "2      106.0       94.0       77.0       77.0       -1.0       -1.0   \n",
       "3      136.0      121.0      107.0      104.0       -1.0       -1.0   \n",
       "4      208.0      200.0      185.0      190.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v18  tof_1_v19  tof_1_v20  tof_1_v21  tof_1_v22  tof_1_v23  \\\n",
       "0       -1.0       -1.0      169.0      118.0       86.0       73.0   \n",
       "1       -1.0       -1.0      165.0      116.0       86.0       75.0   \n",
       "2       -1.0      180.0      140.0      118.0      103.0       92.0   \n",
       "3       -1.0      202.0      171.0      160.0      141.0      135.0   \n",
       "4       -1.0      210.0      246.0      225.0      228.0      202.0   \n",
       "\n",
       "   tof_1_v24  tof_1_v25  tof_1_v26  tof_1_v27  tof_1_v28  tof_1_v29  ...  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0      147.0  ...   \n",
       "1      130.0       -1.0       -1.0       -1.0       -1.0      142.0  ...   \n",
       "2       -1.0       -1.0       -1.0       -1.0       -1.0      155.0  ...   \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0      197.0  ...   \n",
       "4      149.0      206.0      219.0      219.0      225.0      218.0  ...   \n",
       "\n",
       "   tof_5_v16  tof_5_v17  tof_5_v18  tof_5_v19  tof_5_v20  tof_5_v21  \\\n",
       "0      135.0      156.0      166.0       -1.0       -1.0      155.0   \n",
       "1      138.0      157.0       -1.0       -1.0       -1.0      155.0   \n",
       "2      138.0      164.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      162.0      181.0       -1.0       -1.0       -1.0      152.0   \n",
       "4      197.0       -1.0       -1.0      219.0      192.0       -1.0   \n",
       "\n",
       "   tof_5_v22  tof_5_v23  tof_5_v24  tof_5_v25  tof_5_v26  tof_5_v27  \\\n",
       "0      137.0      112.0      148.0      163.0      164.0      153.0   \n",
       "1      133.0      117.0      145.0      170.0      163.0      157.0   \n",
       "2      145.0      120.0      151.0      165.0       -1.0       -1.0   \n",
       "3      134.0       -1.0      148.0      187.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0      204.0       -1.0       -1.0      212.0   \n",
       "\n",
       "   tof_5_v28  tof_5_v29  tof_5_v30  tof_5_v31  tof_5_v32  tof_5_v33  \\\n",
       "0      133.0      131.0      121.0      118.0      134.0      134.0   \n",
       "1      139.0      127.0      126.0      121.0      136.0      142.0   \n",
       "2       -1.0      151.0      138.0      127.0      151.0      187.0   \n",
       "3      149.0      142.0      135.0       -1.0      159.0      181.0   \n",
       "4      181.0       -1.0       -1.0       -1.0      184.0       -1.0   \n",
       "\n",
       "   tof_5_v34  tof_5_v35  tof_5_v36  tof_5_v37  tof_5_v38  tof_5_v39  \\\n",
       "0      128.0      121.0      119.0      121.0      129.0       -1.0   \n",
       "1      133.0      127.0      123.0      127.0      134.0       -1.0   \n",
       "2       -1.0      156.0      136.0      135.0      134.0       -1.0   \n",
       "3      150.0      135.0      129.0      139.0       -1.0       -1.0   \n",
       "4      179.0      162.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v40  tof_5_v41  tof_5_v42  tof_5_v43  tof_5_v44  tof_5_v45  \\\n",
       "0      113.0      124.0      122.0      131.0       -1.0       -1.0   \n",
       "1      116.0      122.0      123.0      126.0       -1.0       -1.0   \n",
       "2      133.0      142.0      131.0      130.0      132.0      136.0   \n",
       "3      141.0      136.0      120.0      122.0      132.0       -1.0   \n",
       "4      169.0      171.0      145.0      140.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v46  tof_5_v47  tof_5_v48  tof_5_v49  tof_5_v50  tof_5_v51  \\\n",
       "0       -1.0       -1.0      120.0      127.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0      122.0      129.0       -1.0       -1.0   \n",
       "2       -1.0       -1.0      112.0      121.0      123.0      125.0   \n",
       "3       -1.0       -1.0      107.0      112.0      115.0      140.0   \n",
       "4       -1.0       -1.0      132.0      125.0      131.0       -1.0   \n",
       "\n",
       "   tof_5_v52  tof_5_v53  tof_5_v54  tof_5_v55  tof_5_v56  tof_5_v57  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2       -1.0       -1.0       -1.0       -1.0      112.0      119.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0      101.0      111.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0      101.0      109.0   \n",
       "\n",
       "   tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  tof_5_v62  tof_5_v63  target  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0       1   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0       1   \n",
       "2       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0       1   \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0       1   \n",
       "4      125.0       -1.0       -1.0       -1.0       -1.0       -1.0       1   \n",
       "\n",
       "   fold  \n",
       "0   2.0  \n",
       "1   2.0  \n",
       "2   2.0  \n",
       "3   2.0  \n",
       "4   2.0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedGroupKFold\n",
    "# 正解ラベルの割合が同じになるようにデータを分割するのがStratified K-Fold\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=config.FOLDS)\n",
    "for fold, (train_index, valid_index) in enumerate(sgkf.split(df_train, df_train.target, df_train.subject)):\n",
    "    df_train.loc[valid_index, \"fold\"] = int(fold)\n",
    "    \n",
    "display(df_train.groupby('fold').size()), sep()\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72c5395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 371.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def min_max_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    min_vals = np.nanmin(arr, axis=0)\n",
    "    max_vals = np.nanmax(arr, axis=0)\n",
    "    ranges = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "    scaled = (arr - min_vals) / ranges\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def standard_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    means = np.nanmean(arr, axis=0)\n",
    "    stds = np.nanstd(arr, axis=0)\n",
    "    stds = np.where(stds == 0, 1, stds)  # Prevent division by zero for constant columns\n",
    "    scaled = (arr - means) / stds\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def pad_or_truncate(\n",
    "    arr: np.ndarray,\n",
    "    max_length: int = 200,\n",
    "    pad_value: int = 0,\n",
    "    mode: str = \"random\"  # \"regular\" or \"random\"\n",
    ") -> np.ndarray:\n",
    "    L, D = arr.shape\n",
    "\n",
    "    if L > max_length:\n",
    "        return arr[:max_length, :]\n",
    "\n",
    "    elif L < max_length:\n",
    "        if mode == \"regular\":\n",
    "            padding = np.full((max_length - L, D), pad_value)\n",
    "            return np.vstack((arr, padding))\n",
    "        \n",
    "        elif mode == \"random\":\n",
    "            total_padding = max_length - L\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "\n",
    "            start_padding = np.full((pad_start, D), pad_value)\n",
    "            end_padding = np.full((pad_end, D), pad_value)\n",
    "\n",
    "            return np.vstack((start_padding, arr, end_padding))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}. Use 'regular' or 'random'.\")\n",
    "\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "all_X, all_y, all_y_hard = [], [], []\n",
    "\n",
    "for sequence_id in tqdm(df_train.sequence_id.unique()):\n",
    "    # Iterate by sequence id: the batch of sensor data\n",
    "    ds = df_train[df_train[\"sequence_id\"] == sequence_id]\n",
    "    X = ds[imu_cols].values\n",
    "    X = pad_or_truncate(X)\n",
    "    y = ds.target.values[0]\n",
    "    y_hard = ds.sequence_type.values[0]\n",
    "    X = np.concatenate((standard_scale(X[:, 0:3]), X[:, 3:]), axis=1)\n",
    "    X = np.where(np.isnan(X), 0.0, X)  # fill NaNs\n",
    "    all_X.append(X)\n",
    "    all_y.append(y)\n",
    "    all_y_hard.append(y_hard)\n",
    "\n",
    "all_X = np.array(all_X)\n",
    "all_y = np.array(all_y)\n",
    "all_y_hard = np.array(all_y_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36515bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, config, df: pd.DataFrame, X: np.ndarray, y: np.ndarray, y_hard: np.ndarray\n",
    "    ): \n",
    "        \n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.y_hard = y_hard\n",
    "        self.indexes = self.df.sequence_id.unique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        sequence_id = self.indexes[index]\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        y_hard = self.y_hard[index]\n",
    "        output = {\n",
    "            \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(y, dtype=torch.long),\n",
    "            \"y_hard\": torch.tensor(y_hard, dtype=torch.float32),\n",
    "            \"sequence_id\": sequence_id\n",
    "        }\n",
    "        return output     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbaed5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X shape: torch.Size([200, 7])\n",
      "Sample y: tensor(1)\n",
      "Sample y_hard: tensor(1.)\n",
      "Sequence ID: SEQ_000007\n",
      "Length of train_dataset: 7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(config, df_train, all_X, all_y, all_y_hard)\n",
    "\n",
    "#### Print out\n",
    "sample = train_dataset[0]\n",
    "\n",
    "sample_X = sample[\"X\"]\n",
    "sample_y = sample[\"y\"]\n",
    "sample_y_hard = sample[\"y_hard\"]\n",
    "sequence_id = sample[\"sequence_id\"]\n",
    "\n",
    "print(\"Sample X shape:\", sample_X.shape)\n",
    "print(\"Sample y:\", sample_y)\n",
    "print(\"Sample y_hard:\", sample_y_hard)\n",
    "print(\"Sequence ID:\", sequence_id)\n",
    "print(\"Length of train_dataset:\", len(train_dataset))\n",
    "#### END\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE_TRAIN,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    ")\n",
    "idx = np.random.choice(range(0, len(train_dataset)))\n",
    "cols = imu_cols\n",
    "X = train_dataset[idx][\"X\"]\n",
    "y = train_dataset[idx][\"y\"].item()\n",
    "y_hard = train_dataset[idx][\"y_hard\"].item()\n",
    "target = num_to_label[y]\n",
    "sequence_id = train_dataset[idx][\"sequence_id\"]\n",
    "N = X.shape[0]\n",
    "df = pd.DataFrame(X, columns=cols)\n",
    "df['step'] = range(N)\n",
    "df_melted = df.melt(id_vars='step', var_name='sequence', value_name='value')\n",
    "\n",
    "fig = px.line(\n",
    "    df_melted,\n",
    "    x='step',\n",
    "    y='value',\n",
    "    color='sequence',\n",
    "    title=f\"Sequences for {sequence_id} | Target: {target}\",\n",
    "    template='plotly_dark',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "print(len(train_loader))\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb7741e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2829226\n"
     ]
    }
   ],
   "source": [
    "class Wave_Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, dilation_rates: int, kernel_size: int = 3):\n",
    "        \"\"\"\n",
    "        WaveNet building block.\n",
    "        :param in_channels: number of input channels.\n",
    "        :param out_channels: number of output channels.\n",
    "        :param dilation_rates: how many levels of dilations are used.\n",
    "        :param kernel_size: size of the convolving kernel.\n",
    "        \"\"\"\n",
    "        super(Wave_Block, self).__init__()\n",
    "        self.num_rates = dilation_rates\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        # First conv: (B, in_channels, L) -> (B, out_channels, L)\n",
    "        self.convs.append(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        dilation_rates = [2 ** i for i in range(dilation_rates)]\n",
    "        for dilation_rate in dilation_rates:\n",
    "            # Filter conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.filter_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    out_channels, out_channels, kernel_size=kernel_size,\n",
    "                    padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate)\n",
    "            )\n",
    "            # Gate conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.gate_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    out_channels, out_channels, kernel_size=kernel_size,\n",
    "                    padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate)\n",
    "            )\n",
    "            # Residual conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.convs.append(nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=True))\n",
    "        \n",
    "        for i in range(len(self.convs)):\n",
    "            nn.init.xavier_uniform_(self.convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.convs[i].bias)\n",
    "\n",
    "        for i in range(len(self.filter_convs)):\n",
    "            nn.init.xavier_uniform_(self.filter_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.filter_convs[i].bias)\n",
    "\n",
    "        for i in range(len(self.gate_convs)):\n",
    "            nn.init.xavier_uniform_(self.gate_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.gate_convs[i].bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (B, in_channels, L)\n",
    "        x = self.convs[0](x)  # (B, in_channels, L) -> (B, out_channels, L)\n",
    "        res = x  # res: (B, out_channels, L)\n",
    "        for i in range(self.num_rates):\n",
    "            tanh_out = torch.tanh(self.filter_convs[i](x))  # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            sigmoid_out = torch.sigmoid(self.gate_convs[i](x)) # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            x = tanh_out * sigmoid_out  # (B, out_channels, L) * (B, out_channels, L) -> (B, out_channels, L)\n",
    "            x = self.convs[i + 1](x) # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            res = res + x  # (B, out_channels, L) + (B, out_channels, L) -> (B, out_channels, L)\n",
    "        return res  # (B, out_channels, L)\n",
    "    \n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, input_channels: int = 1, kernel_size: int = 3):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                Wave_Block(input_channels, 32, 12, kernel_size),   # (B, input_channels, L) -> (B, 8, L)\n",
    "                Wave_Block(32, 64, 8, kernel_size),                # (B, 8, L) -> (B, 16, L)\n",
    "                Wave_Block(64, 128, 4, kernel_size),               # (B, 16, L) -> (B, 32, L)\n",
    "                Wave_Block(128, 256, 1, kernel_size),                # (B, 32, L) -> (B, 64, L)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, L, input_channels) - typical input format\n",
    "        x = x.permute(0, 2, 1)  # (B, L, input_channels) -> (B, input_channels, L)\n",
    "        output = self.model(x)  # (B, input_channels, L) -> (B, 64, L)\n",
    "        return output  # (B, 64, L)\n",
    "\n",
    "\n",
    "class TemporalAttentionPooling(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim=64):\n",
    "        super(TemporalAttentionPooling, self).__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, hidden_dim, kernel_size=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, L)\n",
    "        returns: (B, C)\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        attn_scores = self.attn(x)  # (B, 1, L)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (B, 1, L)\n",
    "\n",
    "        # Weighted sum over time\n",
    "        weighted = x * attn_weights  # (B, C, L)\n",
    "        pooled = weighted.sum(dim=-1)  # (B, C)\n",
    "\n",
    "        return pooled\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.wavenet1 = WaveNet(input_channels=3)  # WaveNet: (B, input_channels, L) -> (B, 64, L)\n",
    "        self.wavenet2 = WaveNet(input_channels=4)  # WaveNet: (B, input_channels, L) -> (B, 64, L)\n",
    "        self.config = config\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)  # (B, 64, L) -> (B, 64, 1)\n",
    "        self.dropout = 0.2\n",
    "        self.head_1 = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512, 256), # (B, 64) -> (B, 64)\n",
    "            nn.BatchNorm1d(256),  # (B, 64) -> (B, 64)\n",
    "            nn.ReLU(),  # (B, 64) -> (B, 64)\n",
    "            nn.Dropout(self.dropout),  # (B, 64) -> (B, 64)\n",
    "            nn.Linear(256, num_classes)  # (B, 64) -> (B, num_classes)\n",
    "        )\n",
    "        self.head_2 = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512, 256), # (B, 64) -> (B, 64)\n",
    "            nn.BatchNorm1d(256),  # (B, 64) -> (B, 64)\n",
    "            nn.ReLU(),  # (B, 64) -> (B, 64)\n",
    "            nn.Dropout(self.dropout),  # (B, 64) -> (B, 64)\n",
    "            nn.Linear(256, 1)  # (B, 64) -> (B, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \"\"\"\n",
    "        # x: (B, L, input_channels) - typical input format\n",
    "        x1 = self.wavenet1(x[:, :, 0:3])  # (B, L, input_channels) -> (B, 64, L)\n",
    "        x1 = self.global_avg_pooling(x1)  # (B, 64, L) -> (B, 64, 1)\n",
    "        x2 = self.wavenet2(x[:, :, 3:])  # (B, L, input_channels) -> (B, 64, L)\n",
    "        x2 = self.global_avg_pooling(x2)  # (B, 64, L) -> (B, 64, 1)\n",
    "        y = torch.concatenate([x1, x2], axis=1) # (B, 128)\n",
    "        z1 = self.head_1(y)  # (B, 64) -> (B, num_classes)\n",
    "        z2 = self.head_2(y)  # (B, 64) -> (B, num_classes)\n",
    "        return z1, z2  # (B, num_classes)\n",
    "\n",
    "model = CustomModel(num_classes=9)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b3e3fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum LR: 0.0007501000000000001 | Minimum LR: 4.0000000000000003e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHACAYAAACMB0PKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPhdJREFUeJzt3QlYVXX+x/EPOyqLCyIuuOUubuCSqZVpi2mllW2mtrqkZdvMZE3ZbsvY1JSaVn/NrUxLKyd1ysas1BRwwX0XFRU3ZFEBwf/zOwYDqSkKnHPvfb+e5zweLnD5Qsb9+Dvf3/d4nTp16pQAAAAcyNvuAgAAAM6FoAIAAByLoAIAAByLoAIAAByLoAIAAByLoAIAAByLoAIAAByLoAIAAByLoAIAAByLoAIAABzLbYLKokWLdNNNN6latWry8vLS7NmzS+1rv/HGG9bXfPzxx0vtawIA4AncJqhkZGSoRYsWGj16dKl+3eXLl2vcuHFq3rx5qX5dAAA8gdsElW7duunVV19Vr169zvr+zMxMPf3006pevbrKlSundu3aaeHChZf0NdPT09WnTx999NFHqlChwiU9FwAAcOOgcj5Dhw7VkiVL9Pnnn2v16tXq3bu3brjhBm3evPmin3PIkCHq3r27unbtWqy1AgCA03zlARITEzVhwgTrT9PDYpjVlXnz5lmPv/7660V+ThN44uPjrUs/AACgZHjEikpCQoJycnLUoEEDBQUF5R8//fSTtm7dan3Mhg0brIbYPzueeeYZ62N37dqlYcOGaerUqQoMDLT5uwMAwH15xIqK6SXx8fFRXFyc9WdBJrAYdevW1fr16//0eSpVqmT9aZ4nOTlZ0dHR+e8zQcjsPPrggw+sfpg/fh0AAFB0HhFUWrVqZQUJEy46dep01o/x9/dXo0aNLuj5unTpYq3SFHT//fdbn/+3v/2NkAIAQDHxdadVky1btuS/vX37dq1cuVIVK1a0LvmY3Tn9+vXTqFGjrOBy4MABLViwwNpWbBpiiyI4OFhRUVGFHjM7icyKyx8fBwAAF89tgkpsbKw6d+6c//aTTz5p/dm/f39NnDjRapo125efeuop7dmzR2FhYbr88svVo0cPG6sGAAB/xuvUqVOn/vQjAAAAbOIRu34AAIBrIqgAAADHcukeldzcXCUlJVnNrWbOCQAAcD7TdZKWlmYNYfX29nbfoGJCSmRkpN1lAACAi2AGqNaoUcN9g4pZScn7RkNCQuwuBwAAXIDU1FRroSHvddxtg0re5R4TUggqAAC4lgtp26CZFgAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZBBQAAOBZB5RyWbD2ktBPZdpcBAIBHI6icxbTfEtXn46V6Yvoq5eaesrscAAA8FkHlLJpWC5Gvj7d+WL9f7y3YbHc5AAB4LILKWbSILK/XekZZ5yaozF+7z+6SAADwSASVc+jdOlL3XVHbOn9y+kpt3p9md0kAAHgcgsqfeK57Y11et6IysnL08KRYHT1Ocy0AAKWJoPIn/Hy8NfqeaFUvX0Y7Dh3TsM9XKIfmWgAASg1B5TwqBQVoXN8YBfp5a+HGAxr1n412lwQAgMcgqFyAqOqhevO25tb5mIVbNWd1kt0lAQDgEQgqF+iWltU18Mq61vlfZqzWuqRUu0sCAMDtEVSK4K83NFKn+mE6np2jAZNjdSQjy+6SAABwawSVIvDx9tL7d7dSzYpltfvIcQ39LF4nc3LtLgsAALdFUCmi8mX9Nb5fjMr6++jXLYf0xtwNdpcEAIDbIqhchEYRIRrVu4V1/vEv2zVrxW67SwIAwC0RVC5St2ZVNbRzPev8mS8TlLD7qN0lAQDgdggql+DJaxuoS6NwZZ7M1cDJsTqYnml3SQAAuBWCyiXw9vbSP+9qqbqVyynp6Ak9MjVe2TTXAgBQbAgqlygk0E/j+7ZWUICvlm0/rFfmrLO7JAAA3AZBpRjUCw/Su3e2tM4nLdmp6csT7S4JAAC3QFApJl2bVLF6VoznZ69VfOIRu0sCAMDl2RpUateuLS8vrzOOIUOGyBWZXUDXN62irJxcDZocp+TUE3aXBACAS7M1qCxfvlx79+7NP77//nvr8d69e8tVm2tH3dFSDaoEKTktU4OmxCnzZI7dZQEA4LJsDSqVK1dWRERE/jFnzhxddtlluuqqq+SqTFOtaa4NCfRVfGKKRny9VqdOnbK7LAAAXJJjelSysrI0ZcoUPfDAA9bln7PJzMxUampqocOJaoeV0/v3RMvbS/p8+S5N/Y3mWgAAXDqozJ49WykpKbrvvvvO+TEjR45UaGho/hEZGSmnuqpBZetuy8aL36y1ti4DAICi8TrlkOsS119/vfz9/fXtt9+e82PMioo58pgVFRNWjh49qpCQEDmN+dE++tkKzVm9V2FB/vpmaEdVK1/G7rIAALCVef02Cw4X8vrtiBWVnTt36ocfftBDDz30px8XEBBgfUMFDyczl7Deur25GlcN0cH0LA2cHKcT2TTXAgBwoRwRVCZMmKDw8HB1795d7qasv2mujVGFsn5K2HNUz85KoLkWAABXCSq5ublWUOnfv798fX3ljiIrltXoe6Ll4+2lr+L3aMKvO+wuCQAAl2B7UDGXfBITE63dPu7sinpheu7Gxtb5a9+t1+ItB+0uCQAAx7M9qFx33XXWpZAGDU6Pn3dn93eorVujqysn95SGTIvXrsPH7C4JAABHsz2oeBLTXPt6r2ZqXiNUR45la8DkOB3PorkWAIBzIaiUskA/H314b4y1XXn93lT9ZeYqmmsBADgHgooNzCyVMX1i5OvtZc1YGbdom90lAQDgSAQVm7StU1Ejbm5qnb85b4MWbky2uyQAAByHoGKje9vV1F1tImWu/Dz22QrtOJhhd0kAADgKQcXm5tqXbmmq6JrllXripAZMjlV65km7ywIAwDEIKjYL8D3dXBseHKBN+9P11BcrlZtLcy0AAAZBxQHCQwL1Yd8Y+ft4a/7a/Rr93y12lwQAgCMQVBwiumYFvdozyjp/54dN+mHdfrtLAgDAdgQVB7mjTaT6ta9lNdc+Pn2ltiSn210SAAC2Iqg4zPM9mlhbl01T7YBJsUo9kW13SQAA2Iag4jB+Pt4a0ydaVUMDte1ghh7/nOZaAIDnIqg4UFhQgMb3ba0AX2/9uCFZ//xhk90lAQBgC4KKQzWrEao3bmtmnb//4xbNTdhrd0kAAJQ6goqD9WpVQw91rGOdPzVjlTbuS7O7JAAAShVBxeGe6dZIHepV0rGsHD08KVYpx7LsLgkAgFJDUHE4Xx9vfXB3tGpUKKPEw8f06GcrdDIn1+6yAAAoFQQVF1ChnL/VXFvGz0c/bz6ot+dvtLskAABKBUHFRTSpFqK3eze3zsct2qavV+6xuyQAAEocQcWF9GheTYOvvsw6/9uXq7Vmz1G7SwIAoEQRVFzM09c11NUNK+tEdq4GTo7TofRMu0sCAKDEEFRcjI+3l967q5XqhJXTnpTjGjpthbJprgUAuCmCigsKLeOn8X1jVM7fR0u2HdLr3623uyQAAEoEQcVF1a8SrHfubGmdT/h1h2bG7ba7JAAAih1BxYVd3zRCw7rUt86fnZWglbtS7C4JAIBiRVBxcSaodG1cRVknczVocpyS007YXRIAAMWGoOLivL299M87W+iyyuW0L/WEHpkSb4UWAADcAUHFDQQH+umjfq0VHOir2J1H9NK3a+0uCQCAYkFQcRN1KwfpX3e1kpeXNPW3RE37LdHukgAAuGQEFTfSuVG4NRDOGPHNGsXtPGx3SQAAXBKCipt55OrLdGOzCGXnnNKgKfHad5TmWgCA6yKouBkvLy+9fXsLNYoI1oG0TA2cEqcT2Tl2lwUAwEUhqLihcgG+Gt+3tTXBdtWuFD0/e41OnTpld1kAABQZQcVN1axUVh/c00reXtKMuN2atGSn3SUBAOB6QWXPnj269957ValSJZUpU0bNmjVTbGys3WW5hU71K2t4t8bW+ctz1mnJ1kN2lwQAgOsElSNHjqhDhw7y8/PT3LlztW7dOo0aNUoVKlSwsyy38lCnOurZsppyck9pyLR4647LAAC4Cl87v/ibb76pyMhITZgwIf+xOnXq2FmSWzbXvnFbc205kK41e1I1YFKsZg66QmX8fewuDQAAZ6+ofPPNN2rdurV69+6t8PBwtWrVSh999NE5Pz4zM1OpqamFDpxfoJ+PxvVtrUrl/LU2KVXDv1pNcy0AwCXYGlS2bdumsWPHqn79+po/f74GDx6sxx57TJ9++ulZP37kyJEKDQ3NP8xqDC5M9fJlNLpPtHy8vTR7ZZI++WW73SUBAHBeXqds/Ke1v7+/taKyePHi/MdMUFm+fLmWLFly1hUVc+QxKyomrBw9elQhISGlVrcr+3TxDo34Zq21G2jSA+3UsX6Y3SUBADxMamqqteBwIa/ftq6oVK1aVU2aNCn0WOPGjZWYePb71AQEBFjfUMEDRdOvfS31jqmh3FPS0M/ilXjomN0lAQDgzKBidvxs3Lix0GObNm1SrVq1bKvJE5prX+kZpRaR5ZVyLFsDJscqI/Ok3WUBAOC8oPLEE09o6dKlev3117VlyxZNmzZN48eP15AhQ+wsyzOaa++NUeXgAG3Yl6a/zFxFcy0AwJFsDSpt2rTRrFmz9NlnnykqKkqvvPKK3n33XfXp08fOsjxCRGigPrw3Wn4+XvouYZ/GLNxqd0kAADirmbY0m3Fwdp8tS9TwrxLk5SX9X/826two3O6SAABuLtVVmmlhv7vb1lSfdjVl4upjn6/QtgPpdpcEAEA+ggo04qamal2rgtJOnNSAyXFKO5Ftd0kAAFgIKpC/r7fG3ButiJBAbUlO1xPTVynX7F8GAMBmBBVYwoMDNa5vjBVafli/X+8t2Gx3SQAAEFTwP2a2yuu9mlnnJqjMX7vP7pIAAB6OoIJCbo+pofs71LbOn5y+Upv3p9ldEgDAgxFUcIZnb2ys9nUrKSMrRw9PitXR4zTXAgDsQVDBGfx8vPXBPa2sOy7vOHRMwz5foRyaawEANiCo4KwqBQVYzbWBft5auPGARv2n8D2ZAAAoDQQVnFNU9VC9eVtz69yM2J+zOsnukgAAHoaggj91S8vqGnhlXev8LzNWa11Sqt0lAQA8CEEF5/XXGxqpU/0wHc/O0YDJsTqSkWV3SQAAD0FQwXn5eHvp/btbqValstp95LiGfhavkzm5dpcFAPAABBVckPJl/TW+b2uV9ffRr1sO6Y25G+wuCQDgAQgquGANI4L1zh0trPOPf9muWSt2210SAMDNEVRQJDdEVdWj19Szzp/5MkEJu4/aXRIAwI0RVFBkT3RtoC6NwpV5MlcDJ8fqYHqm3SUBANwUQQVF5u3tpX/e1VJ1K5dT0tETemRqvLJprgUAlACCCi5KSKCf1VwbHOCrZdsP65U56+wuCQDghggquGj1woP07l0t5eUlTVqyU9OXJ9pdEgDAzRBUcEm6NK6iJ7s2sM6fn71W8YlH7C4JAOBGCCq4ZEM619MNTSOUlZOrQZPjlJx6wu6SAABugqCCYmmu/ccdLdSgSpCS0zI1aEqcMk/m2F0WAMANEFRQLIICfK3m2pBAX8UnpmjE12t16tQpu8sCALg4ggqKTe2wcnr/nmh5e0mfL9+lqb/RXAsAuDQEFRSrqxpUtu62bLz4zVpr6zIAABeLoIJiN/DKurqpRTWdzD2lR6bGKSnluN0lAQBcFEEFxc7Ly0tv3dZcTaqG6GB6lgZOjtOJbJprAQBFR1BBiSjj76NxfWNUoayfEvYc1bOzEmiuBQAUGUEFJSayYlmNvidaPt5e+ip+jyb8usPukgAALoagghJ1Rb0wPXdjY+v8te/Wa/GWg3aXBABwIQQVlLj7O9TWrdHVlZN7SkOmxWvX4WN2lwQAcBEEFZRKc+3rvZqpeY1QHTmWrQGT43Q8i+ZaAMD5EVRQKgL9fPThvTEKC/LX+r2p+svMVTTXAgCcHVRefPFF61/bBY9GjU4PC4P7qVa+jMbeGyNfby/NWb1X4xZts7skAIDD2b6i0rRpU+3duzf/+OWXX+wuCSWoTe2KevHmptb5m/M2aOHGZLtLAgA4mO1BxdfXVxEREflHWFiY3SWhhPVpV1N3t42UufLz2GcrtONght0lAQAcyvagsnnzZlWrVk1169ZVnz59lJh47hvZZWZmKjU1tdAB12Mu8ZlVleia5ZV64qQenhSr9MyTdpcFAHAgW4NKu3btNHHiRM2bN09jx47V9u3b1alTJ6WlpZ3140eOHKnQ0ND8IzIystRrRvEI8D3dXBseHKDNyel66ouVys2luRYAUJjXKQdtvUhJSVGtWrX0zjvv6MEHHzzrioo58pgVFRNWjh49qpCQkFKuFsUhPvGI7hq3VFk5uXrq2gZ6tEt9u0sCAJQw8/ptFhwu5PXb9ks/BZUvX14NGjTQli1bzvr+gIAA6xsqeMC1RdesoFd7Rlnn7/ywST+s2293SQAAB3FUUElPT9fWrVtVtWpVu0tBKbqjTaT6t69lNdc+Pn2ltiSn210SAMAhbA0qTz/9tH766Sft2LFDixcvVq9eveTj46O7777bzrJgg7/3aKK2dSpaTbUDJsUq9US23SUBADw9qOzevdsKJQ0bNtQdd9yhSpUqaenSpapcubKdZcEGfj7eGtMnWtVCA7XtYIYe/5zmWgCAw5ppS7IZB64hYfdR3f7hYmWezNWj19TTU9c1tLskAEAxc9lmWqBZjVC9cVsz6/z9H7dobsJeu0sCANjokoLKiRMniq8S4He9WtXQQx3rWOdPzViljfvOPlcHAOD+ihxUcnNz9corr6h69eoKCgrStm2nbyz3/PPP65NPPimJGuGBnunWSB3qVdKxrBxrcm3KsSy7SwIAuEJQefXVV61psm+99Zb8/f3zH4+KitLHH39c3PXBQ/n6eOuDu6MVWbGMEg8f06OfrdDJnFy7ywIAOD2oTJo0SePHj7fuy2O2Eudp0aKFNmzYUNz1wYNVKOev8X1bq4yfj37efFBvz99od0kAAKcHlT179qhevXpnvSSUnc3sCxSvxlVD9I/eLazzcYu26euVe+wuCQDg5KDSpEkT/fzzz2c8PnPmTLVq1aq46gLydW9eVY9cfZl1/rcvV2vNnqN2lwQAKCW+Rf2EF154Qf3797dWVswqyldffaWNGzdal4TmzJlTMlXC45l5Kuv2pmrhxgMaODlO3wztoEpBAXaXBQBw2orKLbfcom+//VY//PCDypUrZwWX9evXW49de+21JVMlPJ6Pt5feu6uV6oSV056U4xo6bYWyaa4FALfHZFq4lM3709Rz9K/KyMrR/R1qa8RNTe0uCQDgpMm0devW1aFDh854PCUlxXofUJLqVwnWO3e2tM4n/LpDM+N2210SAKAEFTmomDsd5+TknPF4Zmam1bcClLTrm0ZoWJf61vmzsxK0cleK3SUBAOxupv3mm2/yz+fPn28t2eQxwWXBggWqXbt28VcInIUJKqa59vt1+zXINNc+2kHhwYF2lwUAsKtHxdv79OKLl5eX/vgpfn5+VkgZNWqUevToodJCj4pnSzuRrV5jFmtLcrpa16qgaQ9fLn9f7rMJAB7Zo2K2IpujZs2aSk5Ozn/bHOayj9miXJohBQgO9NP4vjEKDvRV7M4jeunbtXaXBAAoZkX+5+f27dsVFhZW3HUAF6Vu5SD9665W8vKSpv6WqGm/JdpdEgDAzoFvRkZGhn766SclJiYqK6vwXW0fe+yx4qoNuCCdG4Xr6esaWvcCGvHNGjWMCFJMrYp2lwUAsGOOyooVK3TjjTfq2LFjVmCpWLGiDh48qLJlyyo8PFzbtm1TaaFHBXnMX+Mh0+L1XcI+VQ4O0LdDOyoilOZaAPC4OSpPPPGEbrrpJh05ckRlypTR0qVLtXPnTsXExOgf//jHpdQNXDTT5P327S3UKCJYB9IyNXBKnE5kn7mNHgDgWoocVFauXKmnnnrK2gXk4+NjNdJGRkbqrbfe0rPPPlsyVQIXoFyAr8b3ba3yZf20aleK/j57zRk71AAAbh5UzFbkvK3K5lKP6VMxzBLOrl27ir9CoAhqViqrD+6OlreXrKm1k5bstLskAEBpBpVWrVpp+fLl1vlVV11l3ZRw6tSpevzxxxUVFXUptQDFomP9MD17Y2Pr/OU567Rk65m3fAAAuGlQef3111W1alXr/LXXXlOFChU0ePBgHThwQOPGjSuJGoEie7BjHfVsWU05uaebbM0dlwEAroe7J8NtmWba2z9crDV7UtW0WohmDrpCZfx97C4LADxeaknu+jmX+Ph4JtPCUQL9fDSub2tVKuevtUmpGv7VapprAcDFFCmomJsRPv3009bunrx5KRs2bFDPnj3Vpk0ba5w+4CTVy5fR6D7R8vH20uyVSfrkl+12lwQAKImg8sknn6hbt26aOHGi3nzzTV1++eWaMmWK2rdvr4iICK1Zs0bfffddUb42UCour1tJL/RoYp2//t16/bz5gN0lAQCKO6i89957VkAxU2i/+OIL688xY8YoISFBH374oRo3Pr3LAnCifu1rqXdMDeWekoZOW6HEQ8fsLgkAUJxBZevWrerdu7d1fuutt8rX11dvv/22atSocaFPAdg6ufaVnlFqGVleR49na8DkWGVknrS7LABAcQWV48ePW/fzyfulHxAQkL9NGXCV5toP742x7gW0YV+a/jJzFc21AOBOd0/++OOPFRQUZJ2fPHnS6lcJCwsr9DHcPRlOZm5U+OG90bpr/FLrBoZjFm7VkM717C4LAHCpc1Rq165traT8GfN+7p4MV/DZskQN/ypB5q/0//Vvo86Nwu0uCQA8RmoRXr8veEVlx44dxVEb4Ah3t62pNXuOaupviXrs8xX6ekgH1a18erUQAOAcxTbw7VK98cYb1oqMuWcQUBpG3NRUrWtVUNqJkxowOU5pJ7LtLgkA4MSgYm5yaO4T1Lx5c7tLgQfx9/XWmHujFRESqC3J6Xpi+irlmv3LAADHsD2opKenq0+fPvroo4+sGxwCpSk8OFDj+sZYoeWH9fv13oLNdpcEAHBSUBkyZIi6d++url272l0KPFSLyPIa2auZdW6Cyvy1++wuCQDghKDy+eefWzczHDly5AV9fGZmptUpXPAAisNtMTV0f4fa1vmT01dq8/40u0sCAFxMUPljUMg70tLSlJWVdcHPs2vXLg0bNkxTp05VYGDgBX2OCTRmO1PeERkZWdTygXN69sbGal+3kjKycvTwpFhrgi0AwEXmqOTx9vb+03kqZqT+fffdpxEjRlgfey6zZ89Wr1695OPjk/9YTk6O9dzm88zqScH3GeYxc+QxAcmEFeaooLgcSs/UzR/8qj0px3V1w8r6pH8b687LAACHz1HJY6bRPvfcc1YYadu2rfXYsmXL9Omnn+rvf/+7Dhw4oH/84x/WiP1nn332nM/TpUsX64aGBd1///1q1KiR/va3v50RUgzznOYASkqloACrufb2Dxdr4cYDGvWfjfrrDY3sLgsAPFaRg4oJJKNGjdIdd9yR/9hNN92kZs2aWVuMFyxYoJo1a+q1117706ASHBysqKioQo+VK1dOlSpVOuNxoDRFVQ/Vm7c117DPV1oj9ptUC1GP5tXsLgsAPFKRe1QWL16sVq1anfG4eWzJkiXWeceOHZWYmFg8FQI2uKVldQ28sq51/pcZq7UuicZtAHCJoGJ6Qj755JMzHjeP5TW3Hjp06KJmoixcuFDvvvtukT8PKAnmkk+n+mE6np2jAZNjdSTjwpvFAQA2Xfox/Se9e/fW3Llz1aZNG+ux2NhYbdiwQTNnzsyfNHvnnXcWU4mAPUwT7ft3t9Ito3/VzkPHNPSzeH16f1v5+tg+fggAPEaRd/0Y27dvt/pRNm3aZL3dsGFDDRw40LrDcmni7skoDRv3panXmF91LCtHD3Wso7/3aGJ3SQDg0ory+n1RQcUpCCooLfPW7NWgKfHW+T/vbKFerWrYXRIAuKwS3Z5spKSkWFuSk5OTlZubW+h9/fr1u5inBBzthqiqevSaenr/xy165ssE1ascrGY1Qu0uCwDcXpFXVL799lvrJoLmZoImBRUc/mbODx8+rNLCigpKk7mzsplYu2BDsqqFBuqbRzsqLIi5PgBQkq/fRe4KfOqpp/TAAw9YQcWsrBw5ciT/KM2QApQ2b28v/fOulqpbuZySjp7QI1PilZ1TeEURAFC8ihxU9uzZo8cee0xly5Yt5lIA5wsJ9NP4vq0VFOCrZTsO65U56+wuCQDcWpGDyvXXX29tRwY8Vb3wIL17Z0uZq56TluzU9OUMNwSAklLkZtru3bvrL3/5i9atW2eNzffz8yv0/ptvvrk46wMcqWuTKnqyawON+n6Tnp+9VvWrBCu6ZtGHHAIASuDuyed8Mi8v6w7IpYVmWtjdXPvI1HjNW7tP4cEBmvNoR4WHBNpdFgB4djOt2Y58rqM0QwrghObaf9zRQg2qBCk5LVODpsQp8yT/DwBAcWIWOHAJTFOtaa4NCfRVfGKKRny9Vi48QxEAXLNH5V//+pcGDBigwMBA6/zPmB1BgCepHVZO798TrfsnLNPny3epafVQ9b28lt1lAYDn9KjUqVPH2ulTqVIl6/ycT+blpW3btqm00KMCJ/nwp616Y+4G+Xp7adrDl6ttnYp2lwQAjsS9fgAbmP+VHv1sheas3quwIH99M7SjqpUvY3dZAOBZzbQAzr2i+NbtzdW4aogOpmdp4OQ4ncimuRYALkWRV1TMzp6JEydqwYIFZ70p4Y8//qjSwooKnGjX4WO6+YNfdORYtm6Nrq5RvVsUuicWAHi61JK8e/KwYcOsoGIGv0VFRfELGPiDyIplNfqeaPX9v2X6Kn6PoqqF6oGO5+7tAgAU44pKWFiYJk2apBtvvFF2Y0UFTvZ/v2zXy3PWycfbS5MfaKsr6oXZXRIAuH+Pir+/v+rVq3cp9QEe4f4Ota1LPzm5pzRkWrx1SQgAUDRFDipPPfWU3nvvPYZaAedhLou+3quZmtcItfpVBkyO07Gsk3aXBQDufemnV69e+u9//6uKFSuqadOmZ9yU8KuvvlJp4dIPXEFSynGrudbsBOrRvKrev7sVvV0APFpqSTbTli9f3gorAC6MmaUypk+M7vloqTVjJap6qAZddZndZQGASyhSUDl58qQ6d+6s6667ThERESVXFeBmzJTaETc31fOz1+jNeRvUKCJYVzcMt7ssAHCvHhVfX18NGjRImZmZJVcR4KbubVdTd7eNlLnY+thnK7TjYIbdJQGA+zXTtm3bVitWrCiZagA3ZvpSXry5qaJrllfqiZMaMDlW6Zk01wJAsfaoPPLII9bOn927dysmJkblypUr9P7mzZsX9SkBjxHg66MP741Rj/d/0ab96Xrqi5Ua2ydG3t401wJAsez68fb2Puu/FM3TmD/NiP3Swq4fuKr4xCO6a9xSZeXk6slrG+ixLvXtLgkA3GPXz/bt2y+lNgCSomtW0Ks9o/TXL1frne83WTcyvLZJFbvLAgDHKXJQqVWrVslUAniYO9pEak3SUU1aslNPTF+p2UM6qF54kN1lAYBrB5U869atU2JiorKysgo9fvPNNxdHXYBHeL5HE23Yl6Zl2w9rwKRYzR7aQSGBhYcoAoAnK3KPyrZt26yBbwkJCfm9KdYT/T5pkx4VoGgOpmfq5vd/UdLRE7qmUbg+7tea5loAbi21JG9KOGzYMNWpU0fJyckqW7as1q5dq0WLFql169ZauHDhpdQNeKSwoACN69taAb7e+nFDsv75wya7SwIAxyhyUFmyZIlefvllhYWFWTuAzNGxY0eNHDlSjz32WMlUCbi5ZjVC9cZtzazz93/corkJe+0uCQBcM6iYSzvBwcHWuQkrSUlJ+U22GzduLNJzjR071pq7YpZ9zNG+fXvNnTu3qCUBbqFXqxp6qGMd6/ypGau0YV+q3SUBgOsFlaioKK1atco6b9eund566y39+uuv1ipL3bp1i/RcNWrU0BtvvKG4uDjFxsbqmmuu0S233GJdTgI80TPdGqlDvUo6lpWjAZPilHKscLM6AHiaIjfTzp8/XxkZGbr11lu1ZcsW9ejRQ5s2bVKlSpU0ffp0K2xciooVK+rtt9/Wgw8+eN6PpZkW7uhIRpZu+uAX7T5yXJ3qh2nCfW3k61Pkf1MAgGMV5fW7yEHlbA4fPqwKFSrk7/y5GOaS0owZM9S/f3/rXkJNmjQ57+cQVOCu1iWl6raxi3U8O0cDr6yr4Tc2trskAHCNXT95zGqKWV05fvy4tQpyscw256CgIAUEBFh3Zp41a9Y5Q4q5a7P55goegDtqUi1Eb/c+fd+scYu26euVe+wuCQBsUeSgcujQIXXp0kUNGjTQjTfeqL17T+9OMJdqzM0Ki6phw4ZauXKlfvvtNw0ePNhaUTHD5M7G7CwyCSzviIyMLPLXA1xFj+bVNPjqy6zzv325Wmv2HLW7JABwflB54okn5OfnZ02lNXNU8tx5552aN29ekQvw9/dXvXr1rDsxmyDSokULvffee2f92OHDh1vLRHnHrl27ivz1AFfy9HUNdXXDyjqRnauBk+N0KD3T7pIAwNlB5T//+Y/efPNNa8dOQfXr19fOnTsvuaDc3FzrEs/ZmMtDeVuZ8w7Anfl4e+m9u1qpTlg57Uk5rqHTVig7J9fusgDAuUHF7PgpuJJSsKHWBImiMCskZqrtjh07rF4V87aZbtunT5+ilgW4rdAyfhrfN0bl/H20ZNshvfbv9XaXBADODSqdOnXSpEmT8t82O33MKoiZp9K5c+ciPZcZw9+vXz+rT8X0vSxfvtxq0L322muLWhbg1upXCdY7d7a0zicu3qEZsVz2BOAZirw9ec2aNVaoiI6O1o8//mjdLdkMaDMrKmbw22WXnW7+Kw1sT4an+ef3m/Tegs3y9/XWFwPbq2VkebtLAgBnbU82k2nNgDdzfx8zRTZv+JuZfVKaIQXwRMO61FfXxlWUdTJXgybHKTnthN0lAUCJKpaBb8bu3butMfrjx49XaWFFBZ4o7US2eo7+VVsPZKh1rQqa9vDl1goLALiKUhn4drb5Kp988klxPR2AcwgO9NNH/VorONBXsTuP6KVvuTcWAPfFP8MAF1S3cpD+dVcrmbtWTP0tUdN+S7S7JAAoEQQVwEV1bhRuDYQzRnyzRnE7D9tdEgAUO4IK4MIeufoy3dgsQtk5pzRoSrz2HaW5FoB78b3QDzQ7e/5MSkpKcdQDoAjMHKO3b2+hbQcytGFfmgZOidP0AZcr0M/H7tIAoHRXVAreDPBsR61atazhbQBKV7kAX43v29qaYLtqV4r+PnuNimkzHwC4z/ZkO7A9GfifnzcfUP//W6bcU9JLNzdV/ytq210SADhnezIAe3WqX1nDuzW2zl+es05Lth6yuyQAuGQEFcCNPNSpjnq2rKac3FMaMi3euuMyALgyggrgZs21b9zWXFHVQ3Q4I0sDJsXqeFaO3WUBwEUjqABuxuz4Gde3tSqV89fapFQ989VqmmsBuCyCCuCGqpcvo9F9ouXj7aWvVybp45+3210SAFwUggrgpi6vW0kv9GhinY+cu97aFQQAroagArixfu1rqXdMDWvL8pCp8YrbecTukgCgSAgqgJs3177SM0qta1VQ6omT6vPxUv13Q7LdZQHABSOoAB7QXDvpwba6umFlncjO1UOTYvVl3G67ywKAC0JQATxAWX9ffdSvtXq1qm7NWHlqxiqNX7TV7rIA4LwIKoCH8PPx1qjeLfRwpzrW269/t0Gvf7deuaaBBQAciqACeBBvby89172JhndrZL09ftE2PT1zlbJzcu0uDQDOiqACeKCBV12mf/RuYc1Z+Sp+jzXB9ljWSbvLAoAzEFQAD3V7TA2N7xujQD9v/XfjAfX5+DcdyciyuywAKISgAniwLo2raOpD7RRaxk8rElPUe9wSJXEjQwAOQlABPFxMrYqaMai9IkICtSU5XbeNXawtyWl2lwUAFoIKADWoEqwvH7lCl1Uup71HT+j2D5cwxRaAIxBUAOTfyHDmoCvUMrK8Uo5lM8UWgCMQVADkq1DOX9MebscUWwCOQVABUAhTbAE4CUEFwDmn2D7UkSm2AOxFUAFwzim2f+/BFFsA9iKoADjvFNu3b2/OFFsAtiCoADiv3q0jmWILwBYEFQAXhCm2ADwuqIwcOVJt2rRRcHCwwsPD1bNnT23cuNHOkgD8CabYAvCooPLTTz9pyJAhWrp0qb7//ntlZ2fruuuuU0ZGhp1lAfgTTLEFUJq8Tp065Zj9hgcOHLBWVkyAufLKK8/78ampqQoNDdXRo0cVEhJSKjUCOO1wRpYemLhcK3elWL0rY/vEqHOjcLvLAuACivL67ageFVOwUbFixbO+PzMz0/rmCh4A7FHx9ym2VzVgii2AkuOYoJKbm6vHH39cHTp0UFRU1Dl7WkwCyzsiIyNLvU4AhafYftyfKbYAPODSz+DBgzV37lz98ssvqlGjxjlXVMyRx6yomLDCpR/AXmZirZlc+/Ev2623B1xZV8/c0MgaGgcAl3Lpx1cOMHToUM2ZM0eLFi06Z0gxAgICrAOAM6fYVg4O0Mi5G6wptgfTM/Xmbc2tcfwAcLFs/Q1iFnNMSJk1a5Z+/PFH1alz+r4iAFwTU2wBuFVQMVuTp0yZomnTplmzVPbt22cdx48zRApwpym2KceYYgvABXtUvLzOfv16woQJuu+++877+WxPBpwrbudhPTAxVkePZ6teeJAmPdBW1cqXsbssAA5QlNdvxzTTXgyCCuBsm/anqd8ny7Qv9YSqhgZq8oNtVS882O6yANjMZeeoAHAvTLEFcKkIKgBKVPXyZTRj0BVqGVleKcey1efjpfrvhmS7ywLgIggqAGyZYvtVPFNsAZwfQQWALVNsn/xilT5atM3usgA4HEEFQKkxw99G9W6hhzqenpn02nfrNfK79dZMJQA4G4IKgFKfYvtc98Z6plsj6+1xi7bp6RmrlZ2Ta3dpAByIoALAlhlKgwpMsf0yfjdTbAGcFUEFgG2YYgvgfAgqAGzVpXEVTX2onULL+GlFYoo1ayUphdtoADiNoALAdjG1KmrGoPaKCAnUluR03TZ2sbYkp9ldFgAHIKgAcNQU27oFptjGJzLFFvB0BBUAjppiO7PAFNt7PmKKLeDpCCoAHIUptgAKIqgAcBym2ALIQ1AB4EhMsQVgEFQAOBZTbAEQVAC43BTbgZPjdDwrx+7SAJQCggoAl5ti++OGZPX5eClTbAEPQFAB4HJTbEMCfRXPFFvAIxBUALjcFNuZg69gii3gIQgqAFwOU2wBz0FQAeA+U2w3MsUWcDcEFQBuM8X24U+ZYgu4G4IKALeYYtuzZTWdZIot4HYIKgDcYortO3e01INMsQXcDkEFgNtMsf07U2wBt0NQAeB2U2zfYoot4DYIKgDczh1MsQXcBkEFgEdMse394RLtPcoUW8DVEFQAeMQU281miu0YptgCroagAsBjptgmMcUWcDkEFQAeM8W2BVNsAZdDUAHgMVNsP2OKLeByCCoAPAZTbAHXY2tQWbRokW666SZVq1bNmn8we/ZsO8sB4AGYYgu4FluDSkZGhlq0aKHRo0fbWQYAD8MUW8B1+Nr5xbt162YdAGDXFFvTuzL8qwRriu2RY1kafU+0yvj72F0eAFfsUcnMzFRqamqhAwAudYrtuHtjFODLFFvAiVwqqIwcOVKhoaH5R2RkpN0lAXADXZswxRZwKpcKKsOHD9fRo0fzj127dtldEgA30bo2U2wBJ3KpoBIQEKCQkJBCBwAUF6bYAs7jUkEFAEp7im2fj35jii3gqUElPT1dK1eutA5j+/bt1nliYqKdZQHwcHlTbK9sUFnHs3OsKbazVjDFFrCD1ykbpxwtXLhQnTt3PuPx/v37a+LEief9fLPrxzTVmn4VLgMBKG5ZJ3P115mrNHtlkvW2mb3yUKe6dpcFuLyivH7bOkfl6quvZhokAMfy9z09xbZSUIA++WW7Xv33eh1Iy7QGxZk5LABKHj0qAHABU2z/dgNTbAE7EFQA4DzM6sngqy/TW7c3l4+3lzXFduDkOB3PyrG7NMDtEVQA4AIxxRYofQQVACgCptgCpYugAgAXMcV2xqArVCUkgCm2QAkjqADARWgYEawvBzPFFihpBBUAuEg1KpRlii3c2pbkdO06fMxzB75dKga+AXCCjMyTGjw1Xos2HbDejq5ZXt2bV9ONzSJUNbSM3eUBRQ4n3yXs1b9X79XG/Wm674raevHmpvLIgW8A4A7KBfjq436t9fzsNfoibpfVZGuOV+ass0LLjc2qWke18oQWONOW5DT9e/U+K6CYcJLH19vLCuJ2YkUFAIrR/tQTmpuwV98l7NPynYdV8DcsoQVODCf/TkjSpv3phcJJx/ph6t6sqq5rEqHQsn62vn4TVADAhtDSylwealZV3ZpVte7YDJSGzfvT9G/r7+TeQuHEz8dLHeuFWSG6pMJJQQQVAHBgaJm3Zp913Z/QAieFk+7Nq+naxlVKPJwURFABAFcILQl7tXxH4dDSMrK8ejQntODSbDLhZPXpcGJm/RQMJ53qV7ZWTko7nBREUAEAF5FsQsvafZqz+uyh5fRKS4S1FRq45HDSpIpCy9gTTgoiqACAC8oLLebFZhmhBUUIJ/9O2GttKy4YTq78PZx0dUg4KYigAgBuHFrMgLnuzSKsFyFCi2eGkzm/r5wUDCf+Pt7qVD/MseGkIIIKALiR5LQTmv97T8tv288eWrpFVVVkRUKLOzp16pTVBJvXEHu2cNK9+elwEhLo3HBSEEEFADwgtCzbfli5BUNLjdD8OS2EFjcJJ6uTrP/WWw9kFAonVzb438qJq4STgggqAOABDqRl/n55KInQ4gbMy7GZCvvd7z0nZwsn3ZtXVZfGrhlOCiKoAICHhhbzIvfb9kOFQkvzGqFWIy6hxdnhZE7CXm07I5xUVvfmEW4RTgoiqACAh4eW+b834p4ttJjAYoILocUe5mV3w7600zf+86BwUhBBBQBQKLSYF8Wl2wgtjggnq/dq28EC4cTXW1eZcNLMXNYJV7CbhpOCCCoAgDMcTM+0JuKeLbQ0q/6/0FKzEqGlOMNJ3hA2Tw8nBRFUAADnDS15Ky1LthJaiot5SV2/9/TKybnCiblFwjWNPC+cFERQAQAUS2iJqh6i7s2qEVouIJz8OyHJulP29j+Ek6utnhPCSUEEFQDARTlkhZb91ovu2UJL3kpLrUrl5MnMS+e6vam/r5ycO5yYhtigAF9ba3UiggoAoNhCi3kxXrz1YKHQ0rRaiPVC7EmhpWA4MX0nOw4dKxROOjc8fW8dwsn5EVQAACUWWpZsO6ScAqnFhJa8lZbaYeXcMpzkNcQWDCcBZuWEcHJRCCoAgBJzOCMrv6dl8Vb3Cy3mZXFtUt5lnTPDSeeG4brx954TwsnFIagAAGwPLU2qnr48ZIJLHYeHlrxwknfjv53nCCddGoWrHOHkkhFUAAC2hJb/mIm4LhJaLiSc5O3WIZwUL4IKAMCxoaVx1RBrlogdoeXPwkmg3+8rJ80IJyWNoAIAcIwjJrSs26c5q88eWro3i7DCQd3KQSXy9c3L3Jo9/wsniYfPDCdm5cT8STgpHQQVAICjQ8u/E/bp1y0HC4WWRhHB+SstlxpazhdOzIqJ+TqEE3u4XFAZPXq03n77be3bt08tWrTQ+++/r7Zt25738wgqAOAeoWXxloM6+YfQYnYOmQbWyy4wtOSFkzkJSZqbsO+c4cT8WdafcGInlwoq06dPV79+/fThhx+qXbt2evfddzVjxgxt3LhR4eHhf/q5BBUAcA8px0xPi5mIu9daabnQ0GJewhL2HM1fOdl1+PgZ4cTcAqBzo8qEEwdxqaBiwkmbNm30wQcfWG/n5uYqMjJSjz76qJ555pk//VyCCgB4XmgxqyIxtSpo0eYDZ4STMn4+/7usQzhxrKK8ftv6XzArK0txcXEaPnx4/mPe3t7q2rWrlixZcsbHZ2ZmWkfBbxQA4F7Kl/XXHW0ircMKLev2W5NhTWjZsC/NOgrKCyemIdZMiiWcuBdb/2sePHhQOTk5qlKlSqHHzdsbNmw44+NHjhypl156qRQrBADYHlpaR1pHXmgxqyjrklLVpk5F65IQ4cS9udR/WbPy8uSTTxZaUTGXiQAAnhVa4DlsDSphYWHy8fHR/v37Cz1u3o6IiDjj4wMCAqwDAAB4Bm87v7i/v79iYmK0YMGC/MdMM615u3379naWBgAAHMD2Sz/mUk7//v3VunVra3aK2Z6ckZGh+++/3+7SAACApweVO++8UwcOHNALL7xgDXxr2bKl5s2bd0aDLQAA8Dy2z1G5FMxRAQDAvV+/be1RAQAA+DMEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4Fi2j9C/FHlDdc2EOwAA4BryXrcvZDi+SweVtLQ068/IyEi7SwEAABfxOm5G6bvtvX5yc3OVlJSk4OBgeXl5FXvaMwFo165d3EeoBPFzLh38nEsHP+fSwc/Z9X/WJnqYkFKtWjV5e3u774qK+eZq1KhRol/D/Ifhf4SSx8+5dPBzLh38nEsHP2fX/lmfbyUlD820AADAsQgqAADAsQgq5xAQEKARI0ZYf6Lk8HMuHfycSwc/59LBz9mzftYu3UwLAADcGysqAADAsQgqAADAsQgqAADAsQgqZzF69GjVrl1bgYGBateunZYtW2Z3SW5n0aJFuummm6xhP2ZY3+zZs+0uyS2NHDlSbdq0sYYihoeHq2fPntq4caPdZbmdsWPHqnnz5vmzJtq3b6+5c+faXZbbe+ONN6zfH48//rjdpbiVF1980fq5FjwaNWpkWz0ElT+YPn26nnzySavLOT4+Xi1atND111+v5ORku0tzKxkZGdbP1oRClJyffvpJQ4YM0dKlS/X9998rOztb1113nfXzR/ExgyfNi2ZcXJxiY2N1zTXX6JZbbtHatWvtLs1tLV++XOPGjbMCIopf06ZNtXfv3vzjl19+kV3Y9fMHZgXF/Av0gw8+yB/Tb8YHP/roo3rmmWfsLs8tmbQ+a9Ys61/7KFkHDhywVlZMgLnyyivtLsetVaxYUW+//bYefPBBu0txO+np6YqOjtaYMWP06quvqmXLlnr33XftLsutVlRmz56tlStXyglYUSkgKyvL+hdR165dC43pN28vWbLE1tqA4nD06NH8F1GUjJycHH3++efWqpW5BITiZ1YJu3fvXuh3NYrX5s2brUvzdevWVZ8+fZSYmCi7uPS9forbwYMHrV8yVapUKfS4eXvDhg221QUUB7M6aK7ld+jQQVFRUXaX43YSEhKsYHLixAkFBQVZq4RNmjSxuyy3Y0KguSxvLv2g5K4sTJw4UQ0bNrQu+7z00kvq1KmT1qxZY/W7lTaCCuBB/wo1v2jsvNbszswvdbNUblatZs6cqf79+1uX2AgrxcfcwXfYsGFWv5XZ7ICS0a1bt/xz0wNkgkutWrX0xRdf2HIpk6BSQFhYmHx8fLR///5Cj5u3IyIibKsLuFRDhw7VnDlzrN1WJX3HcU/l7++vevXqWecxMTHWv/jfe+89q+ETxcNcmjcbG0x/Sh6zCm7+Xpu+wszMTOt3OIpX+fLl1aBBA23ZskV2oEflD79ozC+YBQsWFFouN29zrRmuyPTKm5BiLkP8+OOPqlOnjt0leQzzu8O8cKL4dOnSxbrEZlau8o7WrVtbPRTmnJBScs3LW7duVdWqVWUHVlT+wGxNNku25i9/27ZtrU5y0xR3//33212a2/3FL5jOt2/fbv2iMU2eNWvWtLU2d7vcM23aNH399dfWteV9+/ZZj4eGhqpMmTJ2l+c2hg8fbi2Xm7+7aWlp1s984cKFmj9/vt2luRXzd/iP/VXlypVTpUqV6LsqRk8//bQ158pc7klKSrLGdZgQePfdd8sOBJU/uPPOO60tnC+88IL1S91se5s3b94ZDba4NGbWROfOnQsFRMOERNPEheIbRGZcffXVhR6fMGGC7rvvPpuqcj/mckS/fv2sxkMTAs11fRNSrr32WrtLA4ps9+7dVig5dOiQKleurI4dO1qzmMy5HZijAgAAHIseFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAA4FgEFQAlztyWYvDgwda9cAICAqy7kV9//fX69ddfrfd7eXlp9uzZdpcJwIG41w+AEnfbbbcpKytLn376qerWrav9+/dbdyU39xIBgD/DvX4AlKiUlBRVqFDBupvwVVdddcb7a9eurZ07d+a/be7YumPHDuvc3PX5pZde0rp161StWjXrppXPPfecfH1981dixowZo2+++cZ6fnMb+rfeeku33357KX6HAEoSl34AlKigoCDrMJd2MjMzz3j/8uXL8+/obO4+nPf2zz//bN2ReNiwYVZQGTdunHVn7ddee63Q5z///PPWis2qVavUp08f3XXXXVq/fn0pfXcAShorKgBK3JdffqmHH35Yx48fV3R0tLWyYgJF8+bN81dGZs2apZ49e+Z/TteuXdWlSxcNHz48/7EpU6bor3/9q5KSkvI/b9CgQRo7dmz+x1x++eXW1zArLQBcHysqAEqcWfEw4cJcornhhhusyzQmTJgVknMxKyQvv/xy/oqMOUzYMasux44dy/+49u3bF/o88zYrKoD7oJkWQKkIDAzUtddeax3mcs1DDz2kESNG6L777jvrx6enp1v9KbfeeutZnwuAZ2BFBYAtmjRpooyMDOvcz89POTk5hd5vVlw2btyoevXqnXF4e//vV9fSpUsLfZ55u3HjxqX0XQAoaayoAChRZgty79699cADD1g9KcHBwYqNjbV259xyyy35O3/MduUOHTpYc1bMLqEXXnhBPXr0sGavmF08JpyYy0Fr1qzRq6++mv/8M2bMUOvWrdWxY0dNnTpVy5Yt0yeffGLjdwygONFMC6BEmZ0+L774ov7zn/9o69atys7OVmRkpBVenn32WZUpU0bffvutnnzySWtbcvXq1fO3J8+fP9/qU1mxYoW16tKoUSPrkpHpVclrph09erS1o2jRokXW9uQ333xTd9xxh83fNYDiQlAB4LLOtlsIgHuhRwUAADgWQQUAADgWzbQAXBZXrgH3x4oKAABwLIIKAABwLIIKAABwLIIKAABwLIIKAABwLIIKAABwLIIKAABwLIIKAABwLIIKAACQU/0/F3Y7of4qqNgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "EPOCHS = config.EPOCHS\n",
    "BATCHES = len(train_loader)\n",
    "steps = []\n",
    "lrs = []\n",
    "optim_lrs = []\n",
    "model = CustomModel(num_classes=9)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=config.EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.0,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=100,\n",
    ")\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in range(BATCHES):\n",
    "        scheduler.step()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * BATCHES + batch)\n",
    "\n",
    "max_lr = max(lrs)\n",
    "min_lr = min(lrs)\n",
    "print(f\"Maximum LR: {max_lr} | Minimum LR: {min_lr}\")\n",
    "plt.figure()\n",
    "plt.plot(steps, lrs, label='OneCycle')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c01fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        f1_binary = f1_score(\n",
    "            y_true_bin,\n",
    "            y_pred_bin,\n",
    "            pos_label=True,\n",
    "            zero_division=0,\n",
    "            average='binary'\n",
    "        )\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        # Compute macro F1 over all gesture classes\n",
    "        f1_macro = f1_score(\n",
    "            y_true_mc,\n",
    "            y_pred_mc,\n",
    "            average='macro',\n",
    "            zero_division=0\n",
    "        )\n",
    "        f1_mean = 0.5 * f1_binary + 0.5 * f1_macro\n",
    "        return f1_mean, f1_binary, f1_macro\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute hierarchical macro F1 for the CMI 2025 challenge.\n",
    "\n",
    "    Expected input:\n",
    "      - solution and submission as pandas.DataFrame\n",
    "      - Column 'sequence_id': unique identifier for each sequence\n",
    "      - 'gesture': one of the eight target gestures or \"Non-Target\"\n",
    "\n",
    "    This metric averages:\n",
    "    1. Binary F1 on SequenceType (Target vs Non-Target)\n",
    "    2. Macro F1 on gesture (mapping non-targets to \"Non-Target\")\n",
    "\n",
    "    Raises ParticipantVisibleError for invalid submissions,\n",
    "    including invalid SequenceType or gesture values.\n",
    "\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> solution = pd.DataFrame({'id': range(4), 'gesture': ['Eyebrow - pull hair']*4})\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Forehead - pull hairline']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.5\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Text on phone']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.0\n",
    "    >>> score(solution, solution, row_id_column_name=row_id_column_name)\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    # Validate required columns\n",
    "    for col in (row_id_column_name, 'gesture'):\n",
    "        if col not in solution.columns:\n",
    "            raise ParticipantVisibleError(f\"Solution file missing required column: '{col}'\")\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f\"Submission file missing required column: '{col}'\")\n",
    "\n",
    "    metric = CompetitionMetric()\n",
    "    return metric.calculate_hierarchical_f1(solution, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50192f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train()\n",
    "    criterion1 = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    criterion2 = nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.amp.GradScaler(enabled=config.AMP)\n",
    "    losses, losses1, losses2 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, batch in enumerate(tqdm_train_loader):\n",
    "            X = batch.pop(\"X\").to(device) # send inputs to `device`\n",
    "            y = batch.pop(\"y\").to(device) # send labels to `device`\n",
    "            y_hard = batch.pop(\"y_hard\").to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.amp.autocast(device.type, enabled=config.AMP):\n",
    "                y_preds, y_preds_hard = model(X)\n",
    "                loss1 = criterion1(y_preds, y)\n",
    "                loss2 = criterion2(y_preds_hard, y_hard.unsqueeze(1))\n",
    "                loss = loss1 + loss2 \n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            losses1.update(loss1.item(), batch_size)\n",
    "            losses2.update(loss2.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "            \n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                scheduler.step()\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print(\n",
    "                    'Epoch: [{0}][{1}/{2}] '\n",
    "                    'Elapsed {remain:s} '\n",
    "                    'Loss: {loss.avg:.4f} '\n",
    "                    'Loss CE: {loss1.avg:.4f} '\n",
    "                    'Loss BCE: {loss2.avg:.4f} '\n",
    "                    'Grad: {grad_norm:.4f}  '\n",
    "                    'LR: {lr:.8f}  '\n",
    "                    .format(\n",
    "                        epoch+1, step, len(train_loader), \n",
    "                        remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                        loss=losses, loss1=losses1, loss2=losses2,\n",
    "                        grad_norm=grad_norm,\n",
    "                        lr=scheduler.get_last_lr()[0]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_epoch(valid_loader, model, device):\n",
    "    model.eval() \n",
    "    criterion1 = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    criterion2 = nn.BCEWithLogitsLoss()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    losses, losses1, losses2 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    predictions = {}\n",
    "    all_preds, all_trues, all_ids = [] , [],  []\n",
    "    start = end = time.time()\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, batch in enumerate(tqdm_valid_loader):\n",
    "            X = batch.pop(\"X\").to(device) \n",
    "            y = batch.pop(\"y\").to(device)\n",
    "            y_hard = batch.pop(\"y_hard\").to(device)\n",
    "            sequence_ids = batch.pop(\"sequence_id\")\n",
    "            batch_size = y.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds, y_preds_hard = model(X)\n",
    "                loss1 = criterion1(y_preds, y)\n",
    "                loss2 = criterion2(y_preds_hard, y_hard.unsqueeze(1))\n",
    "                loss = loss1 + loss2\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            losses1.update(loss1.item(), batch_size)\n",
    "            losses2.update(loss2.item(), batch_size)\n",
    "            y_preds = softmax(y_preds)\n",
    "            all_preds.append(y_preds.to('cpu').numpy())\n",
    "            all_trues.append(y.to('cpu').numpy())\n",
    "            all_ids += sequence_ids\n",
    "            end = time.time()\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Loss CE: {loss1.avg:.4f} '\n",
    "                      'Loss BCE: {loss2.avg:.4f} '\n",
    "                      .format(\n",
    "                          step, len(valid_loader),\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                          loss=losses, loss1=losses1, loss2=losses2\n",
    "                        )\n",
    "                     )\n",
    "\n",
    "    y_pred_proba = np.concatenate(all_preds)\n",
    "    predictions[\"sequence_id\"] = all_ids\n",
    "    predictions[\"y_pred\"] = np.argmax(y_pred_proba, axis=1)\n",
    "    predictions[\"y_true\"] = np.concatenate(all_trues)\n",
    "    df_preds = pd.DataFrame(predictions)\n",
    "    return losses.avg, df_preds, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fcfb04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== SPLIT ==========\n",
    "    train_folds = df_train[df_train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = df_train[df_train['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    all_sequences = df_train.sequence_id.unique()\n",
    "    train_sequences = train_folds.sequence_id.unique()\n",
    "    valid_sequences = valid_folds.sequence_id.unique()\n",
    "    train_index = [np.where(all_sequences == item)[0][0] for item in train_sequences]\n",
    "    valid_index = [np.where(all_sequences == item)[0][0] for item in valid_sequences]\n",
    "    \n",
    "    X_train, X_valid = all_X[train_index], all_X[valid_index]\n",
    "    y_train, y_valid = all_y[train_index], all_y[valid_index]\n",
    "    y_hard_train, y_hard_valid = all_y_hard[train_index], all_y_hard[valid_index]\n",
    "    \n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(config, train_folds, X_train, y_train, y_hard_train)\n",
    "    valid_dataset = CustomDataset(config, valid_folds, X_valid, y_valid, y_hard_valid)\n",
    "    \n",
    "    if config.DEBUG:\n",
    "        train_dataset = Subset(train_dataset, list(range(config.BATCH_SIZE_TRAIN * 2)))\n",
    "        config.EPOCHS = 2\n",
    "        \n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE_TRAIN,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.BATCH_SIZE_VALID,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False\n",
    "    )\n",
    "    \n",
    "    # ======== MODEL ==========\n",
    "    model = CustomModel(num_classes=9)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config.LEARNING_RATE,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.0,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "    \n",
    "    best_score = 0\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_train_loss = train_epoch(train_loader, model, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, df_preds, y_pred_proba = valid_epoch(valid_loader, model, device)\n",
    "        solution, submission = format_for_scoring(df_preds)\n",
    "        avg_score, f1_binary, f1_macro = score(solution, submission, \"id\")\n",
    "        # ======= SCORING ==========\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        \n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            LOGGER.info(\n",
    "                f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model | F1-binary: {f1_binary} | F1-macro: {f1_macro}'\n",
    "            )\n",
    "            # === Save ===\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                paths.OUTPUT_DIR + f\"/wavenet_fold_{fold}_best.pth\"\n",
    "            )\n",
    "            df_preds.to_csv(paths.OUTPUT_DIR + f\"/valid_{fold}.csv\", index=False)\n",
    "            np.save(paths.OUTPUT_DIR + f\"/y_pred_proba_{fold}.npy\", y_pred_proba)\n",
    "        else:\n",
    "            print(f\"Score: {avg_score} | F1-binary: {f1_binary} | F1-macro: {f1_macro}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7bd31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold: 0 training ==========\n",
      "========== Fold: 0 training ==========\n",
      "========== Fold: 0 training ==========\n",
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  2.34train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6551 Loss CE: 1.9575 Loss BCE: 0.6976 Grad: 27.5829  LR: 0.00075010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.32train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6666 Loss CE: 2.0281 Loss BCE: 0.6385 Grad: 35.9487  LR: 0.00050020  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 11.90valid_batch/s]\n",
      "Epoch 1 - avg_train_loss: 2.6666  avg_val_loss: 2.6065  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.6666  avg_val_loss: 2.6065  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.6666  avg_val_loss: 2.6065  time: 1s\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6065 Loss CE: 1.4910 Loss BCE: 1.1155 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  2.15train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.1664 Loss CE: 1.8160 Loss BCE: 0.3504 Grad: 28.1357  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.33train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.0326 Loss CE: 1.5085 Loss BCE: 0.5242 Grad: 22.2956  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 13.99valid_batch/s]\n",
      "Epoch 2 - avg_train_loss: 2.0326  avg_val_loss: 2.6610  time: 1s\n",
      "Epoch 2 - avg_train_loss: 2.0326  avg_val_loss: 2.6610  time: 1s\n",
      "Epoch 2 - avg_train_loss: 2.0326  avg_val_loss: 2.6610  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6610 Loss CE: 1.4823 Loss BCE: 1.1787 \n",
      "Score: 0.5 | F1-binary: 0.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  2.57train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.5491 Loss CE: 1.8720 Loss BCE: 0.6771 Grad: 28.1377  LR: 0.00000040  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.43train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.2893 Loss CE: 1.6661 Loss BCE: 0.6232 Grad: 30.1077  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 13.32valid_batch/s]\n",
      "Epoch 3 - avg_train_loss: 2.2893  avg_val_loss: 2.6677  time: 1s\n",
      "Epoch 3 - avg_train_loss: 2.2893  avg_val_loss: 2.6677  time: 1s\n",
      "Epoch 3 - avg_train_loss: 2.2893  avg_val_loss: 2.6677  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6677 Loss CE: 1.4965 Loss BCE: 1.1712 \n",
      "Score: 0.0 | F1-binary: 0.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold 0 finished ==========\n",
      "========== Fold 0 finished ==========\n",
      "========== Fold 0 finished ==========\n",
      "========== Fold: 1 training ==========\n",
      "========== Fold: 1 training ==========\n",
      "========== Fold: 1 training ==========\n",
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  2.28train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6134 Loss CE: 1.9875 Loss BCE: 0.6259 Grad: 46.4967  LR: 0.00075010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.34train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6628 Loss CE: 2.0921 Loss BCE: 0.5707 Grad: 21.0566  LR: 0.00050020  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 12.27valid_batch/s]\n",
      "Epoch 1 - avg_train_loss: 2.6628  avg_val_loss: 2.4112  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.6628  avg_val_loss: 2.4112  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.6628  avg_val_loss: 2.4112  time: 1s\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 0.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.4112 Loss CE: 1.8786 Loss BCE: 0.5326 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  2.56train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.0288 Loss CE: 1.5853 Loss BCE: 0.4435 Grad: 16.3504  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.54train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.2769 Loss CE: 1.7686 Loss BCE: 0.5083 Grad: 34.5438  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 18.89valid_batch/s]\n",
      "Epoch 2 - avg_train_loss: 2.2769  avg_val_loss: 2.2380  time: 1s\n",
      "Epoch 2 - avg_train_loss: 2.2769  avg_val_loss: 2.2380  time: 1s\n",
      "Epoch 2 - avg_train_loss: 2.2769  avg_val_loss: 2.2380  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.2380 Loss CE: 1.7377 Loss BCE: 0.5003 \n",
      "Score: 0.5 | F1-binary: 0.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  3.15train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.6367 Loss CE: 1.2214 Loss BCE: 0.4153 Grad: 13.3860  LR: 0.00000040  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  3.27train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.9310 Loss CE: 1.3800 Loss BCE: 0.5510 Grad: 20.5141  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 17.92valid_batch/s]\n",
      "Epoch 3 - avg_train_loss: 1.9310  avg_val_loss: 2.1969  time: 1s\n",
      "Epoch 3 - avg_train_loss: 1.9310  avg_val_loss: 2.1969  time: 1s\n",
      "Epoch 3 - avg_train_loss: 1.9310  avg_val_loss: 2.1969  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.1969 Loss CE: 1.7092 Loss BCE: 0.4876 \n",
      "Score: 0.5 | F1-binary: 0.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold 1 finished ==========\n",
      "========== Fold 1 finished ==========\n",
      "========== Fold 1 finished ==========\n",
      "========== Fold: 2 training ==========\n",
      "========== Fold: 2 training ==========\n",
      "========== Fold: 2 training ==========\n",
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  3.25train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 3.2762 Loss CE: 2.3760 Loss BCE: 0.9002 Grad: 27.8704  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 13.74valid_batch/s]\n",
      "Epoch 1 - avg_train_loss: 3.2762  avg_val_loss: 2.8288  time: 0s\n",
      "Epoch 1 - avg_train_loss: 3.2762  avg_val_loss: 2.8288  time: 0s\n",
      "Epoch 1 - avg_train_loss: 3.2762  avg_val_loss: 2.8288  time: 0s\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.8288 Loss CE: 2.2636 Loss BCE: 0.5651 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  3.12train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.6514 Loss CE: 1.9743 Loss BCE: 0.6771 Grad: 24.1159  LR: 0.00000040  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 11.96valid_batch/s]\n",
      "Epoch 2 - avg_train_loss: 2.6514  avg_val_loss: 2.8144  time: 0s\n",
      "Epoch 2 - avg_train_loss: 2.6514  avg_val_loss: 2.8144  time: 0s\n",
      "Epoch 2 - avg_train_loss: 2.6514  avg_val_loss: 2.8144  time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.8144 Loss CE: 2.2932 Loss BCE: 0.5213 \n",
      "Score: 0.5 | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  3.43train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.0761 Loss CE: 1.6924 Loss BCE: 0.3837 Grad: 22.3819  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 11.32valid_batch/s]\n",
      "Epoch 3 - avg_train_loss: 2.0761  avg_val_loss: 2.7823  time: 0s\n",
      "Epoch 3 - avg_train_loss: 2.0761  avg_val_loss: 2.7823  time: 0s\n",
      "Epoch 3 - avg_train_loss: 2.0761  avg_val_loss: 2.7823  time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.7823 Loss CE: 2.2724 Loss BCE: 0.5099 \n",
      "Score: 0.5 | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold 2 finished ==========\n",
      "========== Fold 2 finished ==========\n",
      "========== Fold 2 finished ==========\n",
      "========== Fold: 3 training ==========\n",
      "========== Fold: 3 training ==========\n",
      "========== Fold: 3 training ==========\n",
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  3.14train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 3.0734 Loss CE: 2.4062 Loss BCE: 0.6671 Grad: 27.7768  LR: 0.00075010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  3.10train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 2.8283 Loss CE: 2.2183 Loss BCE: 0.6100 Grad: 17.4770  LR: 0.00050020  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 17.58valid_batch/s]\n",
      "Epoch 1 - avg_train_loss: 2.8283  avg_val_loss: 1.4591  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.8283  avg_val_loss: 1.4591  time: 1s\n",
      "Epoch 1 - avg_train_loss: 2.8283  avg_val_loss: 1.4591  time: 1s\n",
      "Epoch 1 - Save Best Score: 1.0000 Model | F1-binary: 1.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 1.0000 Model | F1-binary: 1.0 | F1-macro: 1.0\n",
      "Epoch 1 - Save Best Score: 1.0000 Model | F1-binary: 1.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 1.4591 Loss CE: 1.0512 Loss BCE: 0.4079 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  3.33train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.5303 Loss CE: 1.2045 Loss BCE: 0.3258 Grad: 15.0700  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  2.98train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.7998 Loss CE: 1.4594 Loss BCE: 0.3404 Grad: 18.9419  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 18.07valid_batch/s]\n",
      "Epoch 2 - avg_train_loss: 1.7998  avg_val_loss: 1.0414  time: 1s\n",
      "Epoch 2 - avg_train_loss: 1.7998  avg_val_loss: 1.0414  time: 1s\n",
      "Epoch 2 - avg_train_loss: 1.7998  avg_val_loss: 1.0414  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 1.0414 Loss CE: 0.8260 Loss BCE: 0.2154 \n",
      "Score: 1.0 | F1-binary: 1.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/2 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train:  50%|█████     | 1/2 [00:00<00:00,  3.24train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.5091 Loss CE: 1.3235 Loss BCE: 0.1856 Grad: 14.6422  LR: 0.00000040  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2/2 [00:00<00:00,  3.20train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1/2] Elapsed 0m 0s (remain 0m 0s) Loss: 1.4602 Loss CE: 1.2637 Loss BCE: 0.1966 Grad: 11.0100  LR: 0.00006736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 16.18valid_batch/s]\n",
      "Epoch 3 - avg_train_loss: 1.4602  avg_val_loss: 1.1567  time: 1s\n",
      "Epoch 3 - avg_train_loss: 1.4602  avg_val_loss: 1.1567  time: 1s\n",
      "Epoch 3 - avg_train_loss: 1.4602  avg_val_loss: 1.1567  time: 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 1.1567 Loss CE: 0.9372 Loss BCE: 0.2195 \n",
      "Score: 1.0 | F1-binary: 1.0 | F1-macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold 3 finished ==========\n",
      "========== Fold 3 finished ==========\n",
      "========== Fold 3 finished ==========\n",
      "========== Fold: 4 training ==========\n",
      "========== Fold: 4 training ==========\n",
      "========== Fold: 4 training ==========\n",
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  2.92train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 3.1989 Loss CE: 2.3917 Loss BCE: 0.8072 Grad: 22.4058  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00, 13.00valid_batch/s]\n",
      "Epoch 1 - avg_train_loss: 3.1989  avg_val_loss: 2.9687  time: 0s\n",
      "Epoch 1 - avg_train_loss: 3.1989  avg_val_loss: 2.9687  time: 0s\n",
      "Epoch 1 - avg_train_loss: 3.1989  avg_val_loss: 2.9687  time: 0s\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n",
      "Epoch 1 - Save Best Score: 0.5000 Model | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.9687 Loss CE: 2.2585 Loss BCE: 0.7102 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  3.19train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.4262 Loss CE: 1.9115 Loss BCE: 0.5147 Grad: 96.3130  LR: 0.00000040  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  9.87valid_batch/s]\n",
      "Epoch 2 - avg_train_loss: 2.4262  avg_val_loss: 2.9768  time: 0s\n",
      "Epoch 2 - avg_train_loss: 2.4262  avg_val_loss: 2.9768  time: 0s\n",
      "Epoch 2 - avg_train_loss: 2.4262  avg_val_loss: 2.9768  time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.9768 Loss CE: 2.2980 Loss BCE: 0.6789 \n",
      "Score: 0.5 | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/1 [00:00<?, ?train_batch/s]d:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\n",
      "Train: 100%|██████████| 1/1 [00:00<00:00,  3.17train_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.4870 Loss CE: 2.1051 Loss BCE: 0.3819 Grad: 52.6055  LR: 0.00025030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  8.18valid_batch/s]\n",
      "Epoch 3 - avg_train_loss: 2.4870  avg_val_loss: 2.9982  time: 0s\n",
      "Epoch 3 - avg_train_loss: 2.4870  avg_val_loss: 2.9982  time: 0s\n",
      "Epoch 3 - avg_train_loss: 2.4870  avg_val_loss: 2.9982  time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1] Elapsed 0m 0s (remain 0m 0s) Loss: 2.9982 Loss CE: 2.3162 Loss BCE: 0.6820 \n",
      "Score: 0.5 | F1-binary: 1.0 | F1-macro: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold 4 finished ==========\n",
      "========== Fold 4 finished ==========\n",
      "========== Fold 4 finished ==========\n"
     ]
    }
   ],
   "source": [
    "if not config.TRAIN_FULL_DATA:\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold in range(config.FOLDS):\n",
    "        if fold in [0, 1, 2, 3, 4]:\n",
    "            _oof_df = train_loop(df_train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== Fold {fold} finished ==========\")\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    oof_df.to_csv(paths.OUTPUT_DIR + f\"/oof_df.csv\", index=False)\n",
    "else:\n",
    "    train_loop_full_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96241cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
