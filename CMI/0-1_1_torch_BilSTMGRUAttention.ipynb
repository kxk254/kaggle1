{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b79b6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, joblib\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "82880947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · torch 2.7.1+cu128 device : cuda\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "RAW_DIR = Path(\"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\")\n",
    "\n",
    "# used when TRAIN=False\n",
    "PRETRAINED_DIR = Path(\"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\pretrained-model\")\n",
    "EXPORT_DIR = PRETRAINED_DIR                                  # artefacts will be saved here\n",
    "BATCH_SIZE = 256  #64\n",
    "PAD_PERCENTILE = 95\n",
    "LR_INIT =  5e-3  # too large 5e-2  okay 1e-2  improved 8e-3 \n",
    "WD = 5e-4\n",
    "MIXUP_ALPHA = 0.4\n",
    "EPOCHS = 160 #160\n",
    "PATIENCE = 40\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "print(\"▶ imports ready · torch\", torch.__version__, \"device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "179bbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d535f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_sum(x):\n",
    "    return x.sum(dim=1)\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return x.squeeze(-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return x.unsqueeze(-1)\n",
    "\n",
    "class SEBlock1D(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, time)\n",
    "        b, c, _ = x.size()\n",
    "        y = self.global_avg_pool(x).view(b, c)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualSEBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, pool_size=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.se = SEBlock1D(out_channels)\n",
    "        \n",
    "        self.match_channels = None\n",
    "        if in_channels != out_channels:\n",
    "            self.match_channels = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(pool_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.match_channels is not None:\n",
    "            identity = self.match_channels(identity)\n",
    "        \n",
    "        out = F.relu(out + identity)\n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, features)\n",
    "        # Compute scores with tanh activation\n",
    "        scores = torch.tanh(self.attn_fc(x))  # (batch, time, 1)\n",
    "        scores = scores.squeeze(-1)           # (batch, time)\n",
    "\n",
    "        # Softmax over time dimension to get weights\n",
    "        weights = F.softmax(scores, dim=1)    # (batch, time)\n",
    "        weights = weights.unsqueeze(-1)       # (batch, time, 1)\n",
    "\n",
    "        # Weighted sum of input features over time\n",
    "        context = (x * weights).sum(dim=1)    # (batch, features)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d7803102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n",
    "    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n",
    "    return scaler.transform(mat).astype('float32')\n",
    "\n",
    "# MixUp the data argumentation in order to regularize the neural network. \n",
    "\n",
    "class MixupGenerator(Dataset):\n",
    "    def __init__(self, X, y, alpha, time_cutmix=False, noise_std=0.03):\n",
    "        \"\"\"  \n",
    "        X: np.array or totch.Tensor of shape (N, ...)\n",
    "        y: np.array or torch.Tensor of shape (N, ...)\n",
    "        alpha: Beta distribution parameter for mixup  0.2–0.4 is usually best. Smaller = more like original sample.\n",
    "        time_cutmix: If True, apply temporal cutmix\n",
    "        noise_std: Optional Gaussian noise after mixup  0.01–0.05 for noise injection.\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(X, dtype=torch.float32) if isinstance(X, np.ndarray) else X\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) if isinstance(y, np.ndarray) else y\n",
    "        self.alpha = alpha\n",
    "        self.time_cutmix = time_cutmix\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get current sample\n",
    "        x1, y1 = self.X[index], self.y[index]\n",
    "\n",
    "        # Choose a random other sample\n",
    "        mix_index = np.random.randint(0, len(self.X))\n",
    "        x2, y2 = self.X[mix_index], self.y[mix_index]\n",
    "\n",
    "        # Mix them\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "\n",
    "        if self.time_cutmix:\n",
    "            # Mix only over a time region\n",
    "            T = x1.shape[0]\n",
    "            cut_len = np.random.randint(T // 4, T // 2)\n",
    "            t_start = np.random.randint(0, T - cut_len)\n",
    "            x_mix = x1.clone()\n",
    "            x_mix[t_start:t_start+cut_len] = x2[t_start:t_start+cut_len]\n",
    "        else:\n",
    "            x_mix = lam * x1 + (1 - lam) * x2\n",
    "\n",
    "        y_mix = lam * y1 + (1 - lam) * y2\n",
    "\n",
    "        if self.noise_std > 0:\n",
    "            noise = torch.randn_like(x_mix) * self.noise_std\n",
    "            x_mix += noise\n",
    "\n",
    "        return x_mix, y_mix\n",
    "    \n",
    "# dataset = MixupGenerator(X_train, y_train, alpha=0.2)\n",
    "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def pad_or_truncate(seq, max_len, mode=TRAIN, pad_value=0.0, dtype=np.float32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pads or truncates a sequence to a fixed length.\n",
    "\n",
    "    Parameters:\n",
    "    - seq: np.ndarray of shape (L, D)\n",
    "    - max_len: int, desired sequence length\n",
    "    - mode: bool, True = random pad, False = regular pad\n",
    "    - pad_value: float or int, value to use for padding\n",
    "    - dtype: np.dtype, dtype for the output array\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray of shape (max_len, D)\n",
    "    \"\"\"\n",
    "    # print(\"sequence shape\", seq.shape)\n",
    "    L, D = seq.shape\n",
    "    # print(\"mode = \", mode)\n",
    "\n",
    "    if L > max_len:\n",
    "        return seq[:max_len] # truncate if too long\n",
    "\n",
    "    elif L < max_len:\n",
    "        total_padding = max_len - L\n",
    "        \n",
    "        if mode:\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "            \n",
    "        else:\n",
    "            pad_start = 0\n",
    "            pad_end = total_padding\n",
    "\n",
    "        start_padding = np.full((pad_start, D), pad_value, dtype=dtype)\n",
    "        end_padding = np.full((pad_end, D), pad_value, dtype=dtype)\n",
    "        padded = np.vstack((start_padding, seq, end_padding))\n",
    "        # print(\"padded shape\", padded.shape)\n",
    "        return padded\n",
    "\n",
    "    else:\n",
    "        return seq.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a0242b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2fe10b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoBranchGestureModel(nn.Module):\n",
    "    def __init__(self, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "        super().__init__()\n",
    "        self.imu_dim = imu_dim\n",
    "        self.tof_dim = tof_dim\n",
    "        \n",
    "        # IMU deep branch\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualSEBlock1D(imu_dim, 64, kernel_size=3, dropout=0.1),\n",
    "            ResidualSEBlock1D(64, 128, kernel_size=5, dropout=0.1)\n",
    "        )\n",
    "\n",
    "        # TOF Lighter branch\n",
    "        self.tof_branch = nn.Sequential(\n",
    "            nn.Conv1d(tof_dim, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        # self.lstm = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n",
    "        self.gru = nn.GRU(256, 128, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Gaussian noise (manual) and projection\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Dropout(0.09),\n",
    "            nn.Linear(256, 16),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.pre_attn_dropout = nn.Dropout(0.4)\n",
    "        self.attn = AttentionLayer(128*2 + 16)  #128*2 + 128*2 + 16\n",
    "\n",
    "        # Dense layer\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(272, 128, bias=False),  #528\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0,3),\n",
    "            nn.Linear(128, 64, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, n_classes),  # Softmax handled by loss (e.g., CrossEntropyLoss)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        imu = x[:, :, :self.imu_dim].permute(0, 2, 1) #(B, imu_dim, T)\n",
    "        tof = x[: ,:, self.imu_dim:].permute(0, 2, 1) #(B, tof_dim, T)\n",
    "\n",
    "        imu_feat = self.imu_branch(imu)\n",
    "        tof_feat = self.tof_branch(tof)\n",
    "\n",
    "        imu_feat = imu_feat.permute(0, 2, 1)\n",
    "        tof_feat = tof_feat.permute(0, 2, 1)\n",
    "\n",
    "        merged = torch.cat([imu_feat, tof_feat], dim=-1)  #(B, T', 256)\n",
    "\n",
    "        # xa, _ = self.lstm(merged)  # → 256\n",
    "        # xb, _ = self.gru(merged)  # → 256\n",
    "        # xc = self.projection(merged)  # → 16\n",
    "\n",
    "        x_seq, _ = self.gru(merged)  #(B, T', 256)\n",
    "        x_proj = self.projection(merged)  #(B, T', 16)\n",
    "\n",
    "        x_cat = torch.cat([x_seq, x_proj], dim=-1)  #(B, T', 272)\n",
    "        x_cat = self.pre_attn_dropout(x_cat)\n",
    "        context = self.attn(x_cat)  #(B, 272)\n",
    "\n",
    "        return self.mlp(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b507c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      " Calculating base engineered IMU features (magnitude, angle) ...\n",
      " Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\n",
      " 6 Removing gravity and calculating linear acceleration features...\n",
      " 5 Calculating angular velocity from quaternion derivatives...\n",
      " 4 Calculating angular distance between successive quaternions...\n",
      "  IMU (incl. engineered & derivatives) 17 | THM + Aggregated TOF 25 | total 42 features\n",
      " 3 Building sequences with aggregated TOF and preparing data for scaler...\n",
      " 2 Fitting StandardScaler...\n",
      " 1 Scaling and padding sequences...\n",
      " 0 Splitting data and preparing for training...\n",
      "✅ Train completed\n"
     ]
    }
   ],
   "source": [
    "### DATA CREATION\n",
    "print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "\n",
    "train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "gesture_classes = le.classes_\n",
    "\n",
    "print(\" Calculating base engineered IMU features (magnitude, angle) ...\")\n",
    "df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "df['rot_angle'] = 2* np.arccos(df['rot_w'].clip(-1, 1))\n",
    "\n",
    "print(\" Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\")\n",
    "df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n",
    "\n",
    "print(\" 6 Removing gravity and calculating linear acceleration features...\")\n",
    "\n",
    "linear_accel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n",
    "    linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n",
    "\n",
    "df_linear_accel = pd.concat(linear_accel_list)\n",
    "df = pd.concat([df, df_linear_accel], axis=1)\n",
    "\n",
    "df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "\n",
    "print(\" 5 Calculating angular velocity from quaternion derivatives...\")\n",
    "angular_vel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n",
    "    angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n",
    "\n",
    "df_angular_vel = pd.concat(angular_vel_list)\n",
    "df = pd.concat([df, df_angular_vel], axis=1)\n",
    "\n",
    "print(\" 4 Calculating angular distance between successive quaternions...\")\n",
    "angular_distance_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_dist_group = calculate_angular_distance(rot_data_group)\n",
    "    angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n",
    "\n",
    "df_angular_distance = pd.concat(angular_distance_list)\n",
    "df = pd.concat([df, df_angular_distance], axis=1)\n",
    "\n",
    "meta_cols = { } # This was an empty dict in your provided code, keeping it as is.\n",
    "\n",
    "imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
    "imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n",
    "\n",
    "imu_engineered_features = [\n",
    "    'acc_mag', 'rot_angle',\n",
    "    'acc_mag_jerk', 'rot_angle_vel',\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', # Existing new features\n",
    "    'angular_distance' # Added new feature\n",
    "]\n",
    "imu_cols = imu_cols_base + imu_engineered_features\n",
    "imu_cols = list(dict.fromkeys(imu_cols)) # Для удаления дубликатов\n",
    "\n",
    "thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n",
    "\n",
    "## tof data\n",
    "tof_aggregated_cols_template = []\n",
    "for i in range(1, 6):\n",
    "    tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n",
    "imu_dim_final = len(imu_cols)\n",
    "tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "\n",
    "print(f\"  IMU (incl. engineered & derivatives) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n",
    "np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "print(\" 3 Building sequences with aggregated TOF and preparing data for scaler...\")\n",
    "seq_gp = df.groupby('sequence_id') \n",
    "\n",
    "all_steps_for_scaler_list = []\n",
    "X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n",
    "\n",
    "for seq_id, seq_df_orig in seq_gp:\n",
    "    seq_df = seq_df_orig.copy()\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "        tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n",
    "        seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n",
    "        seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n",
    "        seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n",
    "        seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n",
    "    \n",
    "    mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    \n",
    "    all_steps_for_scaler_list.append(mat_unscaled)\n",
    "    X_list_unscaled.append(mat_unscaled)\n",
    "    y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n",
    "    lens.append(len(mat_unscaled))\n",
    "\n",
    "# fit scaler\n",
    "print(\" 2 Fitting StandardScaler...\")\n",
    "all_steps_concatenated = np.concatenate(all_steps_for_scaler_list, axis=0)\n",
    "scaler = StandardScaler().fit(all_steps_concatenated)\n",
    "joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n",
    "del all_steps_for_scaler_list, all_steps_concatenated\n",
    "\n",
    "# scale individual sequences\n",
    "print(\" 1 Scaling and padding sequences...\")\n",
    "X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n",
    "del X_list_unscaled\n",
    "\n",
    "# calculate pad length\n",
    "pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n",
    "np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n",
    "\n",
    "# padding section\n",
    "X_padded_np = np.stack([pad_or_truncate(seq, pad_len) for seq in X_scaled_list])\n",
    "X = torch.tensor(X_padded_np, dtype=torch.float32)  # shape: (N, T, D)\n",
    "del X_scaled_list\n",
    "\n",
    "y_int_for_stratify = np.array(y_list_int_for_stratify)\n",
    "y = F.one_hot(torch.tensor(y_int_for_stratify), num_classes=len(le.classes_)).float()\n",
    "\n",
    "print(\" 0 Splitting data and preparing for training...\")\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=82, stratify=y_int_for_stratify)\n",
    "\n",
    "cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_int_for_stratify)\n",
    "\n",
    "# Data Loader\n",
    "train_dataset = MixupGenerator(X_tr, y_tr, alpha=0.2, time_cutmix=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = MixupGenerator(X_val, y_val, alpha=0.2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(\"✅ Train completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6f95d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xb :torch.Size([256, 127, 42])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 2.4570 | Train Acc: 0.2695\n",
      "Epoch 0 | Val Acc: 0.3844\n",
      "Current Best Accuracy is 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 2.0088 | Train Acc: 0.4644\n",
      "Epoch 1 | Val Acc: 0.5083\n",
      "Current Best Accuracy is 0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.8691 | Train Acc: 0.5460\n",
      "Epoch 2 | Val Acc: 0.5763\n",
      "Current Best Accuracy is 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.7851 | Train Acc: 0.5807\n",
      "Epoch 3 | Val Acc: 0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.7595 | Train Acc: 0.5980\n",
      "Epoch 4 | Val Acc: 0.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.7396 | Train Acc: 0.6074\n",
      "Epoch 5 | Val Acc: 0.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.6984 | Train Acc: 0.6304\n",
      "Epoch 6 | Val Acc: 0.6131\n",
      "Current Best Accuracy is 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.6573 | Train Acc: 0.6477\n",
      "Epoch 7 | Val Acc: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.6371 | Train Acc: 0.6581\n",
      "Epoch 8 | Val Acc: 0.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.6242 | Train Acc: 0.6825\n",
      "Epoch 9 | Val Acc: 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.6022 | Train Acc: 0.6906\n",
      "Epoch 10 | Val Acc: 0.6278\n",
      "Current Best Accuracy is 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.5915 | Train Acc: 0.7038\n",
      "Epoch 11 | Val Acc: 0.6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.5768 | Train Acc: 0.7035\n",
      "Epoch 12 | Val Acc: 0.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.5486 | Train Acc: 0.7153\n",
      "Epoch 13 | Val Acc: 0.6432\n",
      "Current Best Accuracy is 0.6432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.5413 | Train Acc: 0.7287\n",
      "Epoch 14 | Val Acc: 0.6757\n",
      "Current Best Accuracy is 0.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.5067 | Train Acc: 0.7417\n",
      "Epoch 15 | Val Acc: 0.6622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.5170 | Train Acc: 0.7463\n",
      "Epoch 16 | Val Acc: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 1.4774 | Train Acc: 0.7549\n",
      "Epoch 17 | Val Acc: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 1.4663 | Train Acc: 0.7730\n",
      "Epoch 18 | Val Acc: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 1.4768 | Train Acc: 0.7653\n",
      "Epoch 19 | Val Acc: 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 1.4366 | Train Acc: 0.7779\n",
      "Epoch 20 | Val Acc: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 1.4277 | Train Acc: 0.7844\n",
      "Epoch 21 | Val Acc: 0.6941\n",
      "Current Best Accuracy is 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 1.4181 | Train Acc: 0.7883\n",
      "Epoch 22 | Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 1.3981 | Train Acc: 0.7946\n",
      "Epoch 23 | Val Acc: 0.6990\n",
      "Current Best Accuracy is 0.6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 1.3813 | Train Acc: 0.8067\n",
      "Epoch 24 | Val Acc: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 1.3846 | Train Acc: 0.8071\n",
      "Epoch 25 | Val Acc: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 1.3930 | Train Acc: 0.8118\n",
      "Epoch 26 | Val Acc: 0.7155\n",
      "Current Best Accuracy is 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 1.3777 | Train Acc: 0.8153\n",
      "Epoch 27 | Val Acc: 0.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 1.3473 | Train Acc: 0.8242\n",
      "Epoch 28 | Val Acc: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 1.3582 | Train Acc: 0.8181\n",
      "Epoch 29 | Val Acc: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 1.3327 | Train Acc: 0.8344\n",
      "Epoch 30 | Val Acc: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 1.3308 | Train Acc: 0.8416\n",
      "Epoch 31 | Val Acc: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 1.3302 | Train Acc: 0.8363\n",
      "Epoch 32 | Val Acc: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 1.3229 | Train Acc: 0.8365\n",
      "Epoch 33 | Val Acc: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 1.3032 | Train Acc: 0.8498\n",
      "Epoch 34 | Val Acc: 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 1.3124 | Train Acc: 0.8538\n",
      "Epoch 35 | Val Acc: 0.7039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 1.3183 | Train Acc: 0.8434\n",
      "Epoch 36 | Val Acc: 0.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 1.3088 | Train Acc: 0.8517\n",
      "Epoch 37 | Val Acc: 0.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 1.3004 | Train Acc: 0.8548\n",
      "Epoch 38 | Val Acc: 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 1.2859 | Train Acc: 0.8673\n",
      "Epoch 39 | Val Acc: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 1.2690 | Train Acc: 0.8704\n",
      "Epoch 40 | Val Acc: 0.7210\n",
      "Current Best Accuracy is 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 1.2736 | Train Acc: 0.8683\n",
      "Epoch 41 | Val Acc: 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 1.2690 | Train Acc: 0.8712\n",
      "Epoch 42 | Val Acc: 0.6910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 1.2762 | Train Acc: 0.8744\n",
      "Epoch 43 | Val Acc: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 1.2688 | Train Acc: 0.8722\n",
      "Epoch 44 | Val Acc: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 1.2624 | Train Acc: 0.8660\n",
      "Epoch 45 | Val Acc: 0.7302\n",
      "Current Best Accuracy is 0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 1.2433 | Train Acc: 0.8844\n",
      "Epoch 46 | Val Acc: 0.7124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 1.2402 | Train Acc: 0.8842\n",
      "Epoch 47 | Val Acc: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 1.2348 | Train Acc: 0.8911\n",
      "Epoch 48 | Val Acc: 0.7039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 1.2397 | Train Acc: 0.8863\n",
      "Epoch 49 | Val Acc: 0.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 1.2326 | Train Acc: 0.8902\n",
      "Epoch 50 | Val Acc: 0.7045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 1.2366 | Train Acc: 0.8876\n",
      "Epoch 51 | Val Acc: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 1.2443 | Train Acc: 0.8837\n",
      "Epoch 52 | Val Acc: 0.6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 1.2491 | Train Acc: 0.8893\n",
      "Epoch 53 | Val Acc: 0.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 1.2338 | Train Acc: 0.8933\n",
      "Epoch 54 | Val Acc: 0.7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 1.2368 | Train Acc: 0.8827\n",
      "Epoch 55 | Val Acc: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 1.2263 | Train Acc: 0.8859\n",
      "Epoch 56 | Val Acc: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 1.2218 | Train Acc: 0.8971\n",
      "Epoch 57 | Val Acc: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 1.2195 | Train Acc: 0.8980\n",
      "Epoch 58 | Val Acc: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 1.2340 | Train Acc: 0.8920\n",
      "Epoch 59 | Val Acc: 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 1.2186 | Train Acc: 0.8945\n",
      "Epoch 60 | Val Acc: 0.7443\n",
      "Current Best Accuracy is 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 1.2154 | Train Acc: 0.8977\n",
      "Epoch 61 | Val Acc: 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 1.2197 | Train Acc: 0.8942\n",
      "Epoch 62 | Val Acc: 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 1.1980 | Train Acc: 0.8998\n",
      "Epoch 63 | Val Acc: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 1.1897 | Train Acc: 0.9058\n",
      "Epoch 64 | Val Acc: 0.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 1.1987 | Train Acc: 0.9044\n",
      "Epoch 65 | Val Acc: 0.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 1.1944 | Train Acc: 0.9037\n",
      "Epoch 66 | Val Acc: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 1.1832 | Train Acc: 0.9126\n",
      "Epoch 67 | Val Acc: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 1.2012 | Train Acc: 0.9002\n",
      "Epoch 68 | Val Acc: 0.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 1.1869 | Train Acc: 0.9074\n",
      "Epoch 69 | Val Acc: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 1.1738 | Train Acc: 0.9160\n",
      "Epoch 70 | Val Acc: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 1.1948 | Train Acc: 0.9115\n",
      "Epoch 71 | Val Acc: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 1.1934 | Train Acc: 0.9087\n",
      "Epoch 72 | Val Acc: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 1.1799 | Train Acc: 0.9107\n",
      "Epoch 73 | Val Acc: 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 1.1930 | Train Acc: 0.9061\n",
      "Epoch 74 | Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 1.1780 | Train Acc: 0.9123\n",
      "Epoch 75 | Val Acc: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 1.1747 | Train Acc: 0.9152\n",
      "Epoch 76 | Val Acc: 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 1.1783 | Train Acc: 0.9118\n",
      "Epoch 77 | Val Acc: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 1.1749 | Train Acc: 0.9120\n",
      "Epoch 78 | Val Acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 1.1669 | Train Acc: 0.9152\n",
      "Epoch 79 | Val Acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 1.1797 | Train Acc: 0.9190\n",
      "Epoch 80 | Val Acc: 0.7124\n",
      "Early stopping triggered.\n",
      "Best Accuracy was 0.7443\n"
     ]
    }
   ],
   "source": [
    "model = TwoBranchGestureModel(imu_dim=imu_dim_final, tof_dim=tof_thm_aggregated_dim_final, n_classes=len(le.classes_))\n",
    "model.to(device)\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_INIT, weight_decay=WD)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.95)  # T_max = number of epochs\n",
    "weights_tensor = torch.tensor(cw_vals, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience, patience_counter = 20, 0\n",
    "EPOCHS = EPOCHS\n",
    "counter = 0\n",
    "ud = []\n",
    "steps = []\n",
    "lrs = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0         # <-- reset here\n",
    "    total = 0           # <-- reset here\n",
    "    for xb, yb in tqdm.tqdm(train_loader):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        if counter == 0:\n",
    "            print(f\"shape of xb :{xb.shape}\")\n",
    "            counter +=1\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # optional\n",
    "        # Track parameter-wise update dynamixs\n",
    "        with torch.no_grad():\n",
    "            updates = []\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None and p.data.std() > 0:\n",
    "                    ratio = (LR_INIT * p.grad.std() / (p.data.std() + 1e-8))\n",
    "                    ud.append(ratio.log10().item())  # log10 for readability\n",
    "                    \n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # accumulate train data\n",
    "        total_loss += loss.item()\n",
    "        # lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * BATCH_SIZE + counter + 1)\n",
    "\n",
    "        pred_labels = preds.argmax(dim=1)\n",
    "        yb = yb.argmax(dim=1)\n",
    "        correct += (pred_labels == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    \n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Train Loss: {total_loss / len(train_loader):.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            pred_labels = preds.argmax(1)\n",
    "            true_labels = yb.argmax(1)\n",
    "            correct += (pred_labels == true_labels).sum().item()\n",
    "            total += yb.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'model.state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'epoch': epoch\n",
    "            }, EXPORT_DIR / \"best_model.pt\")\n",
    "        print(f\"Current Best Accuracy is {best_val_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "print(f\"Best Accuracy was {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6fb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a8ccce4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (899083737.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[201]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mbreak\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'break' outside loop\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ud)\n",
    "\n",
    "break\n",
    "\n",
    "checkpoint = torch.load(EXPORT_DIR / \"checkpoint.pt\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "best_val_acc = checkpoint['best_val_acc']\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize at the start of training or epoch\n",
    "ud_dict = {}  # key: layer name, value: list of ud values over time\n",
    "\n",
    "# During training step\n",
    "for name, p in model.named_parameters():\n",
    "    if \"layer_name\" in name and p.grad is not None and p.data.std() > 0:\n",
    "        ratio = (LR_INIT * p.grad.std() / (p.data.std() + 1e-8))\n",
    "        log_ratio = ratio.log10().item()\n",
    "\n",
    "        # Accumulate history per layer\n",
    "        if name not in ud_dict:\n",
    "            ud_dict[name] = []\n",
    "        ud_dict[name].append(log_ratio)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for layer_name, ud_values in ud_dict.items():\n",
    "    plt.plot(ud_values, label=layer_name)\n",
    "\n",
    "plt.xlabel(\"Training step or epoch\")\n",
    "plt.ylabel(\"log10(update/data ratio)\")\n",
    "plt.title(\"Update-to-Data Ratio per Layer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fca264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out H-F1 = 0.3496\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(EXPORT_DIR / \"best_model.pt\"))\n",
    "model.eval()\n",
    "preds_val = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, _ in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds_val.append(logits.argmax(1).cpu())\n",
    "\n",
    "preds_val = torch.cat(preds_val).numpy()\n",
    "true_val_int = y_val.argmax(1).numpy()\n",
    "\n",
    "# Evaluation\n",
    "from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "\n",
    "h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "    pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n",
    "    pd.DataFrame({'gesture': le.classes_[preds_val]})\n",
    ")\n",
    "print(\"Hold-out H-F1 =\", round(h_f1, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
