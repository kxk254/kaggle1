{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c3ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, joblib, re\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import gc  # garbage collection\n",
    "import psutil\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f820e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · torch 2.7.1+cu128 device : cuda\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "\n",
    "class config:\n",
    "    AMP = False\n",
    "    BATCH_SIZE_TRAIN = 8 #32\n",
    "    BATCH_SIZE_VALID = 8 #32\n",
    "    DEBUG = False\n",
    "    EPOCHS = 2  #30\n",
    "    FOLDS = 5\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    LEARNING_RATE = 1e-3\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    PAD_PERCENTILE = 95\n",
    "    SEQUENCE_LENGTH = 150\n",
    "\n",
    "class paths:\n",
    "    BASE_DIR = Path(\"C:/Users/konno/SynologyDrive/datasciense/projects_foler/1_kaggle/CMI/cmi-detect-behavior-with-sensor-data\")\n",
    "    \n",
    "    OUTPUT_DIR = BASE_DIR / \"output-02-wavenet\"\n",
    "    TEST_CSV = BASE_DIR / \"test.csv\"\n",
    "    TEST_DEMOGRAPHICS = BASE_DIR / \"test_demographics.csv\"\n",
    "    TRAIN_CSV = BASE_DIR / \"train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = BASE_DIR / \"train_demographics.csv\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"▶ imports ready · torch\", torch.__version__, \"device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a92808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39b94e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, imu_cols, tof_columns, sequence_ids, max_len=103, mode=TRAIN):\n",
    "        self.df = df\n",
    "        self.imu_cols = imu_cols\n",
    "        self.tof_columns = tof_columns\n",
    "        self.sequence_ids = sequence_ids\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        self.grouped = df.groupby('sequence_id')\n",
    "        self.label_map = {s: i for i, s in enumerate(sorted(df['gesture'].unique()))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_id = self.sequence_ids[idx]\n",
    "        group = self.grouped.get_group(seq_id)\n",
    "\n",
    "        tof_values = group[self.tof_columns].values.astype(np.float32)\n",
    "        imu_values = group[self.imu_cols].values.astype(np.float32)\n",
    "\n",
    "        # Pad or truncate\n",
    "        tof_padded = pad_or_truncate(tof_values, self.max_len, self.mode)\n",
    "        imu_padded = pad_or_truncate(imu_values, self.max_len, self.mode)\n",
    "\n",
    "        tof_input = tof_padded.T  #(320, T)\n",
    "        imu_input = imu_padded.T  #(35, T)\n",
    "\n",
    "        label = self.label_map[group['gesture'].iloc[0]]\n",
    "\n",
    "        return {\n",
    "            \"x_tof\": torch.tensor(tof_input, dtype=torch.float32),\n",
    "            \"x_imu\": torch.tensor(imu_input, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(label, dtype=torch.long),\n",
    "            \"sequence_id\": seq_id\n",
    "        }\n",
    "    \n",
    "# train_dataset = MixupDataset(config, df_train, X_tr, y_tr, y_soft_tr)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE_TRAIN, shuffle=True)\n",
    "# val_dataset = CustomDataset(config, df_train, X_val, y_val, y_soft_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE_VALID, shuffle=True)\n",
    "\n",
    "def pad_or_truncate(seq, max_len, mode=TRAIN, pad_value=0.0, dtype=np.float32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pads or truncates a sequence to a fixed length.\n",
    "\n",
    "    Parameters:\n",
    "    - seq: np.ndarray of shape (L, D)\n",
    "    - max_len: int, desired sequence length\n",
    "    - mode: bool, True = random pad, False = regular pad\n",
    "    - pad_value: float or int, value to use for padding\n",
    "    - dtype: np.dtype, dtype for the output array\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray of shape (max_len, D)\n",
    "    \"\"\"\n",
    "    # print(\"sequence shape\", seq.shape)\n",
    "    L, D = seq.shape\n",
    "    # print(\"mode = \", mode)\n",
    "\n",
    "    if L > max_len:\n",
    "        return seq[:max_len] # truncate if too long\n",
    "\n",
    "    elif L < max_len:\n",
    "        total_padding = max_len - L\n",
    "        \n",
    "        if mode:\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "            \n",
    "        else:\n",
    "            pad_start = 0\n",
    "            pad_end = total_padding\n",
    "\n",
    "        start_padding = np.full((pad_start, D), pad_value, dtype=dtype)\n",
    "        end_padding = np.full((pad_end, D), pad_value, dtype=dtype)\n",
    "        padded = np.vstack((start_padding, seq, end_padding))\n",
    "        # print(\"padded shape\", padded.shape)\n",
    "        return padded\n",
    "\n",
    "    else:\n",
    "        return seq.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce8f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "# Create Spatial Adjacency Matrix\n",
    "def create_8x8_grid_adjacency():\n",
    "    adj = np.zeros((64, 64), dtype=int)\n",
    "    for r in range(8):\n",
    "        for c in range(8):\n",
    "            idx = r * 8 + c\n",
    "            if r > 0: adj[idx][(r - 1) * 8 + c] = 1\n",
    "            if r < 7: adj[idx][(r + 1) * 8 + c] = 1\n",
    "            if c > 0: adj[idx][r * 8 + (c - 1)] = 1\n",
    "            if c < 7: adj[idx][r * 8 + (c + 1)] = 1\n",
    "    return adj\n",
    "\n",
    "def print_memory():\n",
    "    process = psutil.Process()\n",
    "    print(f\"Memory Usage: {process.memory_info().rss / 1024**2:.2f} MB\")\n",
    "\n",
    "def parse_tof_column(col):\n",
    "    # Match patterns like 'tof_1_v42' or 'tof_1_v42_norm'\n",
    "    match = re.match(r\"tof_(\\d+)_v(\\d+)\", col)\n",
    "    if match:\n",
    "        sensor_num = int(match.group(1))\n",
    "        pixel_num = int(match.group(2))\n",
    "        return (sensor_num, pixel_num)\n",
    "    else:\n",
    "        return (float('inf'), float('inf'))  # put unmatchable columns at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8e2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STGCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, A, stride=1, residual=True):\n",
    "        super().__init__()\n",
    "        # Temporal convolution: shape = (kernel_size, 1)\n",
    "        self.A = A  # Adjacency matrix: (V, V)\n",
    "        self.num_nodes = A.shape[0]\n",
    "        # self.gcn = GraphConv(in_channels, out_channels)  # Spatial convolution (GCN)\n",
    "        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(9,1),\n",
    "                      padding=(4,0), stride=(stride,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        if residual is False:\n",
    "            self.residual = nn.Identity()\n",
    "        elif in_channels != out_channels or stride != 1:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "        # print(f\"Residual module for block: {self.residual}\")\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):  # x: [B, C, T, V], A: adjacency matrix\n",
    "        # x shape: (N, C, T, V)\n",
    "        # N, C, T, V = x.size()\n",
    "        res = x\n",
    "        A = self.A.to(x.device)  # ensure A is on the same device\n",
    "\n",
    "        # Graph convolution: multiply input by adjacency matrix\n",
    "        x = torch.einsum('nctv,vw->nctw', (x, A))  # shape: (N, C, T, V)\n",
    "\n",
    "        x = self.gcn(x)  # (N, out_channels, T, V)\n",
    "        x = self.tcn(x)  # temporal conv\n",
    "        # print(f\"x shape: {x.shape}, res shape: {res.shape}\")\n",
    "        res = self.residual(res)\n",
    "        # print(f\"res after residual conv shape: {res.shape}\")\n",
    "        x = x + res  # add residual\n",
    "        return self.relu(x)\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, A, num_nodes):\n",
    "        super().__init__()\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * num_nodes)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            STGCNBlock(in_channels, 64, A),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 128, A, stride=2),\n",
    "            STGCNBlock(128, 128, A),\n",
    "            STGCNBlock(128, 256, A, stride=2),\n",
    "            STGCNBlock(256, 256, A)\n",
    "        ])\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # output shape: (N, C, 1, 1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T, N)\n",
    "        # print(f\"in_channels: {self.data_bn.num_features}\")\n",
    "        # print(f\"input x shape before BN: {x.shape}\")\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()  # (N, C, T, V)\n",
    "\n",
    "        for gcn in self.layers:\n",
    "            x = gcn(x)\n",
    "\n",
    "        x = self.pool(x)  # (N, C, 1, 1)\n",
    "        x = x.view(N, -1)  # flatten\n",
    "        return self.fc(x)  # logits: (N, num_classes)\n",
    "\n",
    "class DualSTGCN(nn.Module):\n",
    "    def __init__(self, in_channels_imu, in_channels_tof, num_classes, A, num_nodes):\n",
    "        super().__init__()\n",
    "        self.stgcn_imu = STGCN(in_channels_imu, 256, A, num_nodes)\n",
    "        self.stgcn_tof = STGCN(in_channels_tof, 256, A, num_nodes)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_imu, x_tof):\n",
    "        # Each input: (B, C, T, N)\n",
    "        feat_imf = self.stgcn_imu(x_imu)  # (B, C, T, N)(320, 35)\n",
    "        feat_tof = self.stgcn_tof(x_tof)  # (B, C, T, N)(320, 320)\n",
    "\n",
    "        x = torch.cat([feat_imf, feat_tof], dim=1)  # (N, 512)\n",
    "        out = self.classifier(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75992ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      "merged df shape : (574945, 348)\n",
      "Memory Usage: 3637.84 MB\n",
      " 0/6 Calculating elbow_to_wrist_cm shoulder_to_wrist_cm adjustment ...\n",
      " 1/6 Calculating base engineered IMU features (magnitude, angle) ...\n",
      " 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\n",
      " 3/6 Removing gravity and calculating linear acceleration features...\n",
      " 4/6 Calculating angular velocity from quaternion derivatives...\n",
      " 5/6 Calculating angular distance between successive quaternions...\n",
      "Memory Usage: 5354.48 MB\n",
      " 6/6 Calculating imu_cols_base ...\n",
      "length of imu_cols : 35\n",
      "✅ Preprocessing done.\n",
      "Memory Usage: 5354.48 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CREATION and PRE PROCESSING\n",
    "\n",
    "print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "\n",
    "df_data = pd.read_csv(paths.TRAIN_CSV)\n",
    "df_data = df_data.fillna(0)\n",
    "\n",
    "train_dem_df = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)\n",
    "df = pd.merge(df_data.copy(), train_dem_df, on='subject', how='left')\n",
    "print(\"merged df shape :\", df.shape)\n",
    "\n",
    "print_memory()\n",
    "\n",
    "print(\" 0/6 Calculating elbow_to_wrist_cm shoulder_to_wrist_cm adjustment ...\")\n",
    "\n",
    "df[\"acc_x_norm_ew\"] = df[\"acc_x\"] / df[\"elbow_to_wrist_cm\"]\n",
    "df[\"acc_y_norm_ew\"] = df[\"acc_y\"] / df[\"elbow_to_wrist_cm\"]\n",
    "df[\"acc_z_norm_ew\"] = df[\"acc_z\"] / df[\"elbow_to_wrist_cm\"]\n",
    "\n",
    "df[\"acc_x_norm_sw\"] = df[\"acc_x\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "df[\"acc_y_norm_sw\"] = df[\"acc_y\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "df[\"acc_z_norm_sw\"] = df[\"acc_z\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "\n",
    "print(\" 1/6 Calculating base engineered IMU features (magnitude, angle) ...\")\n",
    "\n",
    "df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "df['rot_angle'] = 2* np.arccos(df['rot_w'].clip(-1, 1))\n",
    "\n",
    "print(\" 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\")\n",
    "\n",
    "df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n",
    "\n",
    "print(\" 3/6 Removing gravity and calculating linear acceleration features...\")\n",
    "\n",
    "linear_accel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n",
    "    linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n",
    "\n",
    "df_linear_accel = pd.concat(linear_accel_list)\n",
    "df = pd.concat([df, df_linear_accel], axis=1)\n",
    "del df_linear_accel, linear_accel_list  # Memory Management\n",
    "gc.collect()  # Memory Management\n",
    "\n",
    "df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "\n",
    "print(\" 4/6 Calculating angular velocity from quaternion derivatives...\")\n",
    "angular_vel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n",
    "    angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n",
    "\n",
    "df_angular_vel = pd.concat(angular_vel_list)\n",
    "df = pd.concat([df, df_angular_vel], axis=1)\n",
    "del angular_vel_list, df_angular_vel # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "\n",
    "print(\" 5/6 Calculating angular distance between successive quaternions...\")\n",
    "angular_distance_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_dist_group = calculate_angular_distance(rot_data_group)\n",
    "    angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n",
    "\n",
    "df_angular_distance = pd.concat(angular_distance_list)\n",
    "df = pd.concat([df, df_angular_distance], axis=1)\n",
    "del angular_distance_list, df_angular_distance # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "print_memory()\n",
    "\n",
    "meta_cols = { } # This was an empty dict in your provided code, keeping it as is.\n",
    "\n",
    "print(\" 6/6 Calculating imu_cols_base ...\")\n",
    "imu_cols_orig = ['acc_x', 'acc_y', 'acc_z',\n",
    "            'rot_w', 'rot_x', 'rot_y', 'rot_z',\n",
    "            'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
    "\n",
    "imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
    "imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n",
    "\n",
    "imu_engineered_features = [\n",
    "    'acc_x_norm_ew', 'acc_y_norm_ew', 'acc_z_norm_ew',  # new from demographics\n",
    "    'acc_x_norm_sw', 'acc_y_norm_sw', 'acc_z_norm_sw',  # new from demographics\n",
    "    'acc_mag', 'rot_angle',\n",
    "    'acc_mag_jerk', 'rot_angle_vel',\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', # Existing new features\n",
    "    'angular_distance' # Added new feature\n",
    "]\n",
    "\n",
    "dem_features = [\n",
    "    'adult_child', 'age',\n",
    "    'sex', 'handedness',\n",
    "]\n",
    "\n",
    "imu_cols = list(dict.fromkeys(imu_cols_orig + imu_cols_base + imu_engineered_features + dem_features))  # Remove dups\n",
    "\n",
    "print(\"length of imu_cols :\", len(imu_cols),)\n",
    "\n",
    "\n",
    "# print(\"ToF normalization :\")\n",
    "\n",
    "# tof_cols = [col for col in df.columns if col.startswith(\"tof_\")]\n",
    "# for col in tof_cols:\n",
    "#     df[f\"{col}_norm\"] = df[col] / df[\"shoulder_to_wrist_cm\"]\n",
    "\n",
    "print(\"✅ Preprocessing done.\")\n",
    "print_memory()\n",
    "\n",
    "# thm_cols_original = [c for c in df.columns if c.startswith('thm_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbb0061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – configuring dataset …\n",
      "tof_columns length : 320\n",
      "SEQUENCE_LENGTH : 103\n",
      "full adjusted shape : (320, 320)\n",
      "number of classes : 18\n",
      "Memory Usage: 5671.60 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CONFIGURATION\n",
    "print(\"▶ TRAIN MODE – configuring dataset …\")\n",
    "\n",
    "# train_dem_df = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)\n",
    "# df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n",
    "# print(\"df for group shape :\", df_for_groups.shape)\n",
    "\n",
    "\n",
    "# Extract and Sort TOF Columns\n",
    "# Get only tof columns\n",
    "tof_columns = [col for col in df.columns if col.startswith(\"tof_\")]\n",
    "# Sort them safely\n",
    "tof_columns = sorted(tof_columns, key=parse_tof_column)\n",
    "\n",
    "sequence_ids = df[\"sequence_id\"].unique()\n",
    "\n",
    "print(\"tof_columns length :\", len(tof_columns))\n",
    "\n",
    "# Group by Sequence and Reshape\n",
    "grouped = df.groupby('sequence_id')\n",
    "\n",
    "# Estimate the max length\n",
    "sequence_lengths = grouped.size().values  # length of each sequence\n",
    "SEQUENCE_LENGTH = int(np.percentile(sequence_lengths, 90))\n",
    "print(\"SEQUENCE_LENGTH :\", SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    sequence_ids,\n",
    "    test_size=0.2,  # 20% validation\n",
    "    random_state=42,\n",
    "    stratify=df.groupby(\"sequence_id\")[\"gesture\"].first()  # keeps gesture label distribution balanced\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = MotionDataset(df, imu_cols, tof_columns, train_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "val_dataset   = MotionDataset(df, imu_cols, tof_columns, val_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE_TRAIN, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=config.BATCH_SIZE_VALID, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "# Combine adjacency matrices for all 5 sensors (block-diagonal)\n",
    "from scipy.linalg import block_diag\n",
    "sensor_adj = create_8x8_grid_adjacency()\n",
    "full_adj = block_diag(*[sensor_adj] * 5)  # shape: (320, 320)\n",
    "print(\"full adjusted shape :\", full_adj.shape)\n",
    "\n",
    "# Step 2: Add cross-edges between corresponding raw and normalized pixels  we can skip this \n",
    "# for sensor_idx in range(5):  # 5 sensors\n",
    "#     for pixel_idx in range(64):  # 64 pixels per sensor\n",
    "#         raw_node = sensor_idx * 64 + pixel_idx\n",
    "#         norm_node = (sensor_idx + 5) * 64 + pixel_idx  # 5 sensors later\n",
    "#         full_adj[raw_node, norm_node] = 1\n",
    "#         full_adj[norm_node, raw_node] = 1  # Undirected edge\n",
    "\n",
    "# print(\"Full adjacency shape:\", full_adj.shape)  # Should be (640, 640)\n",
    "\n",
    "labels = df[\"gesture\"].unique()\n",
    "print(\"number of classes :\", len(labels))\n",
    "\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e11a6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train_loader batches...\n",
      "Dataset length: 6520\n",
      "Batch 0 keys: dict_keys(['x_tof', 'x_imu', 'y', 'sequence_id'])\n",
      "X imu shape: torch.Size([8, 35, 103]) Full batch: B × N × C × T\n",
      "X tof shape: torch.Size([8, 320, 103]) Full batch: B × N × C × T\n",
      "y shape: torch.Size([8])\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking train_loader batches...\")\n",
    "# print(next(iter(train_dataset)))\n",
    "# Each input: (B, C, T, N)\n",
    "\n",
    "print(f\"Dataset length: {len(train_loader.dataset)}\")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i} keys: {batch.keys()}\")\n",
    "    print(f\"X imu shape: {batch['x_imu'].shape} Full batch: B × N × C × T\")  # [B, N, C, T]\n",
    "    print(f\"X tof shape: {batch['x_tof'].shape} Full batch: B × N × C × T\")  # [B, N, C, T]\n",
    "    print(f\"y shape: {batch['y'].shape}\")  # [B]\n",
    "    print(\"=====\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0e9db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the adjacency Matrix\n",
    "A = torch.tensor(full_adj, dtype=torch.float32, device=device)  # (640, 640)\n",
    "\n",
    "\n",
    "model = DualSTGCN(\n",
    "    in_channels_imu=35,         # channels per node (ToF + IMU)\n",
    "    in_channels_tof=320,         # channels per node (ToF + IMU)\n",
    "    num_classes=len(df[\"gesture\"].unique()),  # e.g., 20\n",
    "    A=A,\n",
    "    num_nodes=320,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c34d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏩ training started .....\n",
      "▶️ Setting scheduler  .....\n",
      "✅ Epoch starts .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape xb ->:  torch.Size([8, 35, 103]) batch_idx ->:  0\n",
      "shape xb ->:  torch.Size([8, 320, 103]) batch_idx ->:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mshape xb ->: \u001b[39m\u001b[33m\"\u001b[39m, x_imu.shape, \u001b[33m\"\u001b[39m\u001b[33mbatch_idx ->: \u001b[39m\u001b[33m\"\u001b[39m, batch_idx)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mshape xb ->: \u001b[39m\u001b[33m\"\u001b[39m, x_tof.shape, \u001b[33m\"\u001b[39m\u001b[33mbatch_idx ->: \u001b[39m\u001b[33m\"\u001b[39m, batch_idx)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m x_imu = \u001b[43mx_imu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m x_tof = x_tof.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mshape xb ->: \u001b[39m\u001b[33m\"\u001b[39m, x_imu.shape, \u001b[33m\"\u001b[39m\u001b[33mbatch_idx ->: \u001b[39m\u001b[33m\"\u001b[39m, batch_idx)\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [
    "print(\"⏩ training started .....\")\n",
    "\n",
    "cw_vals = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "weights_tensor = torch.tensor(cw_vals, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "print(\"▶️ Setting scheduler  .....\")\n",
    "steps = []\n",
    "lrs = []\n",
    "best_val_acc = 0\n",
    "patience, patience_counter = 10, 0\n",
    "EPOCHS = config.EPOCHS\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=config.EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.0,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=100,\n",
    ")\n",
    "\n",
    "print(\"✅ Epoch starts .....\")\n",
    "import itertools\n",
    "\n",
    "max_batches = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0         # <-- reset here\n",
    "    total = 0           # <-- reset here\n",
    "    for batch_idx, batch in tqdm.tqdm(enumerate(itertools.islice(train_loader, max_batches))):\n",
    "    # for batch_idx, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "        x_imu, x_tof, yb = batch[\"x_imu\"].to(device), batch[\"x_tof\"].to(device), batch[\"y\"].to(device)\n",
    "        # if batch_idx == 0:\n",
    "        print(\"shape xb ->: \", x_imu.shape, \"batch_idx ->: \", batch_idx)\n",
    "        print(\"shape xb ->: \", x_tof.shape, \"batch_idx ->: \", batch_idx)\n",
    "        x_imu = x_imu.permute(0, 2, 3, 1)\n",
    "        x_tof = x_tof.permute(0, 2, 3, 1)\n",
    "        print(\"shape xb ->: \", x_imu.shape, \"batch_idx ->: \", batch_idx)\n",
    "        print(\"shape xb ->: \", x_tof.shape, \"batch_idx ->: \", batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        preds_cls = model(x_imu, x_tof)\n",
    "        # yb_indices = yb.argmax(dim=1)\n",
    "        loss = loss_fn(preds_cls, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # optional\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * config.BATCH_SIZE_TRAIN + batch_idx)\n",
    "        pred_labels = preds_cls.argmax(dim=1) \n",
    "        correct += (pred_labels == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Train Loss: {total_loss / len(train_loader):.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_imu, x_tof, yb = batch[\"x_imu\"].to(device), batch[\"x_tof\"].to(device), batch[\"y\"].to(device)\n",
    "            x_imu = x_imu.permute(0, 2, 3, 1)\n",
    "            x_tof = x_tof.permute(0, 2, 3, 1)\n",
    "            print(\"shape xb ->: \", x_imu.shape, \"batch_idx ->: \", batch_idx)\n",
    "            print(\"shape xb ->: \", x_tof.shape, \"batch_idx ->: \", batch_idx)\n",
    "            preds_cls = model(x_imu, x_tof)\n",
    "            pred_labels = preds_cls.argmax(1)\n",
    "            true_labels = yb.argmax(1) if yb.ndim > 1 else yb  #.argmax(1)  val_loader comes from a standard dataset with \"y\" as class index (long), you don’t need argmax.\n",
    "            correct += (pred_labels == true_labels).sum().item()\n",
    "            total += yb.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), paths.OUTPUT_DIR / \"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840200d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2138e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c677c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
