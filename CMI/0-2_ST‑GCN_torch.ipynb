{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79b6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, joblib, re\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import gc  # garbage collection\n",
    "import psutil\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82880947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · torch 2.7.1+cpu device : cpu\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "\n",
    "class config:\n",
    "    AMP = False\n",
    "    BATCH_SIZE_TRAIN = 8 #32\n",
    "    BATCH_SIZE_VALID = 8 #32\n",
    "    DEBUG = False\n",
    "    EPOCHS = 2  #30\n",
    "    FOLDS = 5\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    LEARNING_RATE = 1e-3\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    PAD_PERCENTILE = 95\n",
    "    SEQUENCE_LENGTH = 150\n",
    "\n",
    "class paths:\n",
    "    BASE_DIR = Path(\"C:/Users/konno/SynologyDrive/datasciense/projects_foler/1_kaggle/CMI/cmi-detect-behavior-with-sensor-data\")\n",
    "    \n",
    "    OUTPUT_DIR = BASE_DIR / \"output-02-wavenet\"\n",
    "    TEST_CSV = BASE_DIR / \"test.csv\"\n",
    "    TEST_DEMOGRAPHICS = BASE_DIR / \"test_demographics.csv\"\n",
    "    TRAIN_CSV = BASE_DIR / \"train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = BASE_DIR / \"train_demographics.csv\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"▶ imports ready · torch\", torch.__version__, \"device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "179bbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7803102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MixUp the data argumentation in order to regularize the neural network. \n",
    "\n",
    "class MotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, imu_cols, tof_columns, sequence_ids, max_len=103, mode=TRAIN):\n",
    "        self.df = df\n",
    "        self.imu_cols = imu_cols\n",
    "        self.tof_columns = tof_columns\n",
    "        self.sequence_ids = sequence_ids\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        self.grouped = df.groupby('sequence_id')\n",
    "        self.label_map = {s: i for i, s in enumerate(sorted(df['gesture'].unique()))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_id = self.sequence_ids[idx]\n",
    "        group = self.grouped.get_group(seq_id)\n",
    "\n",
    "        tof_values = group[self.tof_columns].values.astype(np.float32)\n",
    "        imu_values = group[self.imu_cols].values.astype(np.float32)\n",
    "\n",
    "        # Pad or truncate\n",
    "        tof_padded = pad_or_truncate(tof_values, self.max_len, self.mode)\n",
    "        imu_padded = pad_or_truncate(imu_values, self.max_len, self.mode)\n",
    "\n",
    "        fused = np.concatenate([tof_padded, imu_padded], axis=1)\n",
    "        fused = fused.T\n",
    "\n",
    "        label = self.label_map[group['gesture'].iloc[0]]\n",
    "\n",
    "        return {\n",
    "            \"X\": torch.tensor(fused, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(label, dtype=torch.long),\n",
    "            \"sequence_id\": seq_id\n",
    "        }\n",
    "    \n",
    "# train_dataset = MixupDataset(config, df_train, X_tr, y_tr, y_soft_tr)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE_TRAIN, shuffle=True)\n",
    "# val_dataset = CustomDataset(config, df_train, X_val, y_val, y_soft_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE_VALID, shuffle=True)\n",
    "\n",
    "def pad_or_truncate(seq, max_len, mode=TRAIN, pad_value=0.0, dtype=np.float32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pads or truncates a sequence to a fixed length.\n",
    "\n",
    "    Parameters:\n",
    "    - seq: np.ndarray of shape (L, D)\n",
    "    - max_len: int, desired sequence length\n",
    "    - mode: bool, True = random pad, False = regular pad\n",
    "    - pad_value: float or int, value to use for padding\n",
    "    - dtype: np.dtype, dtype for the output array\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray of shape (max_len, D)\n",
    "    \"\"\"\n",
    "    # print(\"sequence shape\", seq.shape)\n",
    "    L, D = seq.shape\n",
    "    # print(\"mode = \", mode)\n",
    "\n",
    "    if L > max_len:\n",
    "        return seq[:max_len] # truncate if too long\n",
    "\n",
    "    elif L < max_len:\n",
    "        total_padding = max_len - L\n",
    "        \n",
    "        if mode:\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "            \n",
    "        else:\n",
    "            pad_start = 0\n",
    "            pad_end = total_padding\n",
    "\n",
    "        start_padding = np.full((pad_start, D), pad_value, dtype=dtype)\n",
    "        end_padding = np.full((pad_end, D), pad_value, dtype=dtype)\n",
    "        padded = np.vstack((start_padding, seq, end_padding))\n",
    "        # print(\"padded shape\", padded.shape)\n",
    "        return padded\n",
    "\n",
    "    else:\n",
    "        return seq.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0242b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "# Create Spatial Adjacency Matrix\n",
    "def create_8x8_grid_adjacency():\n",
    "    adj = np.zeros((64, 64), dtype=int)\n",
    "    for r in range(8):\n",
    "        for c in range(8):\n",
    "            idx = r * 8 + c\n",
    "            if r > 0: adj[idx][(r - 1) * 8 + c] = 1\n",
    "            if r < 7: adj[idx][(r + 1) * 8 + c] = 1\n",
    "            if c > 0: adj[idx][r * 8 + (c - 1)] = 1\n",
    "            if c < 7: adj[idx][r * 8 + (c + 1)] = 1\n",
    "    return adj\n",
    "\n",
    "def print_memory():\n",
    "    process = psutil.Process()\n",
    "    print(f\"Memory Usage: {process.memory_info().rss / 1024**2:.2f} MB\")\n",
    "\n",
    "def parse_tof_column(col):\n",
    "    # Match patterns like 'tof_1_v42' or 'tof_1_v42_norm'\n",
    "    match = re.match(r\"tof_(\\d+)_v(\\d+)\", col)\n",
    "    if match:\n",
    "        sensor_num = int(match.group(1))\n",
    "        pixel_num = int(match.group(2))\n",
    "        return (sensor_num, pixel_num)\n",
    "    else:\n",
    "        return (float('inf'), float('inf'))  # put unmatchable columns at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STGCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, A, stride=1, residual=True):\n",
    "        super().__init__()\n",
    "        # Temporal convolution: shape = (kernel_size, 1)\n",
    "        self.A = A  # Adjacency matrix: (V, V)\n",
    "        self.num_nodes = A.shape[0]\n",
    "        # self.gcn = GraphConv(in_channels, out_channels)  # Spatial convolution (GCN)\n",
    "        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(9,1),\n",
    "                      padding=(4,0), stride=(stride,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        if residual is False:\n",
    "            self.residual = nn.Identity()\n",
    "        elif in_channels != out_channels or stride != 1:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "        # print(f\"Residual module for block: {self.residual}\")\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):  # x: [B, C, T, V], A: adjacency matrix\n",
    "        # x shape: (N, C, T, V)\n",
    "        # N, C, T, V = x.size()\n",
    "        res = x\n",
    "        A = self.A.to(x.device)  # ensure A is on the same device\n",
    "\n",
    "        # Graph convolution: multiply input by adjacency matrix\n",
    "        x = torch.einsum('nctv,vw->nctw', (x, A))  # shape: (N, C, T, V)\n",
    "\n",
    "        x = self.gcn(x)  # (N, out_channels, T, V)\n",
    "        x = self.tcn(x)  # temporal conv\n",
    "        # print(f\"x shape: {x.shape}, res shape: {res.shape}\")\n",
    "        res = self.residual(res)\n",
    "        # print(f\"res after residual conv shape: {res.shape}\")\n",
    "        x = x + res  # add residual\n",
    "        return self.relu(x)\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, A, num_nodes):\n",
    "        super().__init__()\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * num_nodes)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            STGCNBlock(in_channels, 64, A),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 128, A, stride=2),\n",
    "            STGCNBlock(128, 128, A),\n",
    "            STGCNBlock(128, 256, A, stride=2),\n",
    "            STGCNBlock(256, 256, A)\n",
    "        ])\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # output shape: (N, C, 1, 1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C, T, V)\n",
    "        # print(f\"in_channels: {self.data_bn.num_features}\")\n",
    "        # print(f\"input x shape before BN: {x.shape}\")\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()  # (N, C, T, V)\n",
    "\n",
    "        for gcn in self.layers:\n",
    "            x = gcn(x)\n",
    "\n",
    "        x = self.pool(x)  # (N, C, 1, 1)\n",
    "        x = x.view(N, -1)  # flatten\n",
    "        return self.fc(x)  # logits: (N, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5c9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      "merged df shape : (574945, 348)\n",
      "Memory Usage: 3399.18 MB\n",
      " 0/6 Calculating elbow_to_wrist_cm shoulder_to_wrist_cm adjustment ...\n",
      " 1/6 Calculating base engineered IMU features (magnitude, angle) ...\n",
      " 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\n",
      " 3/6 Removing gravity and calculating linear acceleration features...\n",
      " 4/6 Calculating angular velocity from quaternion derivatives...\n",
      " 5/6 Calculating angular distance between successive quaternions...\n",
      "Memory Usage: 3469.16 MB\n",
      " 6/6 Calculating imu_cols_base ...\n",
      "length of imu_cols : 35\n",
      "✅ Preprocessing done.\n",
      "Memory Usage: 3469.47 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CREATION and PRE PROCESSING\n",
    "\n",
    "print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "\n",
    "df_data = pd.read_csv(paths.TRAIN_CSV)\n",
    "df_data = df_data.fillna(0)\n",
    "\n",
    "train_dem_df = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)\n",
    "df = pd.merge(df_data.copy(), train_dem_df, on='subject', how='left')\n",
    "print(\"merged df shape :\", df.shape)\n",
    "\n",
    "print_memory()\n",
    "\n",
    "print(\" 0/6 Calculating elbow_to_wrist_cm shoulder_to_wrist_cm adjustment ...\")\n",
    "\n",
    "df[\"acc_x_norm_ew\"] = df[\"acc_x\"] / df[\"elbow_to_wrist_cm\"]\n",
    "df[\"acc_y_norm_ew\"] = df[\"acc_y\"] / df[\"elbow_to_wrist_cm\"]\n",
    "df[\"acc_z_norm_ew\"] = df[\"acc_z\"] / df[\"elbow_to_wrist_cm\"]\n",
    "\n",
    "df[\"acc_x_norm_sw\"] = df[\"acc_x\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "df[\"acc_y_norm_sw\"] = df[\"acc_y\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "df[\"acc_z_norm_sw\"] = df[\"acc_z\"] / df[\"shoulder_to_wrist_cm\"]\n",
    "\n",
    "print(\" 1/6 Calculating base engineered IMU features (magnitude, angle) ...\")\n",
    "\n",
    "df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "df['rot_angle'] = 2* np.arccos(df['rot_w'].clip(-1, 1))\n",
    "\n",
    "print(\" 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\")\n",
    "\n",
    "df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n",
    "\n",
    "print(\" 3/6 Removing gravity and calculating linear acceleration features...\")\n",
    "\n",
    "linear_accel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n",
    "    linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n",
    "\n",
    "df_linear_accel = pd.concat(linear_accel_list)\n",
    "df = pd.concat([df, df_linear_accel], axis=1)\n",
    "del df_linear_accel, linear_accel_list  # Memory Management\n",
    "gc.collect()  # Memory Management\n",
    "\n",
    "df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "\n",
    "print(\" 4/6 Calculating angular velocity from quaternion derivatives...\")\n",
    "angular_vel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n",
    "    angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n",
    "\n",
    "df_angular_vel = pd.concat(angular_vel_list)\n",
    "df = pd.concat([df, df_angular_vel], axis=1)\n",
    "del angular_vel_list, df_angular_vel # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "\n",
    "print(\" 5/6 Calculating angular distance between successive quaternions...\")\n",
    "angular_distance_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_dist_group = calculate_angular_distance(rot_data_group)\n",
    "    angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n",
    "\n",
    "df_angular_distance = pd.concat(angular_distance_list)\n",
    "df = pd.concat([df, df_angular_distance], axis=1)\n",
    "del angular_distance_list, df_angular_distance # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "print_memory()\n",
    "\n",
    "meta_cols = { } # This was an empty dict in your provided code, keeping it as is.\n",
    "\n",
    "print(\" 6/6 Calculating imu_cols_base ...\")\n",
    "imu_cols_orig = ['acc_x', 'acc_y', 'acc_z',\n",
    "            'rot_w', 'rot_x', 'rot_y', 'rot_z',\n",
    "            'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
    "\n",
    "imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
    "imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n",
    "\n",
    "imu_engineered_features = [\n",
    "    'acc_x_norm_ew', 'acc_y_norm_ew', 'acc_z_norm_ew',  # new from demographics\n",
    "    'acc_x_norm_sw', 'acc_y_norm_sw', 'acc_z_norm_sw',  # new from demographics\n",
    "    'acc_mag', 'rot_angle',\n",
    "    'acc_mag_jerk', 'rot_angle_vel',\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', # Existing new features\n",
    "    'angular_distance' # Added new feature\n",
    "]\n",
    "\n",
    "dem_features = [\n",
    "    'adult_child', 'age',\n",
    "    'sex', 'handedness',\n",
    "]\n",
    "\n",
    "imu_cols = list(dict.fromkeys(imu_cols_orig + imu_cols_base + imu_engineered_features + dem_features))  # Remove dups\n",
    "\n",
    "print(\"length of imu_cols :\", len(imu_cols),)\n",
    "\n",
    "\n",
    "# print(\"ToF normalization :\")\n",
    "\n",
    "# tof_cols = [col for col in df.columns if col.startswith(\"tof_\")]\n",
    "# for col in tof_cols:\n",
    "#     df[f\"{col}_norm\"] = df[col] / df[\"shoulder_to_wrist_cm\"]\n",
    "\n",
    "print(\"✅ Preprocessing done.\")\n",
    "print_memory()\n",
    "\n",
    "# thm_cols_original = [c for c in df.columns if c.startswith('thm_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TOF not used\n",
    "######################\n",
    "\n",
    "# print(\" 6/8 Calculating tof_aggregated_cols_template...\")\n",
    "\n",
    "# ## tof data\n",
    "# tof_aggregated_cols_template = []\n",
    "# for i in range(1, 6):\n",
    "#     tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "# final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n",
    "# imu_dim_final = len(imu_cols)\n",
    "# tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "\n",
    "# print(f\" IMU (incl. engineered & derivatives) {imu_dim_final} | THM ({len(thm_cols_original)}) + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n",
    "# np.save(paths.OUTPUT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "# print(\" 7/8 calculating tof tof_i_mean/std/min/max...\")\n",
    "\n",
    "# seq_gp = df.groupby('sequence_id') \n",
    "\n",
    "# all_steps_for_scaler_list = []\n",
    "# X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n",
    "\n",
    "# for seq_id, seq_df_orig in seq_gp:\n",
    "#     seq_df = seq_df_orig.copy()\n",
    "\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n",
    "#         seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n",
    "#         seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n",
    "#         seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n",
    "#         seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n",
    "    \n",
    "#     mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    \n",
    "#     all_steps_for_scaler_list.append(mat_unscaled)\n",
    "#     X_list_unscaled.append(mat_unscaled)\n",
    "#     y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n",
    "#     lens.append(len(mat_unscaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0461a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – configuring dataset …\n",
      "tof_columns length : 320\n",
      "SEQUENCE_LENGTH : 103\n",
      "full adjusted shape : (320, 320)\n",
      "number of classes : 18\n",
      "Memory Usage: 3523.04 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CONFIGURATION\n",
    "print(\"▶ TRAIN MODE – configuring dataset …\")\n",
    "\n",
    "# train_dem_df = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)\n",
    "# df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n",
    "# print(\"df for group shape :\", df_for_groups.shape)\n",
    "\n",
    "\n",
    "# Extract and Sort TOF Columns\n",
    "# Get only tof columns\n",
    "tof_columns = [col for col in df.columns if col.startswith(\"tof_\")]\n",
    "# Sort them safely\n",
    "tof_columns = sorted(tof_columns, key=parse_tof_column)\n",
    "\n",
    "sequence_ids = df[\"sequence_id\"].unique()\n",
    "\n",
    "print(\"tof_columns length :\", len(tof_columns))\n",
    "\n",
    "# Group by Sequence and Reshape\n",
    "grouped = df.groupby('sequence_id')\n",
    "\n",
    "# Estimate the max length\n",
    "sequence_lengths = grouped.size().values  # length of each sequence\n",
    "SEQUENCE_LENGTH = int(np.percentile(sequence_lengths, 90))\n",
    "print(\"SEQUENCE_LENGTH :\", SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    sequence_ids,\n",
    "    test_size=0.2,  # 20% validation\n",
    "    random_state=42,\n",
    "    stratify=df.groupby(\"sequence_id\")[\"gesture\"].first()  # keeps gesture label distribution balanced\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = MotionDataset(df, imu_cols, tof_columns, train_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "val_dataset   = MotionDataset(df, imu_cols, tof_columns, val_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE_TRAIN, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=config.BATCH_SIZE_VALID, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "# Combine adjacency matrices for all 5 sensors (block-diagonal)\n",
    "from scipy.linalg import block_diag\n",
    "sensor_adj = create_8x8_grid_adjacency()\n",
    "full_adj = block_diag(*[sensor_adj] * 5)  # shape: (320, 320)\n",
    "print(\"full adjusted shape :\", full_adj.shape)\n",
    "\n",
    "# Step 2: Add cross-edges between corresponding raw and normalized pixels  we can skip this \n",
    "# for sensor_idx in range(5):  # 5 sensors\n",
    "#     for pixel_idx in range(64):  # 64 pixels per sensor\n",
    "#         raw_node = sensor_idx * 64 + pixel_idx\n",
    "#         norm_node = (sensor_idx + 5) * 64 + pixel_idx  # 5 sensors later\n",
    "#         full_adj[raw_node, norm_node] = 1\n",
    "#         full_adj[norm_node, raw_node] = 1  # Undirected edge\n",
    "\n",
    "# print(\"Full adjacency shape:\", full_adj.shape)  # Should be (640, 640)\n",
    "\n",
    "labels = df[\"gesture\"].unique()\n",
    "print(\"number of classes :\", len(labels))\n",
    "\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46befbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming your DataLoader is set up like this:\n",
    "# dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False)  # small batch for demo\n",
    "\n",
    "# # Get one batch\n",
    "# batch = next(iter(dataloader))\n",
    "\n",
    "# # batch['X'] shape: (batch_size, 320, 26, max_len)\n",
    "# X = batch['X'].numpy()\n",
    "# y = batch['y'].numpy()\n",
    "# seq_ids = batch['sequence_id']\n",
    "\n",
    "# batch_size = X.shape[0]\n",
    "# tof_dim = 640\n",
    "# imu_dim = 35\n",
    "# max_len = X.shape[3]\n",
    "\n",
    "# # Separate ToF and IMU from fused tensor\n",
    "# # Recall: fused shape (batch_size, 320, 26, max_len)\n",
    "# # Your fused format is: first channel is tof (index 0), second is imu (index 1)\n",
    "# # But your fusion was done with shape (320, 26, time), so let's split that\n",
    "\n",
    "# # Actually your fusion was concatenated on axis=2 (features dim), \n",
    "# # so features dim = 2, time dim = 3\n",
    "\n",
    "# # So to separate:\n",
    "# tof_data = X[:, :, 0, :]  # shape (batch_size, 320, max_len)\n",
    "# imu_data = X[:, :, 1, :]  # shape (batch_size, 320, max_len) ??? Wait that can't be right\n",
    "\n",
    "# # Wait, from your code:\n",
    "# # fused = np.concatenate([\n",
    "# #   tof_padded[:, :, np.newaxis],        # (max_len, 320, 1)\n",
    "# #   np.broadcast_to(imu_expanded, (max_len, 320, imu_expanded.shape[2]))\n",
    "# # ], axis=2)\n",
    "# # Then fused = fused.transpose(1, 2, 0)  # (320, 26, time)\n",
    "\n",
    "# # So fused shape = (320, 26, time)\n",
    "# # You return torch.tensor(fused, float32)\n",
    "\n",
    "# # So X has shape (batch_size, 320, 26, max_len)\n",
    "\n",
    "# # So feature dim = 26: 1 for ToF, 25 for IMU? Actually, you concatenated imu_expanded of shape (max_len, 320, 26) ?\n",
    "\n",
    "# # Wait, the fusion concatenates tof_padded[:, :, np.newaxis] (max_len, 320, 1)\n",
    "# # with imu_expanded broadcasted to (max_len, 320, imu_features)\n",
    "# # then transpose dims to (320, features, max_len)\n",
    "\n",
    "# # So feature dimension 26 = 1 (tof) + 25 imu? Actually you used imu_expanded = imu_padded[:, np.newaxis, :]\n",
    "# # imu_expanded shape = (max_len, 1, imu_features)\n",
    "\n",
    "# # Broadcasted to (max_len, 320, imu_features)\n",
    "\n",
    "# # So after concatenation axis=2 (last axis):\n",
    "# # fused shape (max_len, 320, 1 + imu_features)\n",
    "# # then transpose(1,2,0) -> (320, 1+imu_features, max_len)\n",
    "\n",
    "# # So in your code imu_features=26, meaning total features dimension is 27 (1 tof + 26 imu), not 26 as you said.\n",
    "\n",
    "# # Anyway to extract:\n",
    "# tof_data = X[:, :, 0, :]  # first feature channel (ToF), shape (batch_size, 320, max_len)\n",
    "# imu_data = X[:, :, 1:, :]  # remaining imu features, shape (batch_size, 320, 26, max_len)\n",
    "\n",
    "# # For CSV export, you probably want to flatten time and spatial dims\n",
    "# for i in range(batch_size):\n",
    "#     seq_id = seq_ids[i]\n",
    "#     label = y[i]\n",
    "\n",
    "#     # ToF: (320, max_len)\n",
    "#     tof_seq = tof_data[i]\n",
    "#     pd.DataFrame(tof_seq).to_csv(f\"{paths.BASE_DIR}/tof_seq_{seq_id}.csv\", index=False, header=False)\n",
    "\n",
    "#     # IMU: (320, 26, max_len) → reshape to (320*26, max_len) for tabular view\n",
    "#     imu_seq = imu_data[i].reshape(640 * 35, max_len)\n",
    "#     pd.DataFrame(imu_seq).to_csv(f\"{paths.BASE_DIR}/imu_seq_{seq_id}.csv\", index=False, header=False)\n",
    "\n",
    "#     print(f\"Exported sequence {seq_id} with label {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2efffed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train_loader batches...\n",
      "Dataset length: 6520\n",
      "Batch 0 keys: dict_keys(['X', 'y', 'sequence_id'])\n",
      "X shape: torch.Size([8, 355, 103]) Full batch: B × N × C × T\n",
      "y shape: torch.Size([8])\n",
      "=====\n",
      "x_sample shape: torch.Size([355, 103]) First sample in batch\n",
      " torch.Size([103]) All features over time for first node\n",
      " torch.Size([]) First feature over time for first node\n",
      "time torch.Size([103])\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking train_loader batches...\")\n",
    "# print(next(iter(train_dataset)))\n",
    "\n",
    "print(f\"Dataset length: {len(train_loader.dataset)}\")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i} keys: {batch.keys()}\")\n",
    "    print(f\"X shape: {batch['X'].shape} Full batch: B × N × C × T\")  # [B, N, C, T]\n",
    "    print(f\"y shape: {batch['y'].shape}\")  # [B]\n",
    "    print(\"=====\")\n",
    "    x_sample = batch[\"X\"][0]\n",
    "    print(f\"x_sample shape: {x_sample.shape} First sample in batch\")\n",
    "    print(f\" {x_sample[0].shape} All features over time for first node\")\n",
    "    print(f\" {x_sample[0][0].shape} First feature over time for first node\")\n",
    "    print(f\"time {x_sample[3].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f6cf65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tof_adj shape : torch.Size([320, 320])\n",
      "imu_adj shape : torch.Size([35, 35])\n",
      "full_adj shape : torch.Size([355, 355])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the adjacency Matrix\n",
    "tof_adj = torch.tensor(full_adj, dtype=torch.float32, device=device)  # (640, 640)\n",
    "print(\"tof_adj shape :\", tof_adj.shape)\n",
    "imu_adj = torch.tensor(np.eye(35))\n",
    "print(\"imu_adj shape :\", imu_adj.shape)\n",
    "full_adj_fin = torch.tensor(block_diag(tof_adj, imu_adj)).float()\n",
    "print(\"full_adj shape :\", full_adj_fin.shape)\n",
    "# Model Instantiation  [B=32, T=320, V=26, C=103]\n",
    "\n",
    "model = STGCN(\n",
    "    in_channels=1,         # channels per node (ToF + IMU)\n",
    "    num_classes=len(df[\"gesture\"].unique()),  # e.g., 20\n",
    "    A=full_adj_fin,\n",
    "    num_nodes=355,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f95d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏩ training started .....\n",
      "▶️ Setting scheduler  .....\n",
      "✅ Epoch starts .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:50, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.0180 | Train Acc: 0.1250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m correct, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mMotionDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     18\u001b[39m seq_id = \u001b[38;5;28mself\u001b[39m.sequence_ids[idx]\n\u001b[32m     19\u001b[39m group = \u001b[38;5;28mself\u001b[39m.grouped.get_group(seq_id)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m tof_values = \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtof_columns\u001b[49m\u001b[43m]\u001b[49m.values.astype(np.float32)\n\u001b[32m     22\u001b[39m imu_values = group[\u001b[38;5;28mself\u001b[39m.imu_cols].values.astype(np.float32)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Pad or truncate\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4122\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   4120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._slice(indexer, axis=\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4122\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   4124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4125\u001b[39m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[32m   4126\u001b[39m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[32m   4127\u001b[39m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[32m   4128\u001b[39m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[32m   4129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n\u001b[32m   4130\u001b[39m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4172\u001b[39m, in \u001b[36mNDFrame._take_with_is_copy\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4161\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   4162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis = \u001b[32m0\u001b[39m) -> Self:\n\u001b[32m   4163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4164\u001b[39m \u001b[33;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[32m   4165\u001b[39m \u001b[33;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4170\u001b[39m \u001b[33;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[32m   4171\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4172\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4173\u001b[39m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[32m   4174\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result._get_axis(axis).equals(\u001b[38;5;28mself\u001b[39m._get_axis(axis)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4152\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4147\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4148\u001b[39m     indices = np.arange(\n\u001b[32m   4149\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4150\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4152\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4154\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4158\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4159\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRequested axis not found in manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m     new_blocks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m    688\u001b[39m         blk.take_nd(\n\u001b[32m    689\u001b[39m             indexer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001b[39m, in \u001b[36mBaseBlockManager._slice_take_blocks_ax0\u001b[39m\u001b[34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[39m\n\u001b[32m    841\u001b[39m                     blocks.append(nb)\n\u001b[32m    842\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m                 nb = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m                 blocks.append(nb)\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1373\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1370\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[32m    165\u001b[39m     out = out.T\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"⏩ training started .....\")\n",
    "\n",
    "cw_vals = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "weights_tensor = torch.tensor(cw_vals, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "print(\"▶️ Setting scheduler  .....\")\n",
    "steps = []\n",
    "lrs = []\n",
    "best_val_acc = 0\n",
    "patience, patience_counter = 10, 0\n",
    "EPOCHS = config.EPOCHS\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=config.EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.0,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=100,\n",
    ")\n",
    "\n",
    "print(\"✅ Epoch starts .....\")\n",
    "import itertools\n",
    "\n",
    "max_batches = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0         # <-- reset here\n",
    "    total = 0           # <-- reset here\n",
    "    for batch_idx, batch in tqdm.tqdm(enumerate(itertools.islice(train_loader, max_batches))):\n",
    "    # for batch_idx, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "        xb, yb = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "        # if batch_idx == 0:\n",
    "        xb = xb.permute(0, 2, 1).unsqueeze(1)\n",
    "        # print(\"shape xb ->: \", xb.shape, \"batch_idx ->: \", batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        preds_cls = model(xb)\n",
    "        # yb_indices = yb.argmax(dim=1)\n",
    "        loss = loss_fn(preds_cls, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # optional\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * config.BATCH_SIZE_TRAIN + batch_idx)\n",
    "        pred_labels = preds_cls.argmax(dim=1) \n",
    "        correct += (pred_labels == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Train Loss: {total_loss / len(train_loader):.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            xb, yb = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "            xb = xb.permute(0, 2, 1).unsqueeze(1)\n",
    "            preds_cls = model(xb)\n",
    "            pred_labels = preds_cls.argmax(1)\n",
    "            true_labels = yb.argmax(1) if yb.ndim > 1 else yb  #.argmax(1)  val_loader comes from a standard dataset with \"y\" as class index (long), you don’t need argmax.\n",
    "            correct += (pred_labels == true_labels).sum().item()\n",
    "            total += yb.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), paths.OUTPUT_DIR / \"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c9717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72101f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "608d18b6",
   "metadata": {},
   "source": [
    "0it [00:00, ?it/s]\n",
    "shape xb torch.Size([8, 127, 42])\n",
    "815it [00:33, 24.28it/s]\n",
    "Epoch 0 | Train Loss: 2.7902\n",
    "Epoch 0 | Val Acc: 0.1749\n",
    "3it [00:00, 21.27it/s]\n",
    "shape xb torch.Size([8, 127, 42])\n",
    "815it [00:31, 25.57it/s]\n",
    "Epoch 1 | Train Loss: 2.2463\n",
    "Epoch 1 | Val Acc: 0.2506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fca264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(paths.OUTPUT_DIR / \"best_model.pt\"))\n",
    "# model.eval()\n",
    "# preds_val = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for xb, _ in val_loader:\n",
    "#         xb = xb.to(device)\n",
    "#         logits = model(xb)\n",
    "#         preds_val.append(logits.argmax(1).cpu())\n",
    "\n",
    "# preds_val = torch.cat(preds_val).numpy()\n",
    "# true_val_int = y_val.argmax(1).numpy()\n",
    "\n",
    "# # Evaluation\n",
    "# from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "\n",
    "# h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "#     pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n",
    "#     pd.DataFrame({'gesture': le.classes_[preds_val]})\n",
    "# )\n",
    "# print(\"Hold-out H-F1 =\", round(h_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b429f",
   "metadata": {},
   "source": [
    " |- Model Type\t|Strength|\tEasy to Try?|\n",
    " |------|-------------|---------|\n",
    " |- TCN\tFast,| interpretable\t|✅✅✅\n",
    " |- Transformer |Encoder\tGlobal temporal modeling\t|✅✅\n",
    " |- CNN + Transformer Hybrid\t|Local + global\t|✅✅\n",
    " |- ResNet1D / InceptionTime\t|Robust 1D feature extraction\t|✅✅✅\n",
    " |- BiLSTM + Attention\t|Sequence modeling (non-parallel)\t|✅✅\n",
    " |- ST-GCN\t|Spatial-Temporal & structured\t|❌ (if no graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
