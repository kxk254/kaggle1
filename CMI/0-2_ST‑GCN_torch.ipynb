{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79b6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, joblib\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import gc  # garbage collection\n",
    "import psutil\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82880947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · torch 2.7.1+cpu device : cpu\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "\n",
    "class config:\n",
    "    AMP = False\n",
    "    BATCH_SIZE_TRAIN = 8 #32\n",
    "    BATCH_SIZE_VALID = 8 #32\n",
    "    DEBUG = False\n",
    "    EPOCHS = 2  #30\n",
    "    FOLDS = 5\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    LEARNING_RATE = 1e-3\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    PAD_PERCENTILE = 95\n",
    "    SEQUENCE_LENGTH = 150\n",
    "\n",
    "class paths:\n",
    "    BASE_DIR = Path(\"C:/Users/konno/SynologyDrive/datasciense/projects_foler/1_kaggle/CMI/cmi-detect-behavior-with-sensor-data\")\n",
    "    \n",
    "    OUTPUT_DIR = BASE_DIR / \"output-02-wavenet\"\n",
    "    TEST_CSV = BASE_DIR / \"test.csv\"\n",
    "    TEST_DEMOGRAPHICS = BASE_DIR / \"test_demographics.csv\"\n",
    "    TRAIN_CSV = BASE_DIR / \"train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = BASE_DIR / \"train_demographics.csv\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"▶ imports ready · torch\", torch.__version__, \"device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179bbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7803102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MixUp the data argumentation in order to regularize the neural network. \n",
    "\n",
    "class MotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, imu_cols, tof_columns, sequence_ids, max_len=103, mode=TRAIN):\n",
    "        self.df = df\n",
    "        self.imu_cols = imu_cols\n",
    "        self.tof_columns = tof_columns\n",
    "        self.sequence_ids = sequence_ids\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        self.grouped = df.groupby('sequence_id')\n",
    "        self.label_map = {s: i for i, s in enumerate(sorted(df['gesture'].unique()))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_id = self.sequence_ids[idx]\n",
    "        group = self.grouped.get_group(seq_id)\n",
    "\n",
    "        tof_values = group[self.tof_columns].values.astype(np.float32)\n",
    "        imu_values = group[self.imu_cols].values.astype(np.float32)\n",
    "\n",
    "        # Pad or truncate\n",
    "        tof_padded = pad_or_truncate(tof_values, self.max_len, self.mode)\n",
    "        imu_padded = pad_or_truncate(imu_values, self.max_len, self.mode)\n",
    "\n",
    "        imu_expanded = imu_padded[:, np.newaxis, :]\n",
    "        fused = np.concatenate([\n",
    "            tof_padded[:, :, np.newaxis],\n",
    "            np.broadcast_to(imu_expanded, (self.max_len, tof_padded.shape[1], imu_expanded.shape[2]))\n",
    "        ], axis=2)\n",
    "        fused = fused.transpose(1, 2, 0)  # (320, 26, time)\n",
    "\n",
    "        label = self.label_map[group['gesture'].iloc[0]]\n",
    "\n",
    "        return {\n",
    "            \"X\": torch.tensor(fused, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(label, dtype=torch.long),\n",
    "            \"sequence_id\": seq_id\n",
    "        }\n",
    "    \n",
    "# train_dataset = MixupDataset(config, df_train, X_tr, y_tr, y_soft_tr)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE_TRAIN, shuffle=True)\n",
    "# val_dataset = CustomDataset(config, df_train, X_val, y_val, y_soft_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE_VALID, shuffle=True)\n",
    "\n",
    "def pad_or_truncate(seq, max_len, mode=TRAIN, pad_value=0.0, dtype=np.float32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pads or truncates a sequence to a fixed length.\n",
    "\n",
    "    Parameters:\n",
    "    - seq: np.ndarray of shape (L, D)\n",
    "    - max_len: int, desired sequence length\n",
    "    - mode: bool, True = random pad, False = regular pad\n",
    "    - pad_value: float or int, value to use for padding\n",
    "    - dtype: np.dtype, dtype for the output array\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray of shape (max_len, D)\n",
    "    \"\"\"\n",
    "    # print(\"sequence shape\", seq.shape)\n",
    "    L, D = seq.shape\n",
    "    # print(\"mode = \", mode)\n",
    "\n",
    "    if L > max_len:\n",
    "        return seq[:max_len] # truncate if too long\n",
    "\n",
    "    elif L < max_len:\n",
    "        total_padding = max_len - L\n",
    "        \n",
    "        if mode:\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "            \n",
    "        else:\n",
    "            pad_start = 0\n",
    "            pad_end = total_padding\n",
    "\n",
    "        start_padding = np.full((pad_start, D), pad_value, dtype=dtype)\n",
    "        end_padding = np.full((pad_end, D), pad_value, dtype=dtype)\n",
    "        padded = np.vstack((start_padding, seq, end_padding))\n",
    "        # print(\"padded shape\", padded.shape)\n",
    "        return padded\n",
    "\n",
    "    else:\n",
    "        return seq.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0242b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "# Create Spatial Adjacency Matrix\n",
    "def create_8x8_grid_adjacency():\n",
    "    adj = np.zeros((64, 64), dtype=int)\n",
    "    for r in range(8):\n",
    "        for c in range(8):\n",
    "            idx = r * 8 + c\n",
    "            if r > 0: adj[idx][(r - 1) * 8 + c] = 1\n",
    "            if r < 7: adj[idx][(r + 1) * 8 + c] = 1\n",
    "            if c > 0: adj[idx][r * 8 + (c - 1)] = 1\n",
    "            if c < 7: adj[idx][r * 8 + (c + 1)] = 1\n",
    "    return adj\n",
    "\n",
    "def print_memory():\n",
    "    process = psutil.Process()\n",
    "    print(f\"Memory Usage: {process.memory_info().rss / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f21133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STGCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, A, stride=1, residual=True):\n",
    "        super().__init__()\n",
    "        # Temporal convolution: shape = (kernel_size, 1)\n",
    "        self.A = A  # Adjacency matrix: (V, V)\n",
    "        self.num_nodes = A.shape[0]\n",
    "        # self.gcn = GraphConv(in_channels, out_channels)  # Spatial convolution (GCN)\n",
    "        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(9,1),\n",
    "                      padding=(4,0), stride=(stride,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride,1)),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):  # x: [B, C, T, V], A: adjacency matrix\n",
    "        # x shape: (N, C, T, V)\n",
    "        N, C, T, V = x.size()\n",
    "        A = self.A.to(x.device)  # ensure A is on the same device\n",
    "\n",
    "        # Graph convolution: multiply input by adjacency matrix\n",
    "        x = torch.einsum('nctv,vw->nctw', (x, A))  # shape: (N, C, T, V)\n",
    "\n",
    "        x = self.gcn(x)  # (N, out_channels, T, V)\n",
    "        x = self.tcn(x)  # temporal conv\n",
    "        x = x + self.residual(x)  # add residual\n",
    "        return self.relu(x)\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, A, num_nodes):\n",
    "        super().__init__()\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * num_nodes)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            STGCNBlock(in_channels, 64, A, residual=False),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 64, A),\n",
    "            STGCNBlock(64, 128, A, stride=2),\n",
    "            STGCNBlock(128, 128, A),\n",
    "            STGCNBlock(128, 256, A, stride=2),\n",
    "            STGCNBlock(256, 256, A)\n",
    "        ])\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # output shape: (N, C, 1, 1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C, T, V)\n",
    "        print(f\"in_channels: {self.data_bn.num_features}\")\n",
    "        print(f\"input x shape before BN: {x.shape}\")\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()  # (N, C, T, V)\n",
    "\n",
    "        for gcn in self.layers:\n",
    "            x = gcn(x)\n",
    "\n",
    "        x = self.pool(x)  # (N, C, 1, 1)\n",
    "        x = x.view(N, -1)  # flatten\n",
    "        return self.fc(x)  # logits: (N, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5c9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      "Memory Usage: 1886.02 MB\n",
      " 1/6 Calculating base engineered IMU features (magnitude, angle) ...\n",
      " 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\n",
      " 3/6 Removing gravity and calculating linear acceleration features...\n",
      " 4/6 Calculating angular velocity from quaternion derivatives...\n",
      " 5/6 Calculating angular distance between successive quaternions...\n",
      "Memory Usage: 3516.06 MB\n",
      " 6/6 Calculating imu_cols_base ...\n",
      "length of imu_cols : 25\n",
      "✅ Preprocessing done.\n",
      "Memory Usage: 3516.06 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CREATION and PRE PROCESSING\n",
    "\n",
    "print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(paths.TRAIN_CSV)\n",
    "df = df.fillna(0)\n",
    "\n",
    "print_memory()\n",
    "\n",
    "print(\" 1/6 Calculating base engineered IMU features (magnitude, angle) ...\")\n",
    "\n",
    "df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "df['rot_angle'] = 2* np.arccos(df['rot_w'].clip(-1, 1))\n",
    "\n",
    "print(\" 2/6 Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag ...\")\n",
    "\n",
    "df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n",
    "\n",
    "print(\" 3/6 Removing gravity and calculating linear acceleration features...\")\n",
    "\n",
    "linear_accel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n",
    "    linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n",
    "\n",
    "df_linear_accel = pd.concat(linear_accel_list)\n",
    "df = pd.concat([df, df_linear_accel], axis=1)\n",
    "del df_linear_accel, linear_accel_list  # Memory Management\n",
    "gc.collect()  # Memory Management\n",
    "\n",
    "df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "\n",
    "print(\" 4/6 Calculating angular velocity from quaternion derivatives...\")\n",
    "angular_vel_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n",
    "    angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n",
    "\n",
    "df_angular_vel = pd.concat(angular_vel_list)\n",
    "df = pd.concat([df, df_angular_vel], axis=1)\n",
    "del angular_vel_list, df_angular_vel # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "\n",
    "print(\" 5/6 Calculating angular distance between successive quaternions...\")\n",
    "angular_distance_list = []\n",
    "for _, group in df.groupby('sequence_id'):\n",
    "    rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n",
    "    angular_dist_group = calculate_angular_distance(rot_data_group)\n",
    "    angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n",
    "\n",
    "df_angular_distance = pd.concat(angular_distance_list)\n",
    "df = pd.concat([df, df_angular_distance], axis=1)\n",
    "del angular_distance_list, df_angular_distance # Memory Management\n",
    "gc.collect() # Memory Management\n",
    "\n",
    "print_memory()\n",
    "\n",
    "meta_cols = { } # This was an empty dict in your provided code, keeping it as is.\n",
    "\n",
    "print(\" 6/6 Calculating imu_cols_base ...\")\n",
    "imu_cols_orig = ['acc_x', 'acc_y', 'acc_z',\n",
    "            'rot_w', 'rot_x', 'rot_y', 'rot_z',\n",
    "            'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
    "\n",
    "imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
    "imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n",
    "\n",
    "imu_engineered_features = [\n",
    "    'acc_mag', 'rot_angle',\n",
    "    'acc_mag_jerk', 'rot_angle_vel',\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', # Existing new features\n",
    "    'angular_distance' # Added new feature\n",
    "]\n",
    "imu_cols = list(dict.fromkeys(imu_cols_orig + imu_cols_base + imu_engineered_features))  # Remove dups\n",
    "\n",
    "print(\"length of imu_cols :\", len(imu_cols))\n",
    "\n",
    "print(\"✅ Preprocessing done.\")\n",
    "print_memory()\n",
    "\n",
    "# thm_cols_original = [c for c in df.columns if c.startswith('thm_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1b53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TOF not used\n",
    "######################\n",
    "\n",
    "# print(\" 6/8 Calculating tof_aggregated_cols_template...\")\n",
    "\n",
    "# ## tof data\n",
    "# tof_aggregated_cols_template = []\n",
    "# for i in range(1, 6):\n",
    "#     tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "# final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n",
    "# imu_dim_final = len(imu_cols)\n",
    "# tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "\n",
    "# print(f\" IMU (incl. engineered & derivatives) {imu_dim_final} | THM ({len(thm_cols_original)}) + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n",
    "# np.save(paths.OUTPUT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "# print(\" 7/8 calculating tof tof_i_mean/std/min/max...\")\n",
    "\n",
    "# seq_gp = df.groupby('sequence_id') \n",
    "\n",
    "# all_steps_for_scaler_list = []\n",
    "# X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n",
    "\n",
    "# for seq_id, seq_df_orig in seq_gp:\n",
    "#     seq_df = seq_df_orig.copy()\n",
    "\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n",
    "#         seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n",
    "#         seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n",
    "#         seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n",
    "#         seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n",
    "    \n",
    "#     mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    \n",
    "#     all_steps_for_scaler_list.append(mat_unscaled)\n",
    "#     X_list_unscaled.append(mat_unscaled)\n",
    "#     y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n",
    "#     lens.append(len(mat_unscaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0461a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – configuring dataset …\n",
      "df for group shape : (574945, 361)\n",
      "full adjusted shape : (320, 320)\n",
      "number of classes : 18\n",
      "Memory Usage: 5105.27 MB\n"
     ]
    }
   ],
   "source": [
    "### DATA CONFIGURATION\n",
    "print(\"▶ TRAIN MODE – configuring dataset …\")\n",
    "\n",
    "train_dem_df = pd.read_csv(paths.TRAIN_DEMOGRAPHICS)\n",
    "df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n",
    "print(\"df for group shape :\", df_for_groups.shape)\n",
    "\n",
    "\n",
    "# Extract and Sort TOF Columns\n",
    "tof_columns = [col for col in df.columns if col.startswith(\"tof_\")]\n",
    "tof_columns = sorted(tof_columns, key=lambda x: (\n",
    "    int(x.split('_')[1]), int(x.split('_v')[-1])  # sort by sensor number, then pixel index\n",
    "))\n",
    "sequence_ids = df[\"sequence_id\"].unique()\n",
    "\n",
    "# Group by Sequence and Reshape\n",
    "grouped = df.groupby('sequence_id')\n",
    "\n",
    "# Estimate the max length\n",
    "sequence_lengths = grouped.size().values  # length of each sequence\n",
    "SEQUENCE_LENGTH = int(np.percentile(sequence_lengths, 90))\n",
    "\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    sequence_ids,\n",
    "    test_size=0.2,  # 20% validation\n",
    "    random_state=42,\n",
    "    stratify=df.groupby(\"sequence_id\")[\"gesture\"].first()  # keeps gesture label distribution balanced\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = MotionDataset(df, imu_cols, tof_columns, train_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "val_dataset   = MotionDataset(df, imu_cols, tof_columns, val_ids, max_len=SEQUENCE_LENGTH, mode=TRAIN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "# Combine adjacency matrices for all 5 sensors (block-diagonal)\n",
    "from scipy.linalg import block_diag\n",
    "sensor_adj = create_8x8_grid_adjacency()\n",
    "full_adj = block_diag(*[sensor_adj] * 5)  # shape: (320, 320)\n",
    "print(\"full adjusted shape :\", full_adj.shape)\n",
    "\n",
    "labels = df[\"gesture\"].unique()\n",
    "print(\"number of classes :\", len(labels))\n",
    "\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f6cf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the adjacency Matrix\n",
    "A = torch.tensor(full_adj, dtype=torch.float32, device=device)  # (320, 320)\n",
    "\n",
    "# Model Instantiation  [B=32, T=320, V=26, C=103]\n",
    "\n",
    "model = STGCN(\n",
    "    in_channels=320,         # channels per node (ToF + IMU)\n",
    "    num_classes=len(df[\"gesture\"].unique()),  # e.g., 20\n",
    "    A=A,\n",
    "    num_nodes=103\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec0ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10bed0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train_loader batches...\n",
      "Dataset length: 6520\n",
      "Batch 0 keys: dict_keys(['X', 'y', 'sequence_id'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking train_loader batches...\")\n",
    "# print(next(iter(train_dataset)))\n",
    "\n",
    "print(f\"Dataset length: {len(train_loader.dataset)}\")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i} keys: {batch.keys()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f95d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏩ training started .....\n",
      "▶️ Setting scheduler  .....\n",
      "✅ Epoch starts .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape xb ->:  torch.Size([32, 320, 26, 103]) batch_idx ->:  0\n",
      "in_channels: 32960\n",
      "input x shape before BN: torch.Size([32, 320, 26, 103])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript v has size 320 for operand 1 which does not broadcast with previously seen size 103",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mshape xb ->: \u001b[39m\u001b[33m\"\u001b[39m, xb.shape, \u001b[33m\"\u001b[39m\u001b[33mbatch_idx ->: \u001b[39m\u001b[33m\"\u001b[39m, batch_idx)\n\u001b[32m     35\u001b[39m optimizer.zero_grad()        \n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m preds_cls = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# yb_indices = yb.argmax(dim=1)\u001b[39;00m\n\u001b[32m     38\u001b[39m loss = loss_fn(preds_cls, yb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mSTGCN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     67\u001b[39m x = x.view(N, V, C, T).permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m).contiguous()  \u001b[38;5;66;03m# (N, C, T, V)\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gcn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     x = \u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x)  \u001b[38;5;66;03m# (N, C, 1, 1)\u001b[39;00m\n\u001b[32m     73\u001b[39m x = x.view(N, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# flatten\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mSTGCNBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m A = \u001b[38;5;28mself\u001b[39m.A.to(x.device)  \u001b[38;5;66;03m# ensure A is on the same device\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Graph convolution: multiply input by adjacency matrix\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnctv,vw->nctw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (N, C, T, V)\u001b[39;00m\n\u001b[32m     36\u001b[39m x = \u001b[38;5;28mself\u001b[39m.gcn(x)  \u001b[38;5;66;03m# (N, out_channels, T, V)\u001b[39;00m\n\u001b[32m     37\u001b[39m x = \u001b[38;5;28mself\u001b[39m.tcn(x)  \u001b[38;5;66;03m# temporal conv\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\functional.py:417\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    414\u001b[39m     _operands = operands[\u001b[32m0\u001b[39m]\n\u001b[32m    415\u001b[39m     \u001b[38;5;66;03m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[32m    416\u001b[39m     \u001b[38;5;66;03m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m_operands\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum.enabled:\n\u001b[32m    420\u001b[39m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF.einsum(equation, operands)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\kaggle1\\env\\Lib\\site-packages\\torch\\functional.py:422\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, *_operands)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum.enabled:\n\u001b[32m    420\u001b[39m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    424\u001b[39m path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum.is_available():\n",
      "\u001b[31mRuntimeError\u001b[39m: einsum(): subscript v has size 320 for operand 1 which does not broadcast with previously seen size 103"
     ]
    }
   ],
   "source": [
    "print(\"⏩ training started .....\")\n",
    "\n",
    "cw_vals = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "weights_tensor = torch.tensor(cw_vals, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "print(\"▶️ Setting scheduler  .....\")\n",
    "steps = []\n",
    "lrs = []\n",
    "best_val_acc = 0\n",
    "patience, patience_counter = 10, 0\n",
    "EPOCHS = config.EPOCHS\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=config.EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.0,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=100,\n",
    ")\n",
    "\n",
    "print(\"✅ Epoch starts .....\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0         # <-- reset here\n",
    "    total = 0           # <-- reset here\n",
    "    for batch_idx, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "        xb, yb = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "        # if batch_idx == 0:\n",
    "        print(\"shape xb ->: \", xb.shape, \"batch_idx ->: \", batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        preds_cls = model(xb)\n",
    "        # yb_indices = yb.argmax(dim=1)\n",
    "        loss = loss_fn(preds_cls, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # optional\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * config.BATCH_SIZE_TRAIN + batch_idx)\n",
    "        correct += (pred_labels == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Train Loss: {total_loss / len(train_loader):.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            xb, yb = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "            xb = xb.permute(0, 3, 2, 1)  # from (N, 320, 26, 103) to (N, 103, 26, 320)\n",
    "            preds_cls = model(xb)\n",
    "            pred_labels = preds_cls.argmax(1)\n",
    "            true_labels = yb.argmax(1) if yb.ndim > 1 else yb  #.argmax(1)  val_loader comes from a standard dataset with \"y\" as class index (long), you don’t need argmax.\n",
    "            correct += (pred_labels == true_labels).sum().item()\n",
    "            total += yb.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), paths.OUTPUT_DIR / \"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c9717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72101f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "608d18b6",
   "metadata": {},
   "source": [
    "0it [00:00, ?it/s]\n",
    "shape xb torch.Size([8, 127, 42])\n",
    "815it [00:33, 24.28it/s]\n",
    "Epoch 0 | Train Loss: 2.7902\n",
    "Epoch 0 | Val Acc: 0.1749\n",
    "3it [00:00, 21.27it/s]\n",
    "shape xb torch.Size([8, 127, 42])\n",
    "815it [00:31, 25.57it/s]\n",
    "Epoch 1 | Train Loss: 2.2463\n",
    "Epoch 1 | Val Acc: 0.2506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fca264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(paths.OUTPUT_DIR / \"best_model.pt\"))\n",
    "# model.eval()\n",
    "# preds_val = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for xb, _ in val_loader:\n",
    "#         xb = xb.to(device)\n",
    "#         logits = model(xb)\n",
    "#         preds_val.append(logits.argmax(1).cpu())\n",
    "\n",
    "# preds_val = torch.cat(preds_val).numpy()\n",
    "# true_val_int = y_val.argmax(1).numpy()\n",
    "\n",
    "# # Evaluation\n",
    "# from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "\n",
    "# h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "#     pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n",
    "#     pd.DataFrame({'gesture': le.classes_[preds_val]})\n",
    "# )\n",
    "# print(\"Hold-out H-F1 =\", round(h_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b429f",
   "metadata": {},
   "source": [
    " |- Model Type\t|Strength|\tEasy to Try?|\n",
    " |------|-------------|---------|\n",
    " |- TCN\tFast,| interpretable\t|✅✅✅\n",
    " |- Transformer |Encoder\tGlobal temporal modeling\t|✅✅\n",
    " |- CNN + Transformer Hybrid\t|Local + global\t|✅✅\n",
    " |- ResNet1D / InceptionTime\t|Robust 1D feature extraction\t|✅✅✅\n",
    " |- BiLSTM + Attention\t|Sequence modeling (non-parallel)\t|✅✅\n",
    " |- ST-GCN\t|Spatial-Temporal & structured\t|❌ (if no graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
