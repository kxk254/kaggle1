{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492965e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�T�u�f�B���N�g���܂��̓t�@�C�� output �͊��ɑ��݂��܂��B\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# import kaggle_evaluation.cmi_inference_server\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "!mkdir output\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4485b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    BATCH_SIZE_TEST = 1\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "\n",
    "class paths:\n",
    "    OUTPUT_DIR = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\output\"\n",
    "    TEST_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test.csv\"\n",
    "    TEST_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test_demographics.csv\"\n",
    "    TRAIN_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train_demographics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbf9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_scoring(df_preds: pd.DataFrame) ->tuple[pd.DataFrame, pd.DataFrame]: \n",
    "    solution = df_preds[[\"sequence_id\", \"y_true\"]].copy()\n",
    "    solution.columns = [\"id\", \"gesture\"]\n",
    "    solution[\"gesture\"] = solution[\"gesture\"].map(num_to_label)\n",
    "\n",
    "    submission = df_preds[[\"sequence_id\", \"y_pred\"]].copy()\n",
    "    submission.columns = [\"id\", \"gesture\"]\n",
    "    submission[\"gesture\"] = submission[\"gesture\"].map(num_to_label)\n",
    "    \n",
    "    return solution, submission\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"—\"*100)\n",
    "\n",
    "\n",
    "label_to_num = {\n",
    "    'Above ear - pull hair': 0,  # < ------- TARGETS START\n",
    "    'Cheek - pinch skin': 1,\n",
    "    'Eyebrow - pull hair': 2,\n",
    "    'Eyelash - pull hair': 3,\n",
    "    'Forehead - pull hairline': 4,\n",
    "    'Forehead - scratch': 5,\n",
    "    'Neck - pinch skin': 6,\n",
    "    'Neck - scratch': 7,  # < ------- TARGETS END\n",
    "    'Drink from bottle/cup': 8,  # < ------- NON-TARGETS START\n",
    "    'Feel around in tray and pull out an object': 8,\n",
    "    'Glasses on/off': 8,\n",
    "    'Pinch knee/leg skin': 8,\n",
    "    'Pull air toward your face': 8,\n",
    "    'Scratch knee/leg skin': 8,\n",
    "    'Text on phone': 8,\n",
    "    'Wave hello': 8,\n",
    "    'Write name in air': 8,\n",
    "    'Write name on leg': 8  # < ------- NON-TARGETS END\n",
    "}\n",
    "type_to_num = {\"Target\": 1, \"Non-Target\":0}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "num_to_type = {v: k for k, v in type_to_num.items()}\n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f2891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape: (107, 336)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Test demographics dataframe shape: (2, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001_000000</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.039062</td>\n",
       "      <td>5.261719</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>-0.397400</td>\n",
       "      <td>-0.629028</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000001_000001</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.421875</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>-1.113281</td>\n",
       "      <td>0.353882</td>\n",
       "      <td>-0.507141</td>\n",
       "      <td>-0.652710</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000001_000002</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>10.160156</td>\n",
       "      <td>2.082031</td>\n",
       "      <td>-3.871094</td>\n",
       "      <td>0.384094</td>\n",
       "      <td>-0.532104</td>\n",
       "      <td>-0.639648</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000001_000003</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.773438</td>\n",
       "      <td>1.355469</td>\n",
       "      <td>-4.371094</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>-0.531982</td>\n",
       "      <td>-0.634033</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000001_000004</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.195312</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>-3.222656</td>\n",
       "      <td>0.382751</td>\n",
       "      <td>-0.534180</td>\n",
       "      <td>-0.638367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row_id sequence_id  sequence_counter      subject      acc_x  \\\n",
       "0  SEQ_000001_000000  SEQ_000001                 0  SUBJ_055840   9.039062   \n",
       "1  SEQ_000001_000001  SEQ_000001                 1  SUBJ_055840   9.421875   \n",
       "2  SEQ_000001_000002  SEQ_000001                 2  SUBJ_055840  10.160156   \n",
       "3  SEQ_000001_000003  SEQ_000001                 3  SUBJ_055840   9.773438   \n",
       "4  SEQ_000001_000004  SEQ_000001                 4  SUBJ_055840   9.195312   \n",
       "\n",
       "      acc_y     acc_z     rot_w     rot_x     rot_y  ...  tof_5_v54  \\\n",
       "0  5.261719  0.800781  0.367188 -0.397400 -0.629028  ...       97.0   \n",
       "1  3.460938 -1.113281  0.353882 -0.507141 -0.652710  ...      175.0   \n",
       "2  2.082031 -3.871094  0.384094 -0.532104 -0.639648  ...       -1.0   \n",
       "3  1.355469 -4.371094  0.387756 -0.531982 -0.634033  ...       -1.0   \n",
       "4  1.011719 -3.222656  0.382751 -0.534180 -0.638367  ...       -1.0   \n",
       "\n",
       "   tof_5_v55  tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  \\\n",
       "0       87.0      206.0       -1.0      195.0       -1.0       -1.0   \n",
       "1      158.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2      160.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      160.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4      163.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v61  tof_5_v62  tof_5_v63  \n",
       "0       -1.0      111.0       -1.0  \n",
       "1      211.0      187.0      178.0  \n",
       "2       -1.0      197.0      177.0  \n",
       "3       -1.0      197.0      183.0  \n",
       "4       -1.0      200.0      173.0  \n",
       "\n",
       "[5 rows x 336 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>52</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>177.0</td>\n",
       "      <td>52</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject  adult_child  age  sex  handedness  height_cm  \\\n",
       "0  SUBJ_016452            1   25    1           1      165.0   \n",
       "1  SUBJ_055840            0   13    0           1      177.0   \n",
       "\n",
       "   shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "0                    52               23.0  \n",
       "1                    52               27.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv(paths.TEST_CSV)\n",
    "df_test_demographics = pd.read_csv(paths.TEST_DEMOGRAPHICS)\n",
    "\n",
    "print(f\"Test dataframe shape: {df_test.shape}\"), sep()\n",
    "print(f\"Test demographics dataframe shape: {df_test_demographics.shape}\")\n",
    "\n",
    "display(df_test.head())\n",
    "display(df_test_demographics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcaccc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 576.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def min_max_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    min_vals = np.nanmin(arr, axis=0)\n",
    "    max_vals = np.nanmax(arr, axis=0)\n",
    "    ranges = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "    scaled = (arr - min_vals) / ranges\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def standard_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    means = np.nanmean(arr, axis=0)\n",
    "    stds = np.nanstd(arr, axis=0)\n",
    "    stds = np.where(stds == 0, 1, stds)  # Prevent division by zero for constant columns\n",
    "    scaled = (arr - means) / stds\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def pad_or_truncate(\n",
    "    arr: np.ndarray,\n",
    "    max_length: int = 200,\n",
    "    pad_value: int = 0,\n",
    "    mode: str = \"random\"  # \"regular\" or \"random\"\n",
    ") -> np.ndarray:\n",
    "    L, D = arr.shape\n",
    "\n",
    "    if L > max_length:\n",
    "        return arr[:max_length, :]\n",
    "\n",
    "    elif L < max_length:\n",
    "        if mode == \"regular\":\n",
    "            padding = np.full((max_length - L, D), pad_value)\n",
    "            return np.vstack((arr, padding))\n",
    "        \n",
    "        elif mode == \"random\":\n",
    "            total_padding = max_length - L\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "\n",
    "            start_padding = np.full((pad_start, D), pad_value)\n",
    "            end_padding = np.full((pad_end, D), pad_value)\n",
    "\n",
    "            return np.vstack((start_padding, arr, end_padding))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}. Use 'regular' or 'random'.\")\n",
    "\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "X_test  = []\n",
    "\n",
    "for sequence_id in tqdm(df_test.sequence_id.unique()):\n",
    "    ds = df_test[df_test[\"sequence_id\"] == sequence_id]\n",
    "    X = ds[imu_cols].values\n",
    "    X = pad_or_truncate(X)\n",
    "    X = np.concatenate((standard_scale(X[:, 0:3]), X[:, 3:]), axis=1)\n",
    "    X = np.where(np.isnan(X), 0.0, X)  # fill NaNs\n",
    "    X_test.append(X)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9c36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, config, df: pd.DataFrame, X: np.ndarray\n",
    "    ): \n",
    "        \n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.X = X\n",
    "        self.indexes = self.df.sequence_id.unique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        sequence_id = self.indexes[index]\n",
    "        X = self.X[index]\n",
    "        output = {\n",
    "            \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"sequence_id\": sequence_id\n",
    "        }\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20087595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = CustomDataset(config, df_test, X_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE_TEST,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    ")\n",
    "idx = np.random.choice(range(0, len(test_dataset)))\n",
    "cols = imu_cols\n",
    "X = test_dataset[idx][\"X\"]\n",
    "sequence_id = test_dataset[idx][\"sequence_id\"]\n",
    "N = X.shape[0]\n",
    "df = pd.DataFrame(X, columns=cols)\n",
    "df['step'] = range(N)\n",
    "df_melted = df.melt(id_vars='step', var_name='sequence', value_name='value')\n",
    "\n",
    "fig = px.line(\n",
    "    df_melted,\n",
    "    x='step',\n",
    "    y='value',\n",
    "    color='sequence',\n",
    "    title=f\"Sequences for {sequence_id}\",\n",
    "    template='plotly_dark',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78eb4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EnhancedSEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    An enhanced Squeeze-and-Excitation block that uses both average and max pooling,\n",
    "    inspired by the reference implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels * 2, channels // reduction, bias=False),\n",
    "            nn.SiLU(inplace=True),  # Using SiLU (swish) as in TF reference\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        avg_y = self.avg_pool(x).view(b, c)\n",
    "        max_y = self.max_pool(x).view(b, c)\n",
    "        y = torch.cat([avg_y, max_y], dim=1)\n",
    "        y = self.excitation(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class MultiScaleConv1d(nn.Module):\n",
    "    \"\"\"Multi-scale temporal convolution block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7]):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for ks in kernel_sizes:\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, ks, padding=ks//2, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = [conv(x) for conv in self.convs]\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "class ResidualSEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Use the new EnhancedSEBlock\n",
    "        self.se = EnhancedSEBlock(out_channels, reduction=8)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(pool_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        out = self.se(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MetaFeatureExtractor(nn.Module):\n",
    "    \"\"\"Extract statistical meta-features from input sequence\"\"\"\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, L, C)\n",
    "        mean = torch.mean(x, dim=1)\n",
    "        std = torch.std(x, dim=1)\n",
    "        max_val, _ = torch.max(x, dim=1)\n",
    "        min_val, _ = torch.min(x, dim=1)\n",
    "        \n",
    "        # Calculate slope: (last - first) / seq_len\n",
    "        seq_len = x.size(1)\n",
    "        if seq_len > 1:\n",
    "            slope = (x[:, -1, :] - x[:, 0, :]) / (seq_len - 1)\n",
    "        else:\n",
    "            slope = torch.zeros_like(x[:, 0, :])\n",
    "        \n",
    "        return torch.cat([mean, std, max_val, min_val, slope], dim=1)\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"Pools the output of a sequence-based layer (like LSTM or Attention) over the time dimension.\"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed0ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# EnhancedSEBlock, MetaFeatureExtractor, AttentionLayer\n",
    "\n",
    "\n",
    "class ModelVariant_GRU(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        num_channels = 7  # Hardcoded for IMU data\n",
    "\n",
    "        # 1. \n",
    "        self.meta_extractor = MetaFeatureExtractor()\n",
    "        self.meta_dense = nn.Sequential(\n",
    "            nn.Linear(5 * num_channels, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        # 2. \n",
    "        self.branches = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    # 输出通道数减少，从16*3=48 -> 12*3=36\n",
    "                    MultiScaleConv1d(1, 12, kernel_sizes=[3, 5, 7]),\n",
    "                    # 输出通道数相应调整\n",
    "                    ResidualSEBlock(36, 48, 3, dropout=0.3),\n",
    "                    ResidualSEBlock(48, 48, 3, dropout=0.3),\n",
    "                )\n",
    "                for _ in range(num_channels)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 3. 序列核心：使用BiGRU替换BiLSTM，并移除MultiHeadAttention\n",
    "        self.bigru = nn.GRU(\n",
    "            input_size=48 * num_channels,\n",
    "            hidden_size=128,  # 保持hidden_size\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        # 4. Attention Pooling层保持不变\n",
    "        self.attention_pooling = AttentionLayer(256)  # 128 * 2 for bidirectional\n",
    "\n",
    "        # 5. \n",
    "        self.head_1 = nn.Sequential(\n",
    "            nn.Linear(256 + 32, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "        self.head_2 = nn.Sequential(\n",
    "            nn.Linear(256 + 32, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),  # For regression task\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Meta features\n",
    "        meta = self.meta_extractor(x)\n",
    "        meta_proj = self.meta_dense(meta)\n",
    "\n",
    "        # CNN branches\n",
    "        branch_outputs = []\n",
    "        for i in range(x.shape[2]):\n",
    "            channel_input = x[:, :, i].unsqueeze(1)\n",
    "            processed = self.branches[i](channel_input)\n",
    "            branch_outputs.append(processed.transpose(1, 2))\n",
    "\n",
    "        combined = torch.cat(branch_outputs, dim=2)\n",
    "\n",
    "        # BiGRU processing\n",
    "        gru_out, _ = self.bigru(combined)  # (B, L/k, 256)\n",
    "\n",
    "        # Attention pooling\n",
    "        pooled_output = self.attention_pooling(gru_out)  # (B, 256)\n",
    "\n",
    "        # Combine with meta features\n",
    "        fused = torch.cat([pooled_output, meta_proj], dim=1)\n",
    "\n",
    "        # Final predictions\n",
    "        z1 = self.head_1(fused)\n",
    "        z2 = self.head_2(fused)\n",
    "        return z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a623a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kaggle_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Launch inference server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m inference_server = \u001b[43mkaggle_evaluation\u001b[49m.cmi_inference_server.CMIInferenceServer(predict)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.getenv(\u001b[33m'\u001b[39m\u001b[33mKAGGLE_IS_COMPETITION_RERUN\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     50\u001b[39m     inference_server.serve()\n",
      "\u001b[31mNameError\u001b[39m: name 'kaggle_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_test = sequence.to_pandas()\n",
    "    imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "    X_test, y_test, y_hard_test = [], [], []\n",
    "    \n",
    "    for sequence_id in tqdm(df_test.sequence_id.unique()):\n",
    "        ds = df_test[df_test[\"sequence_id\"] == sequence_id]\n",
    "        X = ds[imu_cols].values\n",
    "        X = pad_or_truncate(X)\n",
    "        X = np.concatenate((standard_scale(X[:, 0:3]), X[:, 3:]), axis=1)\n",
    "        X = np.where(np.isnan(X), 0.0, X)  # fill NaNs\n",
    "        X_test.append(X)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    model_paths = glob(\"/kaggle/input/mixup-gru-cv0-7358/*.pth\")\n",
    "    all_preds = []\n",
    "    for model_path in model_paths:\n",
    "        test_dataset = valid_dataset = CustomDataset(config, df_test, X_test)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=config.BATCH_SIZE_TEST,\n",
    "            shuffle=False,\n",
    "            num_workers=config.NUM_WORKERS, \n",
    "            pin_memory=True, drop_last=False\n",
    "        )\n",
    "        model = ModelVariant_GRU(num_classes=9)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        with tqdm(test_loader, unit=\"test_batch\", desc='Test') as tqdm_test_loader:\n",
    "            for step, batch in enumerate(tqdm_test_loader):\n",
    "                X = batch.pop(\"X\").to(device)\n",
    "                batch_size = X.size(0)\n",
    "                with torch.no_grad():\n",
    "                    y_preds, y_preds_hard = model(X)\n",
    "                y_preds = softmax(y_preds).to('cpu').numpy()\n",
    "                all_preds.append(y_preds)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_preds = np.argmax(all_preds.mean(axis=0)).item()\n",
    "    prediction = num_to_label[all_preds]\n",
    "    return prediction\n",
    "\n",
    "# Launch inference server\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a980f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa45926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
