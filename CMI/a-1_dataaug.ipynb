{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf612d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# You might need scipy for time warping\n",
    "try:\n",
    "    from scipy.interpolate import CubicSpline, interp1d, PchipInterpolator\n",
    "except ImportError:\n",
    "    print(\"Scipy not found. Time Warping augmentation will not be available.\")\n",
    "    CubicSpline, interp1d, PchipInterpolator = None, None, None\n",
    "\n",
    "\n",
    "# Assume TRAIN is defined elsewhere, e.g., as True/False or an enum\n",
    "# For these helper functions, we'll make them generic or controlled by parameters\n",
    "# For the dataset integration, we typically apply augmentations during \"training mode\"\n",
    "\n",
    "# --- Helper Augmentation Functions ---\n",
    "\n",
    "def jitter(seq: torch.Tensor, noise_level: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adds random noise to the sequence.\n",
    "\n",
    "    Args:\n",
    "        seq (torch.Tensor): Input sequence tensor [L, D].\n",
    "        noise_level (float): Standard deviation of the noise to add.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Jittered sequence tensor [L, D].\n",
    "    \"\"\"\n",
    "    if noise_level <= 0:\n",
    "        return seq\n",
    "    # Add noise sampled from a normal distribution\n",
    "    noise = torch.randn_like(seq) * noise_level\n",
    "    return seq + noise\n",
    "\n",
    "def scale(seq: torch.Tensor, scale_range=(0.8, 1.2)) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Randomly scales the sequence values.\n",
    "\n",
    "    Args:\n",
    "        seq (torch.Tensor): Input sequence tensor [L, D].\n",
    "        scale_range (tuple): Tuple (min_scale, max_scale) for random scaling factor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Scaled sequence tensor [L, D].\n",
    "    \"\"\"\n",
    "    min_scale, max_scale = scale_range\n",
    "    if min_scale >= max_scale:\n",
    "        return seq\n",
    "    # Generate a random scale factor for the whole sequence\n",
    "    scale_factor = (max_scale - min_scale) * torch.rand(1) + min_scale\n",
    "    return seq * scale_factor\n",
    "\n",
    "def time_warp(seq: torch.Tensor, num_control_points: int = 4, max_displacement_ratio: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Applies time warping to the sequence using cubic spline interpolation.\n",
    "    Requires scipy.\n",
    "\n",
    "    Args:\n",
    "        seq (torch.Tensor): Input sequence tensor [L, D].\n",
    "        num_control_points (int): Number of control points for the spline.\n",
    "                                  Must be >= 2. First and last points are fixed.\n",
    "        max_displacement_ratio (float): Maximum displacement as a fraction of the\n",
    "                                       interval between control points.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Time-warped sequence tensor [L, D]. Returns original if scipy\n",
    "                      is not available or warping fails.\n",
    "    \"\"\"\n",
    "    if CubicSpline is None:\n",
    "        print(\"Scipy not available. Skipping time warping.\")\n",
    "        return seq\n",
    "\n",
    "    L, D = seq.shape\n",
    "    if L <= 2 or num_control_points < 2:\n",
    "        return seq # Cannot warp very short sequences\n",
    "\n",
    "    try:\n",
    "        # Convert to numpy for scipy operations\n",
    "        seq_np = seq.numpy()\n",
    "\n",
    "        # Original time points\n",
    "        t_orig = np.arange(L)\n",
    "\n",
    "        # Original control points (evenly spaced)\n",
    "        t_orig_ctrl = np.linspace(0, L - 1, num_control_points)\n",
    "\n",
    "        # Randomly displace intermediate control points in time\n",
    "        # Keep start and end points fixed\n",
    "        displacements = (np.random.rand(num_control_points - 2) - 0.5) * 2 * (L / (num_control_points - 1)) * max_displacement_ratio\n",
    "        t_warp_ctrl = np.copy(t_orig_ctrl)\n",
    "        t_warp_ctrl[1:-1] += displacements\n",
    "\n",
    "        # Ensure warped control points are monotonic and within bounds [0, L-1]\n",
    "        t_warp_ctrl = np.clip(t_warp_ctrl, 0, L - 1)\n",
    "        t_warp_ctrl = np.sort(t_warp_ctrl) # Ensure monotonicity\n",
    "\n",
    "        # Create a mapping from original time to warped time using PchipInterpolator\n",
    "        # PchipInterpolator preserves monotonicity and shape better than CubicSpline here\n",
    "        time_map_func = PchipInterpolator(t_orig_ctrl, t_warp_ctrl)\n",
    "\n",
    "        # Get the new time points for the entire sequence\n",
    "        t_warp_full = time_map_func(t_orig)\n",
    "\n",
    "        # Ensure warped time points are within the original time bounds\n",
    "        t_warp_full = np.clip(t_warp_full, 0, L - 1)\n",
    "\n",
    "        # Interpolate the original data values onto the new warped time points\n",
    "        # Apply interpolation independently for each feature dimension\n",
    "        warped_seq_np = np.zeros_like(seq_np)\n",
    "        for d in range(D):\n",
    "            # Use interp1d to interpolate the data\n",
    "            # fill_value=\"extrapolate\" handles values outside the original time range\n",
    "            interpolator = interp1d(t_orig, seq_np[:, d], kind='linear', fill_value=\"extrapolate\")\n",
    "            warped_seq_np[:, d] = interpolator(t_warp_full)\n",
    "\n",
    "        return torch.tensor(warped_seq_np, dtype=seq.dtype)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Time warping failed: {e}. Returning original sequence.\")\n",
    "        # Handle potential errors during interpolation (e.g., non-monotonic control points despite sorting)\n",
    "        return seq\n",
    "\n",
    "\n",
    "def random_crop_or_pad(seq: torch.Tensor, target_len: int, pad_value: float = 0.0, mode: str = 'random') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Crops or pads the sequence to a target length.\n",
    "\n",
    "    Args:\n",
    "        seq (torch.Tensor): Input sequence tensor [L, D].\n",
    "        target_len (int): The desired length of the output sequence.\n",
    "        pad_value (float): The value to use for padding.\n",
    "        mode (str): 'random' for random cropping/padding start, 'start' for\n",
    "                    cropping/padding at the beginning, 'end' for cropping/padding\n",
    "                    at the end.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed sequence tensor [target_len, D].\n",
    "    \"\"\"\n",
    "    L, D = seq.shape\n",
    "\n",
    "    if L == target_len:\n",
    "        return seq\n",
    "\n",
    "    elif L > target_len:\n",
    "        # Crop\n",
    "        max_start = L - target_len\n",
    "        if mode == 'random':\n",
    "            start = np.random.randint(0, max_start + 1)\n",
    "        elif mode == 'start':\n",
    "            start = 0\n",
    "        elif mode == 'end':\n",
    "            start = max_start\n",
    "        else:\n",
    "             raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "        return seq[start : start + target_len]\n",
    "\n",
    "    else: # L < target_len\n",
    "        # Pad\n",
    "        total_padding = target_len - L\n",
    "        if mode == 'random':\n",
    "             pad_start = np.random.randint(0, total_padding + 1)\n",
    "        elif mode == 'start':\n",
    "             pad_start = 0\n",
    "        elif mode == 'end':\n",
    "             pad_start = total_padding\n",
    "        else:\n",
    "             raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "        pad_end = total_padding - pad_start\n",
    "\n",
    "        # Use torch.nn.functional.pad - pads (dim_last_start, dim_last_end, dim_prev_start, ...)\n",
    "        padded_seq = torch.nn.functional.pad(seq, (0, 0, pad_start, pad_end), \"constant\", pad_value)\n",
    "        return padded_seq\n",
    "\n",
    "# --- Example Integration into MotionDataset ---\n",
    "\n",
    "# You would add augmentation parameters to your dataset __init__\n",
    "class MotionDatasetAugmented(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, alpha=0.2,\n",
    "                 target_length=100,  # Define a standard length for sequences\n",
    "                 augmentations=None, # List of augmentation names to apply\n",
    "                 aug_params=None,    # Dictionary of parameters for augmentations\n",
    "                 pad_mode='random',  # Padding mode for random_crop_or_pad\n",
    "                 pad_value=0.0       # Padding value\n",
    "                 ):\n",
    "\n",
    "        # Ensure X and y are tensors, move to appropriate device if needed later\n",
    "        self.X = torch.tensor(X, dtype=torch.float32) if isinstance(X, np.ndarray) else X.clone().detach()\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) if isinstance(y, np.ndarray) else y.clone().detach() # Assuming y is sequence-like\n",
    "\n",
    "        # Make sure X and y have the same number of samples\n",
    "        assert len(self.X) == len(self.y), \"X and y must have the same number of samples.\"\n",
    "        # Make sure samples in X and y have the same sequence length initially\n",
    "        # This assumption might not hold if data is variable length initially.\n",
    "        # If variable length, padding/cropping MUST be the first step before other augs.\n",
    "        # Let's assume initial data might be variable length and pad/crop first or last.\n",
    "        # Applying it LAST after other augs and Mixup is common.\n",
    "\n",
    "        self.alpha = alpha # Mixup parameter\n",
    "        self.target_length = target_length\n",
    "        self.pad_mode = pad_mode\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "        # Configure augmentations\n",
    "        # Default parameters\n",
    "        self._default_aug_params = {\n",
    "            'jitter': {'noise_level': 0.05}, # 5% of the standard deviation of the data might be better\n",
    "            'scale': {'scale_range': (0.9, 1.1)},\n",
    "            'time_warp': {'num_control_points': 4, 'max_displacement_ratio': 0.1},\n",
    "            # Note: random_crop_or_pad is handled separately at the end\n",
    "        }\n",
    "        self.augmentations = augmentations if augmentations is not None else []\n",
    "        self.aug_params = self._default_aug_params.copy()\n",
    "        if aug_params:\n",
    "            for aug_name, params in aug_params.items():\n",
    "                 if aug_name in self.aug_params:\n",
    "                    self.aug_params[aug_name].update(params)\n",
    "                 else:\n",
    "                     print(f\"Warning: Unknown augmentation '{aug_name}' ignored.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def _apply_single_augmentation(self, x: torch.Tensor, aug_name: str) -> torch.Tensor:\n",
    "        \"\"\" Applies a single specified augmentation function. \"\"\"\n",
    "        params = self.aug_params.get(aug_name, {})\n",
    "        try:\n",
    "            if aug_name == 'jitter':\n",
    "                # A potentially better jittering: relative to data std deviation\n",
    "                # data_std = torch.std(x)\n",
    "                # return jitter(x, noise_level=params.get('noise_level', 0.05) * data_std)\n",
    "                # Or simpler fixed level:\n",
    "                 return jitter(x, noise_level=params.get('noise_level', 0.05))\n",
    "            elif aug_name == 'scale':\n",
    "                return scale(x, scale_range=params.get('scale_range', (0.9, 1.1)))\n",
    "            elif aug_name == 'time_warp':\n",
    "                 if CubicSpline is None: return x # Skip if scipy not available\n",
    "                 # Time warp needs numpy conversion\n",
    "                 x_np = x.numpy()\n",
    "                 x_warped_np = time_warp(x_np,\n",
    "                                         num_control_points=params.get('num_control_points', 4),\n",
    "                                         max_displacement_ratio=params.get('max_displacement_ratio', 0.1))\n",
    "                 return torch.tensor(x_warped_np, dtype=x.dtype) # Convert back\n",
    "            # Add other augmentations here if needed\n",
    "            else:\n",
    "                 print(f\"Warning: Unknown augmentation '{aug_name}' specified.\")\n",
    "                 return x\n",
    "        except Exception as e:\n",
    "             print(f\"Error applying augmentation '{aug_name}': {e}. Returning original sequence.\")\n",
    "             return x\n",
    "\n",
    "\n",
    "    def _apply_augmentations(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Applies the configured sequence of augmentations. \"\"\"\n",
    "        augmented_x = x\n",
    "        # Apply augmentations in a fixed order (e.g., Jitter -> Scale -> Time Warp)\n",
    "        # The order can matter!\n",
    "        for aug_name in ['jitter', 'scale', 'time_warp']: # Define your desired order\n",
    "            if aug_name in self.augmentations:\n",
    "                 augmented_x = self._apply_single_augmentation(augmented_x, aug_name)\n",
    "        return augmented_x\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the first sample\n",
    "        x1_orig, y1_orig = self.X[idx], self.y[idx]\n",
    "\n",
    "        # Get a random second sample for Mixup\n",
    "        shuffle_index = np.random.randint(0, len(self.X))\n",
    "        x2_orig, y2_orig = self.X[shuffle_index], self.y[shuffle_index]\n",
    "\n",
    "        # --- Apply Augmentations to Individual Samples (except random crop/pad) ---\n",
    "        # Apply augmentations *before* Mixup.\n",
    "        # Time warping requires numpy, so handle conversion if needed.\n",
    "        # Jitter and Scale can work directly on torch tensors.\n",
    "        x1_aug = self._apply_augmentations(x1_orig)\n",
    "        x2_aug = self._apply_augmentations(x2_orig)\n",
    "\n",
    "        # --- Apply Mixup ---\n",
    "        # Only mix the augmented X. Mix the label Y if Y is a sequence label.\n",
    "        # If Y is a single class label, you might only mix the label based on alpha\n",
    "        # for label smoothing, not directly mixing the tensor.\n",
    "        # Assuming Y is a sequence of the same length as X:\n",
    "        weight = np.random.beta(self.alpha, self.alpha)\n",
    "        weight_t = torch.tensor(weight, dtype=x1_aug.dtype) # Ensure weight is a tensor for tensor ops\n",
    "\n",
    "        x_mix = x1_aug * weight_t + x2_aug * (1 - weight_t)\n",
    "        y_mix = y1_orig * weight_t + y2_orig * (1 - weight_t) # Mix Y if Y is sequence-like\n",
    "\n",
    "        # --- Apply Random Crop/Pad to standardize length ---\n",
    "        # This should be applied *after* other augmentations and Mixup\n",
    "        # to ensure the final output has the target_length.\n",
    "        # It needs to be applied consistently to both x_mix and y_mix.\n",
    "\n",
    "        # Combine x_mix and y_mix along a new dimension temporarily for consistent padding\n",
    "        # Assuming x_mix shape [L, D_x] and y_mix shape [L, D_y]\n",
    "        # Stack them to get [L, D_x + D_y]\n",
    "        mixed_data = torch.cat([x_mix, y_mix], dim=-1) # Concatenate along feature dimension\n",
    "\n",
    "        # Apply random crop or pad\n",
    "        mixed_data_processed = random_crop_or_pad(mixed_data,\n",
    "                                                  target_len=self.target_length,\n",
    "                                                  pad_value=self.pad_value,\n",
    "                                                  mode=self.pad_mode)\n",
    "\n",
    "        # Split back into x and y\n",
    "        # Assuming original dimensions D_x = x_mix.shape[-1] and D_y = y_mix.shape[-1]\n",
    "        D_x = x_mix.shape[-1]\n",
    "        x_final = mixed_data_processed[:, :D_x]\n",
    "        y_final = mixed_data_processed[:, D_x:] # y_final will have shape [target_length, D_y]\n",
    "\n",
    "\n",
    "        return x_final, y_final\n",
    "\n",
    "\n",
    "# --- How to Use ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example Dummy Data (batch_size=10, seq_len=50-150, features=10)\n",
    "    # Assume y is also a sequence of same length, e.g., per-frame labels\n",
    "    num_samples = 100\n",
    "    min_len, max_len = 50, 150\n",
    "    num_features_x = 10\n",
    "    num_features_y = 3 # Example: one-hot encoding for per-frame classification\n",
    "\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for i in range(num_samples):\n",
    "        current_len = np.random.randint(min_len, max_len + 1)\n",
    "        # Create some simple wavy data + noise\n",
    "        t = np.linspace(0, 4 * np.pi, current_len)\n",
    "        x_sample = np.vstack([\n",
    "            np.sin(t) + np.random.randn(current_len) * 0.1 * (i / num_samples),\n",
    "            np.cos(t * 0.5) + np.random.randn(current_len) * 0.1 * (i / num_samples),\n",
    "            np.linspace(0, 1, current_len) + np.random.randn(current_len) * 0.05,\n",
    "            np.random.rand(current_len, num_features_x - 3) * 0.1 # Other features as noise\n",
    "        ]).T.astype(np.float32) # Shape [L, D_x]\n",
    "\n",
    "        # Create dummy per-frame labels (e.g., based on time)\n",
    "        y_sample_idx = (t > np.pi).astype(int) + (t > 2*np.pi).astype(int) # 0, 1, or 2\n",
    "        y_sample = np.zeros((current_len, num_features_y), dtype=np.float32)\n",
    "        y_sample[np.arange(current_len), y_sample_idx] = 1 # One-hot like [L, D_y]\n",
    "\n",
    "\n",
    "        X_data.append(x_sample)\n",
    "        y_data.append(y_sample)\n",
    "\n",
    "    print(f\"Generated {num_samples} samples with variable lengths ({min_len}-{max_len})\")\n",
    "    print(f\"Sample 0 X shape: {X_data[0].shape}, y shape: {y_data[0].shape}\")\n",
    "\n",
    "\n",
    "    # --- Configure the Augmented Dataset ---\n",
    "    target_sequence_length = 128\n",
    "\n",
    "    # Augmentations to use: jitter, scale, time_warp\n",
    "    # random_crop_or_pad is applied automatically at the end\n",
    "    augmentations_to_apply = ['jitter', 'scale', 'time_warp']\n",
    "\n",
    "    # Optional: Customize parameters\n",
    "    custom_aug_params = {\n",
    "        'jitter': {'noise_level': 0.02},\n",
    "        'scale': {'scale_range': (0.85, 1.15)},\n",
    "        # Use default params for time_warp\n",
    "    }\n",
    "\n",
    "\n",
    "    dataset = MotionDatasetAugmented(\n",
    "        X=X_data,\n",
    "        y=y_data,\n",
    "        alpha=0.4, # Mixup strength\n",
    "        target_length=target_sequence_length,\n",
    "        augmentations=augmentations_to_apply,\n",
    "        aug_params=custom_aug_params,\n",
    "        pad_mode='random', # 'random', 'start', or 'end' padding/cropping\n",
    "        pad_value=0.0\n",
    "    )\n",
    "\n",
    "    print(f\"\\nCreated augmented dataset with target length {target_sequence_length}\")\n",
    "    print(f\"Augmentations active: {dataset.augmentations}\")\n",
    "    print(f\"Mixup alpha: {dataset.alpha}\")\n",
    "    print(f\"Padding/Cropping mode: {dataset.pad_mode}\")\n",
    "\n",
    "\n",
    "    # --- Test getting a sample ---\n",
    "    sample_idx = 0\n",
    "    x_orig_sample, y_orig_sample = X_data[sample_idx], y_data[sample_idx]\n",
    "    x_aug_mix_processed, y_aug_mix_processed = dataset[sample_idx]\n",
    "\n",
    "    print(f\"\\nOriginal sample {sample_idx}: X shape {x_orig_sample.shape}, y shape {y_orig_sample.shape}\")\n",
    "    print(f\"Processed sample {sample_idx} from dataset: X shape {x_aug_mix_processed.shape}, y shape {y_aug_mix_processed.shape}\")\n",
    "\n",
    "    # Verify shape is the target length\n",
    "    assert x_aug_mix_processed.shape[0] == target_sequence_length\n",
    "    assert y_aug_mix_processed.shape[0] == target_sequence_length\n",
    "    assert x_aug_mix_processed.shape[1] == num_features_x\n",
    "    assert y_aug_mix_processed.shape[1] == num_features_y\n",
    "\n",
    "    print(\"\\nSample processed successfully and has target length.\")\n",
    "\n",
    "    # --- Example with DataLoader ---\n",
    "    # Use a DataLoader to process data in batches with multiprocessing\n",
    "    # num_workers > 0 is recommended for faster data loading and augmentation\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True, # Shuffle the dataset indices\n",
    "        num_workers=0 # Set to > 0 for faster loading in practice\n",
    "    )\n",
    "\n",
    "    print(f\"\\nCreated DataLoader with batch size {dataloader.batch_size}\")\n",
    "\n",
    "    # Get a batch\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        print(f\"\\nReceived batch:\")\n",
    "        print(f\" Batch X shape: {batch_x.shape}\") # Expected: [batch_size, target_length, num_features_x]\n",
    "        print(f\" Batch y shape: {batch_y.shape}\") # Expected: [batch_size, target_length, num_features_y]\n",
    "        print(f\" Data type X: {batch_x.dtype}, Data type y: {batch_y.dtype}\")\n",
    "        # Assert batch dimensions match expectations\n",
    "        assert batch_x.shape == (dataloader.batch_size, target_sequence_length, num_features_x)\n",
    "        assert batch_y.shape == (dataloader.batch_size, target_sequence_length, num_features_y)\n",
    "        break # Just take one batch for demonstration\n",
    "\n",
    "    print(\"\\nDataLoader batch processed successfully.\")\n",
    "    # Remember to install scipy if time_warp is used: pip install scipy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
